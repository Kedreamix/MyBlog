
---
title: 元宇宙/虚拟人
date: 2024-12-07 13:59:36
author: Kedreamix
cover: https://picx.zhimg.com/v2-325bb7409947b2356cc510d3fabf325b.jpg
categories: Paper
tags:
    - 元宇宙/虚拟人
description: 元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2024-12-07  PBDyG Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars  
keywords: 元宇宙/虚拟人
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>⚠️ 以下所有内容总结都来自于 Google的大语言模型[Gemini-Pro](https://ai.google.dev/)的能力，如有错误，仅供参考，谨慎使用
>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！
>💗 如果您觉得我们的项目对您有帮助 [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ，还请您给我们一些鼓励！⭐️ [HuggingFace免费体验](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-12-07 更新


## PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human   Avatars

**Authors:Shota Sasaki, Jane Wu, Ko Nishino**

This paper introduces a novel clothed human model that can be learned from multiview RGB videos, with a particular emphasis on recovering physically accurate body and cloth movements. Our method, Position Based Dynamic Gaussians (PBDyG), realizes ``movement-dependent'' cloth deformation via physical simulation, rather than merely relying on ``pose-dependent'' rigid transformations. We model the clothed human holistically but with two distinct physical entities in contact: clothing modeled as 3D Gaussians, which are attached to a skinned SMPL body that follows the movement of the person in the input videos. The articulation of the SMPL body also drives physically-based simulation of the clothes' Gaussians to transform the avatar to novel poses. In order to run position based dynamics simulation, physical properties including mass and material stiffness are estimated from the RGB videos through Dynamic 3D Gaussian Splatting. Experiments demonstrate that our method not only accurately reproduces appearance but also enables the reconstruction of avatars wearing highly deformable garments, such as skirts or coats, which have been challenging to reconstruct using existing methods. 

[PDF](http://arxiv.org/abs/2412.04433v1) 

**Summary**
新型衣饰人体模型可通过多视角RGB视频学习，实现物理精确的身体和衣物运动，并支持高度可变形服装的重建。

**Key Takeaways**
1. 提出基于多视角RGB视频学习的衣饰人体模型。
2. 使用物理模拟实现运动依赖的衣物变形。
3. 模型包括3D高斯衣物和SMPL骨骼。
4. SMPL骨骼的运动驱动衣物高斯变形。
5. 利用动态3D高斯喷绘估计物理属性。
6. 成功重建高度可变形服装，如裙子和外套。
7. 方法在复现外观和重建上优于现有技术。

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. **标题**：基于位置的动态高斯模型：运动感知穿衣人类化身研究（PBDyG: Position Based Dynamic Gaussians for Motion-Aware Clothed Human Avatars）

2. **作者**：Shota Sasaki（佐佐木翔太）、Jane Wu（吴婧）、Ko Nishino（柴原幸）。

3. **作者所属机构**：京都大学（Shota Sasaki和Ko Nishino）、加利福尼亚大学伯克利分校（Jane Wu）。

4. **关键词**：PBDyG模型、运动感知、穿衣人类化身、物理仿真、动态高斯模型。

5. **链接**：论文链接：[点击这里进入论文网页](https://vision.ist.i.kyoto-u.ac.jp)。代码链接：Github:None（如果可用，请填写具体的GitHub代码仓库链接）。

6. **摘要**：

    - (1)研究背景：随着计算机视觉技术的发展，构建运动感知的虚拟人类化身成为了研究热点。特别是穿着宽松衣物的化身模拟对于计算机视觉领域来说是一个挑战。本文介绍了一种新的穿衣人类模型，可以从多视角RGB视频中学习。
    
    - (2)过去的方法与问题：现有方法主要依赖姿态依赖的刚性变换来模拟衣物的动态变形，难以实现高度逼真的运动感知虚拟化身。本文提出了一种新的方法PBDyG，通过物理仿真实现运动依赖的衣物变形。
    
    - (3)研究方法：本文提出的PBDyG模型使用基于位置的动态高斯模型来模拟衣物的动态变形。该方法将衣物建模为3D高斯模型，并附着在跟随人物运动的SMPL身体上。通过物理仿真模拟衣物的动态变形，以实现运动感知的虚拟化身。物理属性如质量和材料刚度通过动态3D高斯喷涂从RGB视频中进行估算。
    
    - (4)任务与性能：本文的方法不仅准确还原了人物的外观，还能重建穿着高度可变形衣物（如裙子或外套）的化身，这是现有方法难以实现的。实验表明，该方法在重建高度可变形衣物方面的性能优越，支持了其目标的实现。

希望这个摘要能够满足您的需求！
7. 方法介绍：

    - (1)研究背景及前人方法分析：该研究旨在解决构建运动感知的虚拟人类化身的问题，特别是针对穿着宽松衣物的化身模拟。先前的方法主要依赖姿态依赖的刚性变换模拟衣物的动态变形，难以实现高度逼真的运动感知虚拟化身。
    
    - (2)本文方法提出：本文提出了一种新的方法PBDyG，该方法基于位置的动态高斯模型模拟衣物的动态变形。首先，将衣物建模为3D高斯模型并附着在跟随人物运动的SMPL身体上。然后通过物理仿真模拟衣物的动态变形，以创建运动感知的虚拟化身。物理属性如质量和材料刚度通过动态3D高斯喷涂从RGB视频中进行估算。
    
    - (3)实验设计及实现：实验通过对比PBDyG模型与其他先进的动画高斯模型（AG）在Avatar重建方法上的表现，验证了PBDyG模型的优越性。实验结果表明，PBDyG模型在重建高度可变形衣物方面性能优越，支持了其目标的实现。此外，通过引入新的评估指标HF-SSIM和HF-PSNR，对重建结果的准确性进行了更准确的评估。实验过程中使用了位置基动力学（PBD）进行仿真模拟，并通过最小化预测位置与实际跟踪结果之间的均方误差来优化参数α和M。为了保持衣物的灵活性和防止仿真过程中的不稳定现象，采用了AirMesh约束。
    
    - (4)方法的详细实现：实现过程中采用了子步策略进行仿真模拟，将每一帧分为多个小步骤进行模拟计算；采用距离约束和AirMesh约束来保证衣物的稳定性和灵活性；根据物理规律模拟衣物的动态变形，使得虚拟化身能够反映实际衣物的材料特性。
8. 结论：

（1）意义：
该研究提出了一种基于位置的动态高斯模型（PBDyG）来模拟运动感知穿衣人类化身的方法。这对于计算机视觉领域具有重要的研究意义，特别是在构建高度逼真的虚拟人类化身方面具有重要的应用前景。通过该方法，可以实现从多视角RGB视频中学习虚拟人类模型，为虚拟角色动画、游戏开发、电影制作等领域提供了有力的技术支持。

（2）创新点、性能和工作量总结：

创新点：

* 提出了基于位置的动态高斯模型（PBDyG），用于模拟运动感知穿衣人类化身。
* 通过物理仿真实现运动依赖的衣物变形，提高了虚拟化身的逼真度。
* 引入了新的评估指标HF-SSIM和HF-PSNR，对重建结果的准确性进行了更准确的评估。

性能：

* PBDyG模型在重建高度可变形衣物方面性能优越，实验结果表明其有效性。
* 通过引入位置基动力学（PBD）进行仿真模拟，实现了高度逼真的虚拟化身动画。
* 采用子步策略进行仿真模拟，提高了计算效率和稳定性。

工作量：

* 实现了PBDyG模型的详细算法，包括高斯建模、物理仿真、参数优化等。
* 进行了大量的实验验证和性能评估，包括对比实验和案例分析。
* 论文撰写和整理工作量大，需要具备一定的计算机视觉和物理仿真背景知识才能深入理解。


<details>
  <summary>点此查看论文截图</summary>
<img src="https://picx.zhimg.com/v2-82f94660d8c6d0d0a07a76597f86198f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-325bb7409947b2356cc510d3fabf325b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-082105f475afd440dabb10a54eb43e99.jpg" align="middle">
</details>




