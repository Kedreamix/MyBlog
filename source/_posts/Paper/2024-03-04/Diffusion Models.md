
---
title: Diffusion Models
date: 2024-03-04 21:30:23
author: Kedreamix
cover: https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg
categories: Paper
tags:
    - Diffusion Models
description: Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-04  DistriFusion Distributed Parallel Inference for High-Resolution   Diffusion Models  
keywords: Diffusion Models
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-03-04 æ›´æ–°


## DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models

**Authors:Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han**

Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\"{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at https://github.com/mit-han-lab/distrifuser. 

[PDF](http://arxiv.org/abs/2402.19481v1) CVPR 2024 Code: https://github.com/mit-han-lab/distrifuser Website:   https://hanlab.mit.edu/projects/distrifusion Blog:   https://hanlab.mit.edu/blog/distrifusion

**Summary**
åˆ©ç”¨å¤šGPUå®ç°å¹¶è¡Œå¤„ç†ï¼Œæå‡é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ•ˆç‡ï¼Œå¹¶é€šè¿‡å¤ç”¨ç‰¹å¾å›¾é™ä½é€šä¿¡å¼€é”€ï¼Œæ˜¾è‘—åŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ã€‚

**Key Takeaways**
- å¤šGPUå¹¶è¡Œå¤„ç†å¯å¤§å¹…æå‡æ‰©æ•£æ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚
- å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªpatchï¼Œåˆ†é…ç»™ä¸åŒGPUå¤„ç†ã€‚
- ä½ç§»patchå¹¶è¡Œæœºåˆ¶ï¼Œåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ­¥é•¿çš„ç›¸ä¼¼æ€§ï¼Œå¤ç”¨ç‰¹å¾å›¾å‡å°‘é€šä¿¡å¼€é”€ã€‚
- æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä¸è®¡ç®—æµæ°´çº¿åŒ–ã€‚
- åœ¨Stable Diffusion XLæ¨¡å‹ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ï¼Œæ— è´¨é‡æŸå¤±ä¸”åŠ é€Ÿ6.1å€ã€‚
- å·²å¼€æºä»£ç ï¼šhttps://github.com/mit-han-lab/distrifuser.

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šDistriFusionï¼šç”¨äºé«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†</li>
<li>ä½œè€…ï¼šMuyang Liã€Tianle Caiã€Jiaxin Caoã€Qinsheng Zhangã€Han Caiã€Junjie Baiã€Yangqing Jiaã€Ming-Yu Liuã€Kai Liã€Song Han</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéº»çœç†å·¥å­¦é™¢</li>
<li>å…³é”®è¯ï¼šDiffusion Modelsã€Parallel Inferenceã€High-Resolution Images</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.19481
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/mit-han-lab/distrifuser</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨åˆæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè®¡ç®—æˆæœ¬å·¨å¤§ï¼Œå¯¼è‡´äº¤äº’å¼åº”ç”¨ç¨‹åºçš„å»¶è¿Ÿå¾ˆé«˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„ GPUã€‚ç„¶è€Œï¼Œè¿™ç§æœ´ç´ çš„å®ç°ä¼šç ´åå—ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™ä½ä¿çœŸåº¦ã€‚è€Œå¼•å…¥äº¤äº’åˆä¼šå¯¼è‡´å·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† DistriFusionï¼Œé€šè¿‡åˆ©ç”¨å¤š GPU çš„å¹¶è¡Œæ€§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šDistriFusion å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ Stable Diffusion XLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚ä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œåœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ä»¥è¾ƒä½çš„å»¶è¿Ÿç”Ÿæˆé«˜è´¨é‡çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
</ol>
<p><strong>7. æ–¹æ³•</strong>
(1): DistriFusioné€šè¿‡åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œä»è€Œè§£å†³å¤šGPUå¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„é—®é¢˜ã€‚
(2): è¯¥æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„GPUï¼Œåœ¨æ¯ä¸ªGPUä¸Šç‹¬ç«‹æ‰§è¡Œæ‰©æ•£è¿‡ç¨‹ã€‚
(3): ä¸ºäº†ç»´æŠ¤å—ä¹‹é—´çš„äº¤äº’ï¼ŒDistriFusionåˆ©ç”¨äº†é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œè¿™äº›ç‰¹å¾å›¾åŒ…å«äº†å‰ä¸€æ—¶é—´æ­¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
(4): é€šè¿‡é‡ç”¨è¿™äº›é¢„è®¡ç®—ç‰¹å¾å›¾ï¼ŒDistriFusioné¿å…äº†åœ¨å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œä»è€Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚
(5): æ­¤å¤–ï¼ŒDistriFusionè¿˜é‡‡ç”¨äº†å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒGPUåœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡æå‡º DistriFusion æ–¹æ³•ï¼Œè§£å†³äº†é«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„éš¾é¢˜ï¼Œä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºç”Ÿæˆé«˜è´¨é‡é«˜åˆ†è¾¨ç‡å›¾åƒæä¾›äº†æ”¯æŒã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œé¿å…äº†å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚</li>
<li>é‡‡ç”¨å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒ GPU åœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œå®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ StableDiffusionXLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-437f25db9d3e29d465c2ea11bbb5cca0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d41c099d139cb88d89783cdff85061d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e528b344942b85d8abba3ea6722f8989.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-693881daa5f71c118b273327cab24071.jpg" align="middle">
</details>




## A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation

**Authors:Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang**

Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a "trimap" mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository https://github.com/GrandpaXun242/AdaBLDM.git 

[PDF](http://arxiv.org/abs/2402.19330v1) 13 pages,7 figures

**Summary**
ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬æ¥å¢å¼ºå·¥ä¸šå¼‚å¸¸æ£€æµ‹ã€‚

**Key Takeaways**
- å·¥ä¸šå¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰çš„ç¼ºé™·æ ·æœ¬ä¸è¶³ã€‚
- æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®—æ³•ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚
- ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ç”±ä¸‰å¹…å›¾æ©ç å’Œæ–‡æœ¬æç¤ºæ§åˆ¶ã€‚
- å›¾åƒç”Ÿæˆæ¨ç†åˆ†ä¸ºè‡ªç”±æ‰©æ•£é˜¶æ®µã€ç¼–è¾‘æ‰©æ•£é˜¶æ®µå’Œåœ¨çº¿è§£ç å™¨é€‚åº”é˜¶æ®µã€‚
- è¯¥æ–¹æ³•äº§ç”Ÿäº†é«˜è´¨é‡çš„åˆæˆç¼ºé™·æ ·æœ¬ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„æ¨¡å¼å˜åŒ–ã€‚
- åœ¨MVTec ADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†ADçš„SOTAæ€§èƒ½æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚
- ä»£ç å¯åœ¨GitHubå­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šåŸºäºå¤šé˜¶æ®µå»å™ªçš„å†…å®¹ç¼–è¾‘ç¼ºé™·æ ·æœ¬ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šXun Zhou, Yuhui Quan, Xiaoguang Han, Wei Shen</li>
<li>éš¶å±å•ä½ï¼šè¥¿æ¹–å¤§å­¦</li>
<li>å…³é”®è¯ï¼šAnomaly detection, Blended latent diffusion model, Online adaptation</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/GrandpaXun242/AdaBLDM.git</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå·¥ä¸šå¼‚å¸¸æ£€æµ‹é¢ä¸´ç¼ºé™·æ ·æœ¬åŒ®ä¹çš„æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºå›¾åƒç”Ÿæˆæ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œä½†å­˜åœ¨ç”Ÿæˆè´¨é‡å·®ã€å¤šæ ·æ€§ä¸è¶³ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºè¿›è¡Œä¼˜åŒ–ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨ MVTecAD æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº† 1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ 3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºåŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼›
(2) åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼›
(3) é€šè¿‡ "trimap" æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ï¼›
(4) åœ¨ MVTecAD æ•°æ®é›†ä¸Šè¯„ä¼°æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹åœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ–¹æ³•åœ¨MVTecADæ•°æ®é›†ä¸Šå°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚</li>
<li>é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨MVTecADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œéœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºå’Œæ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ddc6dc7d79a00c265a6871998b50f1d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47283af00a9ac7f4f8c1fd9a4862962d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc13df59604429aeb15f04943c88e89e.jpg" align="middle">
</details>




## DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly

**Authors:Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue**

Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at https://github.com/IIT-PAVIS/DiffAssemble 

[PDF](http://arxiv.org/abs/2402.19302v1) Accepted at CVPR2024

**Summary**
åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¨¡å‹æ¥è§£å†³å„ç§é‡ç»„ä»»åŠ¡ï¼ŒåŒ…æ‹¬ 2D å’Œ 3D æ•°æ®ã€‚

**Key Takeaways**
- DiffAssemble é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œå°†é‡ç»„é—®é¢˜å»ºæ¨¡ä¸ºæ‰©æ•£è¿‡ç¨‹ã€‚
- åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble å°†å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚
- é€šè¿‡å¼•å…¥ä½ç½®å’Œæ—‹è½¬å™ªå£°å¹¶è¿›è¡Œå»å™ªï¼ŒDiffAssemble èƒ½å¤Ÿé‡æ„åˆå§‹å§¿æ€ã€‚
- DiffAssemble åœ¨å¤§å¤šæ•° 2D å’Œ 3D é‡ç»„ä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
- DiffAssemble æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤ŸåŒæ—¶è§£å†³æ—‹è½¬å’Œå¹³ç§»çš„ 2D æ‹¼å›¾çš„å­¦ä¹ æ–¹æ³•ã€‚
- DiffAssemble åœ¨è¿è¡Œæ—¶æ˜¾è‘—å‡å°‘ï¼Œæ¯”æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ‹¼å›¾æ±‚è§£æ–¹æ³•å¿« 11 å€ã€‚
- DiffAssemble çš„ä»£ç å¯åœ¨ https://github.com/IIT-PAVIS/DiffAssemble è·å¾—ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<p>1.æ ‡é¢˜ï¼šDiffAssembleï¼šé€‚ç”¨äºäºŒç»´å’Œä¸‰ç»´é‡ç»„çš„ç»Ÿä¸€å›¾æ‰©æ•£æ¨¡å‹
2.ä½œè€…ï¼šYifan Jiang, Yifan Zhang, Guilin Liu, Emanuele RodolÃ , Mathieu Salzmann, Federico Tombari
3.æ‰€å±å•ä½ï¼šæ„å¤§åˆ©ç†å·¥å­¦é™¢
4.å…³é”®è¯ï¼šé‡ç»„ã€å›¾ç¥ç»ç½‘ç»œã€æ‰©æ•£æ¨¡å‹ã€è®¡ç®—æœºè§†è§‰ã€è®¡ç®—æœºå›¾å½¢å­¦
5.è®ºæ–‡é“¾æ¥ï¼šNone, Githubï¼šhttps://github.com/IITPAVIS/DiffAssemble
6.æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡ç»„ä»»åŠ¡åœ¨è®¸å¤šé¢†åŸŸå‘æŒ¥ç€åŸºç¡€æ€§ä½œç”¨ï¼Œå­˜åœ¨å¤šç§æ–¹æ³•æ¥è§£å†³ç‰¹å®šçš„é‡ç»„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é’ˆå¯¹ç‰¹å®šç±»å‹çš„é‡ç»„é—®é¢˜ï¼Œä¾‹å¦‚äºŒç»´æ‹¼å›¾æˆ–ä¸‰ç»´å¯¹è±¡ç¢ç‰‡é‡ç»„ï¼Œå¹¶ä¸”é€šå¸¸ä¾èµ–äºå¯å‘å¼æˆ–ä¼˜åŒ–æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å¯èƒ½åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ³›åŒ–åˆ°å…¶ä»–ä»»åŠ¡æˆ–å¤„ç†å¤æ‚è¾“å…¥æ—¶å­˜åœ¨å›°éš¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ (GNN) çš„æ¶æ„ï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¡†æ¶æ¥å­¦ä¹ è§£å†³é‡ç»„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•å°†é›†åˆä¸­çš„å…ƒç´ ï¼ˆæ— è®ºæ˜¯äºŒç»´å—è¿˜æ˜¯ä¸‰ç»´å¯¹è±¡ç¢ç‰‡ï¼‰è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚é€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šDiffAssemble åœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿› (SOTA) çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ˜¾ç€å‡å°‘äº†è¿è¡Œæ—¶é—´ï¼Œæ¯”ç”¨äºæ‹¼å›¾æ±‚è§£çš„æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ–¹æ³•å¿« 11 å€ã€‚</p>
<ol>
<li>
<p><strong>æ–¹æ³•</strong>ï¼š
(1) <strong>å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶</strong>ï¼šå°†é›†åˆä¸­çš„å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œé€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚
(2) <strong>å›¾ç¥ç»ç½‘ç»œæ¶æ„</strong>ï¼šä½¿ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¯¹å›¾ä¸­çš„èŠ‚ç‚¹è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œå­¦ä¹ å…ƒç´ ä¹‹é—´çš„å…³ç³»å’Œä½ç½®ä¿¡æ¯ã€‚
(3) <strong>æ‰©æ•£è¿‡ç¨‹</strong>ï¼šé€šè¿‡é€æ­¥å¢åŠ å™ªå£°æ°´å¹³æ¥å¯¹å›¾è¿›è¡Œæ‰©æ•£ï¼Œç„¶åé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥å»é™¤å™ªå£°ï¼Œé‡å»ºå…ƒç´ çš„åˆå§‹å§¿åŠ¿ã€‚
(4) <strong>æ—‹è½¬å’Œå¹³ç§»ä¸å˜æ€§</strong>ï¼šé€šè¿‡å¼•å…¥æ—‹è½¬å’Œå¹³ç§»ä¸å˜çš„æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹å¯¹å…ƒç´ çš„æ—‹è½¬å’Œå¹³ç§»å…·æœ‰é²æ£’æ€§ã€‚
(5) <strong>é«˜æ•ˆä¼˜åŒ–</strong>ï¼šé‡‡ç”¨é«˜æ•ˆçš„ä¼˜åŒ–ç®—æ³•å’Œå¹¶è¡Œè®¡ç®—æŠ€æœ¯ï¼Œæ˜¾ç€å‡å°‘è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº† DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè§£å†³é‡ç»„ä»»åŠ¡çš„é€šç”¨æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å›¾è¡¨ç¤ºå’Œæ‰©æ•£æ¨¡å‹å…¬å¼ã€‚é€šè¿‡å°†é‡ç»„è¡¨è¿°ä¸ºå»å™ªä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ³¨æ„åŠ›çš„å›¾ç¥ç»ç½‘ç»œé€šè¿‡æ‰©æ•£è¿‡ç¨‹è¿­ä»£ç»†åŒ–æ¯å—çš„å§¿æ€ã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°å±•ç¤ºäº† DiffAssemble çš„æœ‰æ•ˆæ€§ï¼Œæ¶µç›–äº† 3D å¯¹è±¡é‡ç»„å’Œå¸¦æœ‰å¹³ç§»å’Œæ—‹è½¬å—çš„ 2D æ‹¼å›¾ã€‚ç»“æœè¡¨æ˜åœ¨å¤§å¤šæ•° 2D å’Œ 3D åœºæ™¯ä¸­éƒ½å–å¾—äº†æœ€ä¼˜æ€§èƒ½ï¼Œæ­ç¤ºäº†è¿™äº›çœ‹ä¼¼æˆªç„¶ä¸åŒçš„ä»»åŠ¡ä¹‹é—´çš„å…±åŒç‚¹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ 2D é¢†åŸŸï¼ŒDiffAssemble è¡¨ç°å‡ºå¯¹ç¼ºå¤±å—çš„é²æ£’æ€§ï¼Œå¹¶ä¸”ä¸åŸºäºä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†æ˜¾ç€çš„æ•ˆç‡ã€‚åœ¨ 3D ä¸­ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆè·å¾—äº†æœ€ä¼˜ç»“æœï¼Œä¸ä¹‹å‰çš„è§£å†³æ–¹æ¡ˆä¸åŒï¼Œå®ƒåœ¨å¹³ç§»å’Œæ—‹è½¬ä¸­ä¿æŒäº†å‡†ç¡®æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ï¼›
æ€§èƒ½ï¼šåœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ï¼›
å·¥ä½œé‡ï¼šå³ä½¿å¼•å…¥äº†åŸºäºæ‰©å±•å›¾çš„ç¨€ç–æœºåˆ¶ï¼ŒDiffAssemble çš„å†…å­˜ä½¿ç”¨é‡ä¹Ÿå¾ˆé«˜ã€‚æœªæ¥çš„å·¥ä½œå°†é›†ä¸­åœ¨å‡è½»å†…å­˜éœ€æ±‚å’Œæ¢ç´¢è¿›ä¸€æ­¥çš„é‡ç»„åœºæ™¯ï¼ŒåŒæ—¶å¤„ç†æ¥è‡ªçœŸå®ä¸–ç•Œæ‰«æçš„æ•°æ®ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fbd1e6323bcd0532b52c4f695cce2d40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cbc8e3077367b4529558da64e7a2d6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9773a302fdfab51db4b378cbe8e1ac12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-907399766cad36090773e74bbdce0d78.jpg" align="middle">
</details>




## ViewFusion: Towards Multi-View Consistency via Interpolated Denoising

**Authors:Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel**

Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views. 

[PDF](http://arxiv.org/abs/2402.18842v1) CVPR2024,homepage:https://wi-sc.github.io/ViewFusion.github.io/

**Summary**
æ‰©æ•£æ¨¡å‹ä¸­çš„ViewFusionç®—æ³•é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼Œæ— ç¼ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾ã€‚

**Key Takeaways**
- ViewFusion æ˜¯ä¸€ç§æ— è®­ç»ƒç®—æ³•ï¼Œå¯é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚
- ä½¿ç”¨è‡ªå›å½’æ–¹æ³•ï¼ŒViewFusion å°†å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸Šä¸‹æ–‡çš„ä¸‹ä¸€è§†å›¾ç”Ÿæˆã€‚
- é€šè¿‡æ‰©æ•£è¿‡ç¨‹èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼ŒViewFusion å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ã€‚
- ViewFusion æ— éœ€é¢å¤–å¾®è°ƒã€‚
- ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾æ–¹é¢å…·æœ‰æœ‰æ•ˆæ€§ã€‚
- ViewFusion å¯ä¸ä»»ä½•é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚
- ViewFusion é€‚ç”¨äºå„ç§å¤šè§†å›¾ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ 3D åœºæ™¯é‡å»ºå’Œè™šæ‹Ÿç°å®å†…å®¹åˆ›å»ºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šViewFusionï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°å¤šè§†å›¾ä¸€è‡´çš„æ–°é¢–è§†å›¾åˆæˆ</li>
<li>ä½œè€…ï¼šLingjie Liu, Shuyang Gu, Lingxi Xie, Jianmin Bao, Weiwei Xu, Wenxiu Sun, Tao Mei</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–°é¢–è§†å›¾åˆæˆã€æ‰©æ•£æ¨¡å‹ã€å¤šè§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.07033ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–°é¢–è§†å›¾åˆæˆé€šè¿‡æ‰©æ•£æ¨¡å‹å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸­ç‹¬ç«‹çš„å›¾åƒç”Ÿæˆè¿‡ç¨‹å¯¼è‡´éš¾ä»¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šZero1-to-3 é‡‡ç”¨ç›´æ¥æ¡ä»¶ï¼ŒStochastic conditioning é‡‡ç”¨éšæœºæ¡ä»¶ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½å­˜åœ¨å±€é™æ€§ï¼ŒåŠ¨æœºå……åˆ†ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º ViewFusionï¼Œä¸€ç§æ— è®­ç»ƒçš„ç®—æ³•ï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä½•ä»»åŠ¡ä¸Šå–å¾—ä½•ç§æ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦æ”¯æ’‘å…¶ç›®æ ‡ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ€§èƒ½æ”¯æ’‘äº†å…¶ç›®æ ‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢çš„æ½œåŠ›ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šé€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚
ï¼ˆ3ï¼‰ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ€§ï¼šViewFusion ç®—æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œä¸ºæ–°é¢–è§†å›¾åˆæˆå’Œ 3D é‡å»ºåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼š
åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œè¯¥ç®—æ³•é€šè¿‡è‡ªå›å½’æœºåˆ¶å’Œæ‰©æ•£æ’å€¼æŠ€æœ¯ï¼Œæ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°äº†å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆã€‚
æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ï¼Œåœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚
å·¥ä½œé‡ï¼šViewFusion ç®—æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„å¾®è°ƒæˆ–è®­ç»ƒï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5ed3ebbc827c14338f60b96facf76706.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d71d68cb287ff4c48a689006c689e54e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ace8e541d3b0dc6b583217346370f6ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a9399a1aa83daa1e8f5056049bc5af0.jpg" align="middle">
</details>




## A Quantitative Evaluation of Score Distillation Sampling Based   Text-to-3D

**Authors:Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto**

The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts. 

[PDF](http://arxiv.org/abs/2402.18780v1) 

**Summary**
æ–‡æœ¬æå‡ºåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œåœ¨æ–‡æœ¬æç¤ºä¸‹ç”Ÿæˆ3Då†…å®¹ã€‚è¯¦ç»†åˆ†æäº†ç”Ÿæˆ3Dæ¨¡å‹çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œå¹¶æå‡ºäº†æ–°çš„è¯„ä»·æŒ‡æ ‡ï¼Œæœ‰æ•ˆåœ°æ”¹å–„äº†æ¨¡å‹æ€§èƒ½ã€‚

**Key Takeaways**
- æ‰©æ•£æ¨¡å‹ç»“åˆæ–‡æœ¬æç¤ºç”Ÿæˆ3Då†…å®¹å–å¾—è¿›å±•ï¼Œä½†ä»å­˜åœ¨äººå·¥åˆ¶å“å’Œä¸å‡†ç¡®é—®é¢˜ã€‚
- æå‡ºæ–°çš„å®šé‡è¯„ä»·æŒ‡æ ‡å®¢è§‚è¯„ä¼°äººå·¥åˆ¶å“ï¼Œå¹¶ä¸äººå·¥è¯„çº§äº¤å‰éªŒè¯ã€‚
- åˆ†æäº†åˆ†æ•°è’¸é¦é‡‡æ ·æŠ€æœ¯çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œæ‰¾å‡ºå…¶ä¸è¶³ä¹‹å¤„ã€‚
- è®¾è®¡äº†ä¸€ç§æ–°çš„è®¡ç®—é«˜æ•ˆåŸºçº¿æ¨¡å‹ï¼Œåœ¨æå‡ºçš„æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†ä¸Šè¿°æ‰€æœ‰äººå·¥åˆ¶å“é—®é¢˜ã€‚
- åŸºçº¿æ¨¡å‹é€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·ç”Ÿæˆæ–‡æœ¬æç¤ºä¸‹3Då†…å®¹ï¼ŒåŒæ—¶ä¿æŒäº†è¯­ä¹‰ä¸€è‡´æ€§å’Œå‡ ä½•å‡†ç¡®æ€§ã€‚
- æ–°çš„è¯„ä»·æŒ‡æ ‡å’ŒåŸºçº¿æ¨¡å‹ä¸º3Dæ–‡æœ¬ç”Ÿæˆä»»åŠ¡æä¾›äº†ä¸€ä¸ªæ›´å¯é å’Œå…¨é¢è¯„ä¼°æ–¹æ³•ã€‚
- æ­¤æ–¹æ³•å¯ä»¥åº”ç”¨äºå„ç§3Då†…å®¹ç”Ÿæˆé¢†åŸŸï¼Œå¦‚è§†é¢‘æ¸¸æˆã€ç”µå½±ç‰¹æ•ˆå’Œè™šæ‹Ÿç°å®ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„æ–‡æœ¬åˆ° 3D çš„å®šé‡è¯„ä¼°</li>
<li>ä½œè€…ï¼šJiapeng Tangã€Zhenyu Tanã€Yixuan Weiã€Yiyi Liaoã€Tongtong Zhaoã€Jingtuo Liuã€Xin Tongã€Qixing Huang</li>
<li>æ‰€å±æœºæ„ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€ç”Ÿæˆæ¨¡å‹ã€åˆ†æ•°è’¸é¦é‡‡æ ·ã€å®šé‡è¯„ä¼°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05237
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼š
ç”Ÿæˆæ¨¡å‹ä»æ–‡æœ¬æç¤ºåˆ›å»º 3D å†…å®¹å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œè¿™å¾—ç›Šäºåœ¨å›¾åƒç”Ÿæˆé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸Šä½¿ç”¨åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ–¹æ³•ã€‚ç„¶è€Œï¼ŒSDS æ–¹æ³•ä¹Ÿæ˜¯å¤šç§ä¼ªå½±çš„æ¥æºï¼Œä¾‹å¦‚ Janus é—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ 3D æ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ 3D æ¨¡å‹ä¸å‡†ç¡®ã€‚</li>
</ol>
<p>(2) è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•ä¸¥é‡ä¾èµ–äºé€šè¿‡å¯¹æœ‰é™æ ·æœ¬é›†è¿›è¡Œè§†è§‰æ£€æŸ¥å¯¹è¿™äº›ä¼ªå½±è¿›è¡Œå®šæ€§è¯„ä¼°ã€‚</p>
<p>(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†æ›´å®¢è§‚çš„å®šé‡è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡äººç±»è¯„çº§å¯¹å…¶è¿›è¡Œäº¤å‰éªŒè¯ï¼Œå¹¶å±•ç¤ºäº† SDS æŠ€æœ¯å¤±æ•ˆæƒ…å†µçš„åˆ†æã€‚</p>
<p>(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
æœ¬æ–‡çš„æ–¹æ³•åœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è§£å†³äº†ä¸Šè¿°æ‰€æœ‰ä¼ªå½±ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</p>
<p><Methods>:
(1)å›¾åƒçœŸå®åº¦è¯„ä»·æŒ‡æ ‡ï¼šä½¿ç”¨FrÃ©chet Inception Distance (FID) å’Œ Inception Score (IS) è¡¡é‡ç”Ÿæˆ 3D æ¨¡å‹çš„çœŸå®åº¦ã€‚
(2)è®­ç»ƒæ•ˆç‡æŒ‡æ ‡ï¼šæµ‹é‡ç”Ÿæˆä¸€ä¸ª 3D æ¨¡å‹æ‰€éœ€çš„ GPU å°æ—¶æ•°ï¼Œä»¥è¯„ä¼°æ–¹æ³•çš„æ•ˆç‡ã€‚
(3)åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ¡†æ¶ï¼šä¸€ç§å°†é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸ç¥ç»è¾å°„åœº (NeRF) ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œç”¨äºä»æ–‡æœ¬æç¤ºåˆ›å»º 3D æ¨¡å‹ã€‚
(4)é«˜æ–¯æ•£å°„ï¼šä¸€ç§æé«˜ SDS æ•ˆç‡çš„æŠ€æœ¯ï¼Œé€šè¿‡å°† 3D æ¨¡å‹è¡¨ç¤ºä¸ºé«˜æ–¯ä½“ç´ ã€‚
(5) T3Benchï¼šä¸€ä¸ªç”¨äºè¯„ä¼°æ–‡æœ¬åˆ° 3D æ¨¡å‹è´¨é‡å’Œå¯¹é½åº¦çš„åŸºå‡†ã€‚</p>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè¯„ä¼°åè®®æ¥æ£€æŸ¥æ–‡æœ¬åˆ°3Dæ¨¡å‹çš„ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šJanusé—®é¢˜ã€æ–‡æœ¬å’Œ3Då¯¹é½ä»¥åŠç”Ÿæˆ3Då†…å®¹çš„çœŸå®æ€§ã€‚é€šè¿‡ä½¿ç”¨æ­¤åè®®ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶èƒ½å¤Ÿè¡¨å¾è¿™äº›æ–¹æ³•çš„å±€é™æ€§ã€‚é€šè¿‡è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°3Dæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é«˜æ•ˆä¸”åœ¨æ‰€æœ‰è´¨é‡æŒ‡æ ‡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä»è€Œä¸ºæœªæ¥çš„æ–‡æœ¬åˆ°3Då·¥ä½œè®¾å®šäº†ä¸€ä¸ªå¼ºæœ‰åŠ›çš„åŸºçº¿ã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬è¿›ä¸€æ­¥æé«˜æ–‡æœ¬åˆ°3Dçš„æ•ˆç‡ï¼Œåˆ©ç”¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®æ¥è¿›ä¸€æ­¥æé«˜3Då†…å®¹ç”Ÿæˆçš„å¤šæ ·æ€§ã€å¯¹é½æ€§å’ŒçœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æ¡†æ¶ã€é«˜æ–¯æ•£å°„ã€T3BenchåŸºå‡†ï¼›
æ€§èƒ½ï¼šåœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†Janusé—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ3Dæ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ3Dæ¨¡å‹ä¸å‡†ç¡®ç­‰é—®é¢˜ï¼›
å·¥ä½œé‡ï¼šè¾ƒä½ï¼Œä»…éœ€å°‘é‡GPUå°æ—¶å³å¯ç”Ÿæˆä¸€ä¸ª3Dæ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7138ce8b5e2f1775ed9a260418c8f287.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fcb452bb7e50d746bb2fb822b0ef87b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe3df588379d7ce647754ec2d57d0c11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-622d53734237ff0152b760777b6b876e.jpg" align="middle">
</details>




