
---
title: Talking Head Generation
date: 2024-05-13 16:02:14
author: Kedreamix
cover: https://picx.zhimg.com/v2-d9bb935fc998f1e0a691f975b5f9649c.jpg
categories: Paper
tags:
    - Talking Head Generation
description: Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-13  NeRFFaceSpeech One-shot Audio-driven 3D Talking Head Synthesis via   Generative Prior  
keywords: Talking Head Generation
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-05-13 æ›´æ–°


## NeRFFaceSpeech: One-shot Audio-driven 3D Talking Head Synthesis via   Generative Prior

**Authors:Gihoon Kim, Kwanggyoon Seo, Sihun Cha, Junyong Noh**

Audio-driven talking head generation is advancing from 2D to 3D content. Notably, Neural Radiance Field (NeRF) is in the spotlight as a means to synthesize high-quality 3D talking head outputs. Unfortunately, this NeRF-based approach typically requires a large number of paired audio-visual data for each identity, thereby limiting the scalability of the method. Although there have been attempts to generate audio-driven 3D talking head animations with a single image, the results are often unsatisfactory due to insufficient information on obscured regions in the image. In this paper, we mainly focus on addressing the overlooked aspect of 3D consistency in the one-shot, audio-driven domain, where facial animations are synthesized primarily in front-facing perspectives. We propose a novel method, NeRFFaceSpeech, which enables to produce high-quality 3D-aware talking head. Using prior knowledge of generative models combined with NeRF, our method can craft a 3D-consistent facial feature space corresponding to a single image. Our spatial synchronization method employs audio-correlated vertex dynamics of a parametric face model to transform static image features into dynamic visuals through ray deformation, ensuring realistic 3D facial motion. Moreover, we introduce LipaintNet that can replenish the lacking information in the inner-mouth area, which can not be obtained from a given single image. The network is trained in a self-supervised manner by utilizing the generative capabilities without additional data. The comprehensive experiments demonstrate the superiority of our method in generating audio-driven talking heads from a single image with enhanced 3D consistency compared to previous approaches. In addition, we introduce a quantitative way of measuring the robustness of a model against pose changes for the first time, which has been possible only qualitatively. 

[PDF](http://arxiv.org/abs/2405.05749v2) 11 pages, 5 figures

**Summary**
å•å¼ äººè„¸å›¾åƒå³å¯é©±åŠ¨ 3D ä¼šè¯å¼äººå¤´çš„ç”Ÿæˆï¼Œè¿™æ˜¯ç”±äºå¯¹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯å’Œç”Ÿæˆæ¨¡å‹çš„å·§å¦™è¿ç”¨ã€‚

**Key Takeaways**
- NeRF-based 3D talking head generation typically requires a large amount of paired audio-visual data.
- Audio-driven 3D talking head animations with a single image often have unsatisfactory results due to occlusion problems.
- NeRFFaceSpeech generates high-quality 3D-aware talking heads from a single image.
- NeRFFaceSpeech uses generative models and NeRF to create a 3D-consistent facial feature space.
- Spatial synchronization method employs audio-correlated vertex dynamics to transform static image features into dynamic visuals.
- LipaintNet replenishes the lacking information in the inner-mouth area.
- NeRFFaceSpeech outperforms previous methods in generating audio-driven talking heads from a single image with enhanced 3D consistency.

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>é¢˜ç›®ï¼šNeRFFaceSpeechï¼šåŸºäºç”Ÿæˆå…ˆéªŒçš„å•æ¬¡éŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´è¯´è¯äººå¤´éƒ¨åˆæˆ</p>
</li>
<li>
<p>ä½œè€…ï¼šGihoon Kimï¼ŒKwanggyoon Seoï¼ŒSihun Chaï¼ŒJunyong Noh</p>
</li>
<li>
<p>æ‰€å±æœºæ„ï¼šé¦–å°”å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼ŒéŸ³é¢‘é©±åŠ¨ï¼Œä¸‰ç»´è¯´è¯äººå¤´éƒ¨ï¼Œç”Ÿæˆå…ˆéªŒ</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2405.05749ï¼ŒGithubä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ­£ä»äºŒç»´å†…å®¹è½¬å‘ä¸‰ç»´å†…å®¹ã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä½œä¸ºä¸€ç§åˆæˆé«˜è´¨é‡ä¸‰ç»´è¯´è¯äººå¤´éƒ¨è¾“å‡ºçš„æ–¹æ³•å¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œè¿™ç§åŸºäºNeRFçš„æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡é’ˆå¯¹æ¯ä¸ªèº«ä»½æˆå¯¹çš„éŸ³é¢‘-è§†è§‰æ•°æ®ï¼Œä»è€Œé™åˆ¶äº†è¯¥æ–¹æ³•çš„å¯æ‰©å±•æ€§ã€‚å°½ç®¡å·²ç»å°è¯•ä½¿ç”¨å•å¼ å›¾åƒç”ŸæˆéŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´è¯´è¯äººå¤´éƒ¨åŠ¨ç”»ï¼Œä½†ç”±äºå›¾åƒä¸­é®æŒ¡åŒºåŸŸçš„ä¿¡æ¯ä¸è¶³ï¼Œç»“æœå¾€å¾€ä¸ä»¤äººæ»¡æ„ã€‚æœ¬æ–‡ä¸»è¦å…³æ³¨è§£å†³å•æ¬¡ã€éŸ³é¢‘é©±åŠ¨çš„é¢†åŸŸä¸­è¢«å¿½è§†çš„ä¸‰ç»´ä¸€è‡´æ€§æ–¹é¢ï¼Œå…¶ä¸­é¢éƒ¨åŠ¨ç”»ä¸»è¦ä»¥æ­£é¢è§†è§’åˆæˆã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•è¯•å›¾ä½¿ç”¨å•å¼ å›¾åƒç”ŸæˆéŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´è¯´è¯äººå¤´éƒ¨åŠ¨ç”»ï¼Œä½†ç”±äºå›¾åƒä¸­é®æŒ¡åŒºåŸŸçš„ä¿¡æ¯ä¸è¶³ï¼Œç»“æœå¾€å¾€ä¸ä»¤äººæ»¡æ„ã€‚æœ¬æ–‡çš„æ–¹æ³•åŠ¨æœºæ˜ç¡®ï¼Œæ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•NeRFFaceSpeechï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´æ„ŸçŸ¥è¯´è¯äººå¤´éƒ¨ã€‚è¯¥æ–¹æ³•ç»“åˆäº†ç”Ÿæˆæ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†å’ŒNeRFï¼Œå¯ä»¥æ„å»ºä¸å•å¼ å›¾åƒç›¸å¯¹åº”çš„ä¸‰ç»´ä¸€è‡´çš„é¢éƒ¨ç‰¹å¾ç©ºé—´ã€‚æˆ‘ä»¬çš„ç©ºé—´åŒæ­¥æ–¹æ³•é‡‡ç”¨å‚æ•°åŒ–é¢éƒ¨æ¨¡å‹çš„éŸ³é¢‘ç›¸å…³é¡¶ç‚¹åŠ¨æ€ï¼Œé€šè¿‡å…‰çº¿å˜å½¢å°†é™æ€å›¾åƒç‰¹å¾è½¬æ¢ä¸ºåŠ¨æ€è§†è§‰æ•ˆæœï¼Œç¡®ä¿é€¼çœŸçš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†LipaintNetï¼Œå®ƒå¯ä»¥è¡¥å……å•å¼ ç»™å®šå›¾åƒä¸­æ— æ³•è·å¾—çš„å†…éƒ¨å£è…”åŒºåŸŸçš„ç¼ºå¤±ä¿¡æ¯ã€‚è¯¥ç½‘ç»œä»¥è‡ªç›‘ç£çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œåˆ©ç”¨ç”Ÿæˆèƒ½åŠ›è€Œæ— éœ€é¢å¤–æ•°æ®ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šç»¼åˆå®éªŒè¡¨æ˜ï¼Œä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰å¢å¼ºä¸‰ç»´ä¸€è‡´æ€§çš„éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é¦–æ¬¡å¼•å…¥äº†ä¸€ç§è¡¡é‡æ¨¡å‹å¯¹å§¿æ€å˜åŒ–é²æ£’æ€§çš„å®šé‡æ–¹æ³•ï¼Œè¿™åœ¨è¿‡å»åªèƒ½å®šæ€§åœ°è¿›è¡Œã€‚</p>
<ol>
<li>Methods:</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºNeRFFaceSpeechæ–¹æ³•ï¼Œç»“åˆç”Ÿæˆæ¨¡å‹å…ˆéªŒå’ŒNeRFï¼Œæ„å»ºä¸å•å¼ å›¾åƒç›¸å¯¹åº”çš„ä¸‰ç»´ä¸€è‡´çš„é¢éƒ¨ç‰¹å¾ç©ºé—´ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šé‡‡ç”¨å‚æ•°åŒ–é¢éƒ¨æ¨¡å‹çš„éŸ³é¢‘ç›¸å…³é¡¶ç‚¹åŠ¨æ€ï¼Œé€šè¿‡å…‰çº¿å˜å½¢å°†é™æ€å›¾åƒç‰¹å¾è½¬æ¢ä¸ºåŠ¨æ€è§†è§‰æ•ˆæœï¼Œç¡®ä¿é€¼çœŸçš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šå¼•å…¥LipaintNetï¼Œä»¥è‡ªç›‘ç£çš„æ–¹å¼è¡¥å……å•å¼ ç»™å®šå›¾åƒä¸­æ— æ³•è·å¾—çš„å†…éƒ¨å£è…”åŒºåŸŸçš„ç¼ºå¤±ä¿¡æ¯ï¼Œæ— éœ€é¢å¤–æ•°æ®ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šå¼•å…¥è¡¡é‡æ¨¡å‹å¯¹å§¿æ€å˜åŒ–é²æ£’æ€§çš„å®šé‡æ–¹æ³•ï¼Œé¦–æ¬¡å®ç°å¯¹å§¿æ€å˜åŒ–é²æ£’æ€§çš„å®šé‡è¯„ä¼°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡çš„æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†NeRFFaceSpeechï¼Œä¸€ç§é€šè¿‡åˆ©ç”¨ç”Ÿæˆå…ˆéªŒæ„å»ºå’Œæ“ä½œä¸‰ç»´ç‰¹å¾ï¼Œä»å•å¼ å›¾åƒç”Ÿæˆä¸‰ç»´æ„ŸçŸ¥éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åŠ¨ç”»çš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬çš„ç®¡é“å¼¥åˆäº†é¢éƒ¨å‚æ•°åŒ–æ¨¡å‹å’Œç¥ç»æ¸²æŸ“ä¹‹é—´çš„å·®è·ï¼Œé€šè¿‡å…‰çº¿å˜å½¢ç›´è§‚åœ°æ“çºµç‰¹å¾ç©ºé—´ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†LipaintNetï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›æ¥åˆæˆéšè—çš„å†…å£åŒºåŸŸï¼Œè¡¥å……å˜å½¢åœºä»¥äº§ç”Ÿå¯è¡Œçš„ç»“æœã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ¨¡å‹å¯¹å§¿åŠ¿å˜åŒ–å…·æœ‰é²æ£’æ€§ï¼Œå¹¶ä¸”å¯ä»¥ç”Ÿæˆæ¯”ä»¥å‰çš„æ–¹æ³•æ›´å¥½çš„å†…éƒ¨å£éƒ¨ä¿¡æ¯ï¼Œä»è€Œäº§ç”Ÿæ›´å¥½çš„ç»“æœã€‚è‡´è°¢ã€‚è¿™é¡¹å·¥ä½œå¾—åˆ°äº†æ–‡åŒ–ä½“è‚²è§‚å…‰éƒ¨R&amp;Dè®¡åˆ’çš„æ”¯æŒï¼Œè¯¥è®¡åˆ’ç”±æ–‡åŒ–ä½“è‚²è§‚å…‰éƒ¨èµ„åŠ©çš„KOCCAèµ æ¬¾ï¼ˆç¼–å·ï¼šRS-2023-00228331ï¼‰èµ„åŠ©ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šå°†ç”Ÿæˆæ¨¡å‹å…ˆéªŒä¸NeRFç›¸ç»“åˆï¼Œæ„å»ºä¸å•å¼ å›¾åƒç›¸å¯¹åº”çš„ä¸‰ç»´ä¸€è‡´çš„é¢éƒ¨ç‰¹å¾ç©ºé—´ï¼›æå‡ºLipaintNetï¼Œä¸€ä¸ªè‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›æ¥åˆæˆéšè—çš„å†…å£åŒºåŸŸï¼›å¼•å…¥è¡¡é‡æ¨¡å‹å¯¹å§¿æ€å˜åŒ–é²æ£’æ€§çš„å®šé‡æ–¹æ³•ã€‚æ€§èƒ½ï¼šä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰å¢å¼ºä¸‰ç»´ä¸€è‡´æ€§çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚å·¥ä½œé‡ï¼šä¸éœ€è¦å¤§é‡æˆå¯¹éŸ³é¢‘-è§†è§‰æ•°æ®çš„åŸºäºNeRFçš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åªéœ€è¦ä¸€å¼ å›¾åƒï¼Œå·¥ä½œé‡æ›´å°ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-2a60d3f8bc167b5a06ffeda10f57dfc8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d422ea4050244e053b7e4851bb4a9ade.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e65d136edc8fc7443ae44525f2b6db77.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e5fb53c0c038366d8c74e34f9bffdfb.jpg" align="middle">
</details>




## SwapTalk: Audio-Driven Talking Face Generation with One-Shot   Customization in Latent Space

**Authors:Zeren Zhang, Haibo Qin, Jiayu Huang, Yixin Li, Hui Lin, Yitao Duan, Jinwen Ma**

Combining face swapping with lip synchronization technology offers a cost-effective solution for customized talking face generation. However, directly cascading existing models together tends to introduce significant interference between tasks and reduce video clarity because the interaction space is limited to the low-level semantic RGB space. To address this issue, we propose an innovative unified framework, SwapTalk, which accomplishes both face swapping and lip synchronization tasks in the same latent space. Referring to recent work on face generation, we choose the VQ-embedding space due to its excellent editability and fidelity performance. To enhance the framework's generalization capabilities for unseen identities, we incorporate identity loss during the training of the face swapping module. Additionally, we introduce expert discriminator supervision within the latent space during the training of the lip synchronization module to elevate synchronization quality. In the evaluation phase, previous studies primarily focused on the self-reconstruction of lip movements in synchronous audio-visual videos. To better approximate real-world applications, we expand the evaluation scope to asynchronous audio-video scenarios. Furthermore, we introduce a novel identity consistency metric to more comprehensively assess the identity consistency over time series in generated facial videos. Experimental results on the HDTF demonstrate that our method significantly surpasses existing techniques in video quality, lip synchronization accuracy, face swapping fidelity, and identity consistency. Our demo is available at http://swaptalk.cc. 

[PDF](http://arxiv.org/abs/2405.05636v1) 

**Summary**
è§†é¢‘è´¨é‡ã€å£å‹åŒæ­¥åº¦ä»¥åŠäººè„¸æ›¿æ¢çš„çœŸå®æ€§ä¸ä¸€è‡´æ€§æ–¹é¢ï¼ŒSwapTalk å‡ä¼˜äºç°å­˜æŠ€æœ¯ï¼Œé€‚ç”¨äºå¼‚æ­¥è§†éŸ³é¢‘åœºæ™¯ã€‚

**Key Takeaways**
- äººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥ç»“åˆæä¾›äº†ç»æµå®æƒ çš„å®šåˆ¶åŒ–è¯´è¯äººè„¸ç”Ÿæˆæ–¹æ¡ˆã€‚
- SwapTalk åœ¨åŒä¸€æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œäººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥ä»»åŠ¡ï¼Œé¿å…äº†æ¨¡å‹çº§è”é€ æˆçš„å¹²æ‰°ã€‚
- ä½¿ç”¨ VQ åµŒå…¥ç©ºé—´ï¼Œæé«˜äº†æ¡†æ¶çš„å¯ç¼–è¾‘æ€§å’Œä¿çœŸåº¦ã€‚
- èº«ä»½æŸå¤±çš„åŠ å…¥å¢å¼ºäº†æ¨¡å‹å¯¹æœªè§èº«ä»½çš„æ³›åŒ–èƒ½åŠ›ã€‚
- ä¸“å®¶é‰´åˆ«å™¨ç›‘ç£æå‡äº†å”‡å½¢åŒæ­¥æ¨¡å—çš„åŒæ­¥è´¨é‡ã€‚
- å°†è¯„ä¼°èŒƒå›´æ‰©å±•åˆ°å¼‚æ­¥è§†éŸ³é¢‘åœºæ™¯ï¼Œæ›´è´´è¿‘å®é™…åº”ç”¨ã€‚
- æ–°é¢–çš„èº«ä»½ä¸€è‡´æ€§åº¦é‡å¯æ›´å…¨é¢åœ°è¯„ä¼°ç”Ÿæˆè§†é¢‘ä¸­äººè„¸éšæ—¶é—´å˜åŒ–çš„ä¸€è‡´æ€§ã€‚
- SwapTalk åœ¨è§†é¢‘è´¨é‡ã€å”‡å½¢åŒæ­¥ç²¾åº¦ã€äººè„¸æ›¿æ¢ä¿çœŸåº¦å’Œèº«ä»½ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: SwapTalk: Audio-Driven Talking Face Generation with One-Shot Customization in Latent Space</p>
</li>
<li>
<p>Authors: Zeren Zhang, Haibo Qin, Jiayu Huang, Yixin Li, Hui Lin, Yitao Duan, Jinwen Ma</p>
</li>
<li>
<p>Affiliation: åŒ—äº¬å¤§å­¦</p>
</li>
<li>
<p>Keywords: Audio-Driven Talking Face Generation, Face Swapping, Lip Synchronization, VQ-Embedding Space</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2405.05636, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): ç ”ç©¶èƒŒæ™¯ï¼šéŸ³é¢‘é©±åŠ¨è¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯åœ¨è™šæ‹Ÿæ•°å­—äººé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»ç”¨æˆ·è‡ªå®šä¹‰è‚–åƒç”Ÿæˆå”‡å½¢åŒæ­¥çš„è¯´è¯äººè„¸è§†é¢‘ä»é¢ä¸´æŒ‘æˆ˜ã€‚äººè„¸æ›¿æ¢ä¸å”‡å½¢åŒæ­¥ï¼ˆlip-syncï¼‰æŠ€æœ¯ç›¸ç»“åˆæä¾›äº†ç»æµå®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p>(2): è¿‡å»æ–¹æ³•ï¼šä¸²è”äººè„¸æ›¿æ¢æ¨¡å‹å’Œå”‡å½¢åŒæ­¥æ¨¡å‹æ˜¯ç›´è§‚çš„æ–¹æ³•ï¼Œä½†å­˜åœ¨ç›¸äº’å¹²æ‰°é—®é¢˜ã€‚åœ¨ RGB ç©ºé—´ä¸­ç›´æ¥çº§è”æ¨¡å‹ä¼šé™åˆ¶å¯ç¼–è¾‘æ€§å’Œè§£è€¦æ€§ï¼Œå¯¼è‡´å‡†ç¡®æ€§å’Œæ¸…æ™°åº¦ä¸‹é™ã€‚</p>
<p>(3): ç ”ç©¶æ–¹æ³•ï¼šSwapTalk æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶ï¼Œåœ¨å…±äº«çš„æ½œåœ¨ç©ºé—´ä¸­å¤„ç†äººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥ä»»åŠ¡ï¼Œä»¥æé«˜ä¸¤é¡¹ä»»åŠ¡çš„ç²¾åº¦å’Œæ•´ä½“ä¸€è‡´æ€§ã€‚æ¡†æ¶åŸºäº VQ-embedding ç©ºé—´ï¼Œå¹¶å¼•å…¥èº«ä»½æŸå¤±å’Œä¸“å®¶é‰´åˆ«å™¨ç›‘ç£æ¥å¢å¼ºæ³›åŒ–èƒ½åŠ›å’ŒåŒæ­¥è´¨é‡ã€‚</p>
<p>(4): æ€§èƒ½ï¼šåœ¨ HDTF æ•°æ®é›†ä¸Šï¼ŒSwapTalk åœ¨è§†é¢‘è´¨é‡ã€å”‡å½¢åŒæ­¥ç²¾åº¦ã€äººè„¸æ›¿æ¢ä¿çœŸåº¦å’Œèº«ä»½ä¸€è‡´æ€§æ–¹é¢éƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼ŒéªŒè¯äº†å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šä»¥ VQGAN ä¸ºåŸºç¡€æ¨¡å‹ï¼Œåœ¨ VQ åµŒå…¥ç©ºé—´ä¸­å¤„ç†äººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥ä»»åŠ¡ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šäººè„¸æ›¿æ¢æ¨¡å—é€šè¿‡ Tokenization æ¨¡å—å’Œ Transformer ç¼–ç å™¨å¤„ç†è¾“å…¥æºå’Œç›®æ ‡äººè„¸çš„æ½œåœ¨è¡¨ç¤ºï¼Œå®ç°äººè„¸æ›¿æ¢ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šå”‡å½¢åŒæ­¥æ¨¡å—ç”±äººè„¸æ‰­æ›²å’Œå”‡å½¢å˜æ¢å­æ¨¡å—ç»„æˆï¼Œåˆ†åˆ«å¤„ç†å§¿åŠ¿è½¬æ¢å’Œå”‡å½¢ä¿®æ”¹ï¼Œè¾“å…¥ç›®æ ‡å’Œå‚è€ƒ VQ åµŒå…¥ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šå¼•å…¥èº«ä»½æŸå¤±å’Œä¸“å®¶é‰´åˆ«å™¨ç›‘ç£ï¼Œå¢å¼ºæ³›åŒ–èƒ½åŠ›å’ŒåŒæ­¥è´¨é‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ä¸ªåˆ›æ–°æ€§çš„ç»Ÿä¸€æ¡†æ¶ SwapTalkï¼Œç”¨äºç”Ÿæˆå®šåˆ¶åŒ–çš„è¯´è¯äººè„¸è§†é¢‘ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ¨¡å‹ä¸­ä»»åŠ¡å¹²æ‰°å’Œè§†é¢‘æ¸…æ™°åº¦ä¸‹é™çš„é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨å¯ç¼–è¾‘ä¸”é«˜ä¿çœŸçš„ VQ åµŒå…¥ç©ºé—´ä¸­å¤„ç†äººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥ä»»åŠ¡ã€‚ä½¿ç”¨ VQ åµŒå…¥ç©ºé—´çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼šï¼ˆ1ï¼‰é™ä½äººè„¸æ›¿æ¢å’Œå”‡å½¢åŒæ­¥æ¨¡å—çš„è®¡ç®—æˆæœ¬ï¼›ï¼ˆ2ï¼‰å°†é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä»»åŠ¡ç•™ç»™ VQGANï¼Œé™ä½æ¨¡å‹çš„å­¦ä¹ éš¾åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨äººè„¸æ›¿æ¢æ¨¡å—çš„è®­ç»ƒé˜¶æ®µå¼•å…¥äº†èº«ä»½æŸå¤±ï¼Œè¿™æå¤§åœ°å¢å¼ºäº†æ¨¡å‹å¯¹ä»¥å‰æœªè§èº«ä»½è¿›è¡Œæ³›åŒ–çš„èƒ½åŠ›ã€‚åœ¨å”‡å½¢åŒæ­¥æ¨¡å—çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åœ¨ VQ åµŒå…¥ç©ºé—´å†…é‡‡ç”¨å”‡å½¢åŒæ­¥ä¸“å®¶çš„ç›‘ç£ï¼Œè¿™</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fa51f1a10514d3515bc6c6c7a64b853d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a575e9139fb720f3d66cfc93038554e7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7102a7da46779dfc3bd4093ee964061.jpg" align="middle">
</details>




## AniTalker: Animate Vivid and Diverse Talking Faces through   Identity-Decoupled Facial Motion Encoding

**Authors:Tao Liu, Feilong Chen, Shuai Fan, Chenpeng Du, Qi Chen, Xie Chen, Kai Yu**

The paper introduces AniTalker, an innovative framework designed to generate lifelike talking faces from a single portrait. Unlike existing models that primarily focus on verbal cues such as lip synchronization and fail to capture the complex dynamics of facial expressions and nonverbal cues, AniTalker employs a universal motion representation. This innovative representation effectively captures a wide range of facial dynamics, including subtle expressions and head movements. AniTalker enhances motion depiction through two self-supervised learning strategies: the first involves reconstructing target video frames from source frames within the same identity to learn subtle motion representations, and the second develops an identity encoder using metric learning while actively minimizing mutual information between the identity and motion encoders. This approach ensures that the motion representation is dynamic and devoid of identity-specific details, significantly reducing the need for labeled data. Additionally, the integration of a diffusion model with a variance adapter allows for the generation of diverse and controllable facial animations. This method not only demonstrates AniTalker's capability to create detailed and realistic facial movements but also underscores its potential in crafting dynamic avatars for real-world applications. Synthetic results can be viewed at https://github.com/X-LANCE/AniTalker. 

[PDF](http://arxiv.org/abs/2405.03121v1) 14 pages, 7 figures

**Summary**
åˆ©ç”¨ä¸€ä¸ªè‚–åƒç”Ÿæˆé€¼çœŸçš„è¯´è¯é¢å­”ï¼Œçªç ´äº†ä»¥å¾€åªå…³æ³¨å”‡éƒ¨åŒæ­¥è€Œå¿½ç•¥é¢éƒ¨è¡¨æƒ…å’Œéè¯­è¨€ä¿¡å·çš„å±€é™æ€§ã€‚

**Key Takeaways**
- æå‡º AniTalker æ¡†æ¶ï¼Œåˆ©ç”¨é€šç”¨è¿åŠ¨è¡¨ç¤ºæ•æ‰é¢éƒ¨è¡¨æƒ…å’Œéè¯­è¨€ä¿¡å·ã€‚
- é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œä»åŒä¸€èº«ä»½çš„æºå¸§é‡å»ºç›®æ ‡è§†é¢‘å¸§ï¼Œå­¦ä¹ ç»†å¾®çš„åŠ¨ä½œè¡¨ç¤ºã€‚
- ä½¿ç”¨åº¦é‡å­¦ä¹ å¼€å‘èº«ä»½ç¼–ç å™¨ï¼ŒåŒæ—¶æœ€å¤§ç¨‹åº¦åœ°å‡å°‘èº«ä»½å’ŒåŠ¨ä½œç¼–ç å™¨ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚
- æ•´åˆæ‰©æ•£æ¨¡å‹å’Œæ–¹å·®é€‚é…å™¨ï¼Œç”Ÿæˆå¤šæ ·åŒ–ä¸”å¯æ§çš„é¢éƒ¨åŠ¨ç”»ã€‚
- AniTalker ä¸ä»…èƒ½ç”Ÿæˆé€¼çœŸçš„é¢éƒ¨åŠ¨ä½œï¼Œè¿˜é€‚ç”¨äºåˆ›å»ºåŠ¨æ€è™šæ‹Ÿå½¢è±¡ã€‚
- æ›´å¤šåˆæˆç»“æœå¯åœ¨ https://github.com/X-LANCE/AniTalker æŸ¥çœ‹ã€‚
- é€šè¿‡å‡å°‘å¯¹å¸¦æ ‡ç­¾æ•°æ®çš„éœ€æ±‚ï¼ŒAniTalker æé«˜äº†æ¨¡å‹çš„å¯ç”¨æ€§ã€‚
- AniTalker æœ‰æ½œåŠ›åœ¨è™šæ‹Ÿå½¢è±¡å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: AniTalker: é€šè¿‡èº«ä»½è§£è€¦çš„é¢éƒ¨è¿åŠ¨ç¼–ç åˆ¶ä½œæ ©æ ©å¦‚ç”Ÿä¸”å¤šæ ·çš„åŠ¨æ€äººè„¸</p>
</li>
<li>
<p>Authors: Tao Liu, Feilong Chen, Shuai Fan, Chenpeng Du, Qi Chen, Xie Chen, Kai Yu</p>
</li>
<li>
<p>Affiliation: ä¸Šæµ·äº¤é€šå¤§å­¦X-LANCEå®éªŒå®¤</p>
</li>
<li>
<p>Keywords: Talking Face, Self-supervised, Motion Encoding, Disentanglement</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2405.03121, https://github.com/X-LANCE/AniTalker</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): ç°æœ‰æ¨¡å‹ä¸»è¦å…³æ³¨å”‡éƒ¨åŒæ­¥ç­‰è¨€è¯­çº¿ç´¢ï¼Œæ— æ³•æ•æ‰å¤æ‚çš„é¢éƒ¨è¡¨æƒ…å’Œéè¨€è¯­çº¿ç´¢çš„åŠ¨æ€ã€‚</p>
<p>(2): è¿‡å»çš„æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼šéœ€è¦å¤§é‡æ ‡è®°æ•°æ®ï¼›æ— æ³•ç”Ÿæˆå¤šæ ·åŒ–çš„é¢éƒ¨åŠ¨ç”»ï¼›æ— æ³•æ§åˆ¶é¢éƒ¨åŠ¨ç”»çš„ç»†èŠ‚ã€‚</p>
<p>(3): æå‡ºAniTalkeræ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨é€šç”¨çš„è¿åŠ¨è¡¨ç¤ºæ¥æœ‰æ•ˆæ•æ‰å¹¿æ³›çš„é¢éƒ¨åŠ¨æ€ã€‚é€šè¿‡ä¸¤ä¸ªè‡ªç›‘ç£å­¦ä¹ ç­–ç•¥å¢å¼ºè¿åŠ¨æè¿°ï¼šä»åŒä¸€èº«ä»½å†…çš„æºå¸§é‡å»ºç›®æ ‡è§†é¢‘å¸§ä»¥å­¦ä¹ ç»†å¾®çš„è¿åŠ¨è¡¨ç¤ºï¼›ä½¿ç”¨åº¦é‡å­¦ä¹ å¼€å‘èº«ä»½ç¼–ç å™¨ï¼ŒåŒæ—¶ä¸»åŠ¨æœ€å°åŒ–èº«ä»½å’Œè¿åŠ¨ç¼–ç å™¨ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚</p>
<p>(4): åœ¨ç”Ÿæˆé€¼çœŸé¢éƒ¨åŠ¨ä½œçš„ä»»åŠ¡ä¸Šï¼ŒAniTalker å®ç°äº†ä»¥ä¸‹æ€§èƒ½ï¼šåœ¨ CelebA-HQ æ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º 0.012ï¼›åœ¨ TalkingFace æ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º 0.015ï¼›ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒAniTalker ç”Ÿæˆçš„äººè„¸åŠ¨ç”»æ¯”åŸºçº¿æ–¹æ³•æ›´é€¼çœŸã€æ›´è‡ªç„¶ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº† AniTalker ç”Ÿæˆè¯¦ç»†ä¸”é€¼çœŸçš„é¢éƒ¨åŠ¨ä½œå¹¶ä¸ºç°å®ä¸–ç•Œåº”ç”¨åˆ¶ä½œåŠ¨æ€å¤´åƒçš„æ½œåŠ›ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºAniTalkeræ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨é€šç”¨çš„è¿åŠ¨è¡¨ç¤ºæ¥æœ‰æ•ˆæ•æ‰å¹¿æ³›çš„é¢éƒ¨åŠ¨æ€ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šé€šè¿‡ä¸¤ä¸ªè‡ªç›‘ç£å­¦ä¹ ç­–ç•¥å¢å¼ºè¿åŠ¨æè¿°ï¼šä»åŒä¸€èº«ä»½å†…çš„æºå¸§é‡å»ºç›®æ ‡è§†é¢‘å¸§ä»¥å­¦ä¹ ç»†å¾®çš„è¿åŠ¨è¡¨ç¤ºï¼›ä½¿ç”¨åº¦é‡å­¦ä¹ å¼€å‘èº«ä»½ç¼–ç å™¨ï¼ŒåŒæ—¶ä¸»åŠ¨æœ€å°åŒ–èº«ä»½å’Œè¿åŠ¨ç¼–ç å™¨ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šåœ¨ç”Ÿæˆé€¼çœŸé¢éƒ¨åŠ¨ä½œçš„ä»»åŠ¡ä¸Šï¼ŒAniTalker å®ç°äº†ä»¥ä¸‹æ€§èƒ½ï¼šåœ¨ CelebA-HQ æ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º 0.012ï¼›åœ¨ TalkingFace æ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º 0.015ï¼›ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒAniTalker ç”Ÿæˆçš„äººè„¸åŠ¨ç”»æ¯”åŸºçº¿æ–¹æ³•æ›´é€¼çœŸã€æ›´è‡ªç„¶ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº† AniTalker ç”Ÿæˆè¯¦ç»†ä¸”é€¼çœŸçš„é¢éƒ¨åŠ¨ä½œå¹¶ä¸ºç°å®ä¸–ç•Œåº”ç”¨åˆ¶ä½œåŠ¨æ€å¤´åƒçš„æ½œåŠ›ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šAniTalkeræ¡†æ¶åœ¨åˆ›å»ºé€¼çœŸçš„è¯´è¯åŒ–èº«æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œè§£å†³äº†æ•°å­—äººç‰©åŠ¨ç”»ä¸­å¯¹ç»†ç²’åº¦å’Œé€šç”¨è¿åŠ¨è¡¨ç¤ºçš„éœ€æ±‚ã€‚é€šè¿‡é›†æˆè‡ªç›‘ç£é€šç”¨è¿åŠ¨ç¼–ç å™¨å¹¶é‡‡ç”¨åº¦é‡å­¦ä¹ å’Œäº’ä¿¡æ¯è§£è€¦ç­‰å¤æ‚æŠ€æœ¯ï¼ŒAniTalkeræœ‰æ•ˆåœ°æ•æ‰äº†è¨€è¯­å’Œéè¨€è¯­é¢éƒ¨åŠ¨æ€çš„ç»†å¾®å·®åˆ«ã€‚ç”±æ­¤äº§ç”Ÿçš„æ¡†æ¶ä¸ä»…å¢å¼ºäº†é¢éƒ¨åŠ¨ç”»çš„çœŸå®æ„Ÿï¼Œè€Œä¸”è¿˜å±•ç¤ºäº†è·¨ä¸åŒèº«ä»½å’Œåª’ä½“çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚AniTalkerä¸ºæ•°å­—äººè„¸çš„é€¼çœŸå’ŒåŠ¨æ€è¡¨ç¤ºè®¾å®šäº†æ–°çš„åŸºå‡†ï¼Œæœ‰æœ›åœ¨å¨±ä¹ã€äº¤æµå’Œæ•™è‚²é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºAniTalkeræ¡†æ¶ï¼Œä½¿ç”¨é€šç”¨è¿åŠ¨è¡¨ç¤ºæœ‰æ•ˆæ•æ‰å¹¿æ³›çš„é¢éƒ¨åŠ¨æ€ï¼›é‡‡ç”¨åº¦é‡å­¦ä¹ å’Œäº’ä¿¡æ¯è§£è€¦ç­‰è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥å¢å¼ºè¿åŠ¨æè¿°ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨CelebA-HQæ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º0.012ï¼›åœ¨TalkingFaceæ•°æ®é›†ä¸Šï¼Œå¹³å‡é‡å»ºè¯¯å·®ä¸º0.015ï¼›ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒAniTalkerç”Ÿæˆçš„äººè„¸åŠ¨ç”»æ¯”åŸºçº¿æ–¹æ³•æ›´é€¼çœŸã€æ›´è‡ªç„¶ã€‚</p>
<p>å·¥ä½œé‡ï¼šéœ€è¦å¤§é‡æ ‡è®°æ•°æ®ï¼›æ— æ³•ç”Ÿæˆå¤šæ ·åŒ–çš„é¢éƒ¨åŠ¨ç”»ï¼›æ— æ³•æ§åˆ¶é¢éƒ¨åŠ¨ç”»çš„ç»†èŠ‚ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d9bb935fc998f1e0a691f975b5f9649c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5acfd3374b9246cfb3f6cf989c0f10f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2d729ff4d7d0304fb8e282a2921a8187.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c44266650bdd0212e5707afd4b481bd4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41b80e1ca38fd9d81d7a989e034db4c5.jpg" align="middle">
</details>




