
---
title: å…ƒå®‡å®™/è™šæ‹Ÿäºº
date: 2024-10-07 19:15:31
author: Kedreamix
cover: 
categories: Paper
tags:
    - å…ƒå®‡å®™/è™šæ‹Ÿäºº
description: å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-10-07  EgoAvatar Egocentric View-Driven and Photorealistic Full-body Avatars  
keywords: å…ƒå®‡å®™/è™šæ‹Ÿäºº
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-10-07 æ›´æ–°


## EgoAvatar: Egocentric View-Driven and Photorealistic Full-body Avatars

**Authors:Jianchun Chen, Jian Wang, Yinda Zhang, Rohit Pandey, Thabo Beeler, Marc Habermann, Christian Theobalt**

Immersive VR telepresence ideally means being able to interact and communicate with digital avatars that are indistinguishable from and precisely reflect the behaviour of their real counterparts. The core technical challenge is two fold: Creating a digital double that faithfully reflects the real human and tracking the real human solely from egocentric sensing devices that are lightweight and have a low energy consumption, e.g. a single RGB camera. Up to date, no unified solution to this problem exists as recent works solely focus on egocentric motion capture, only model the head, or build avatars from multi-view captures. In this work, we, for the first time in literature, propose a person-specific egocentric telepresence approach, which jointly models the photoreal digital avatar while also driving it from a single egocentric video. We first present a character model that is animatible, i.e. can be solely driven by skeletal motion, while being capable of modeling geometry and appearance. Then, we introduce a personalized egocentric motion capture component, which recovers full-body motion from an egocentric video. Finally, we apply the recovered pose to our character model and perform a test-time mesh refinement such that the geometry faithfully projects onto the egocentric view. To validate our design choices, we propose a new and challenging benchmark, which provides paired egocentric and dense multi-view videos of real humans performing various motions. Our experiments demonstrate a clear step towards egocentric and photoreal telepresence as our method outperforms baselines as well as competing methods. For more details, code, and data, we refer to our project page. 

[PDF](http://arxiv.org/abs/2410.01835v1) 

**Summary**
è¯¥ç ”ç©¶é¦–æ¬¡æå‡ºä¸€ç§ä¸ªæ€§åŒ–è‡ªè§†è§’è¿œç¨‹å‘ˆç°æ–¹æ³•ï¼Œé€šè¿‡å•ä¸€è‡ªè§†è§’è§†é¢‘åŒæ—¶å»ºæ¨¡å’Œé©±åŠ¨é€¼çœŸçš„æ•°å­—è™šæ‹Ÿäººã€‚

**Key Takeaways**
1. ç ”ç©¶èšç„¦äºåˆ›å»ºä¸çœŸäººè¡Œä¸ºä¸€è‡´çš„æ•°å­—å­ªç”Ÿè™šæ‹Ÿäººã€‚
2. æŠ€æœ¯æŒ‘æˆ˜åŒ…æ‹¬åˆ›å»ºç²¾ç¡®çš„æ•°å­—åŒèƒèƒå’Œè½»é‡çº§ä½èƒ½è€—çš„è·Ÿè¸ªè®¾å¤‡ã€‚
3. ç›®å‰ç¼ºä¹ç»Ÿä¸€è§£å†³æ–¹æ¡ˆï¼Œç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨å¤´éƒ¨æ•æ‰æˆ–å¤šè§†è§’æ•æ‰ã€‚
4. é¦–æ¬¡æå‡ºåŸºäºä¸ªæ€§åŒ–è‡ªè§†è§’çš„è¿œç¨‹å‘ˆç°æ–¹æ³•ã€‚
5. æå‡ºå¯ç”±éª¨éª¼åŠ¨ä½œé©±åŠ¨çš„åŠ¨ç”»æ¨¡å‹ï¼ŒåŒæ—¶å»ºæ¨¡å‡ ä½•å’Œå¤–è§‚ã€‚
6. å¼•å…¥ä¸ªæ€§åŒ–è‡ªè§†è§’åŠ¨ä½œæ•æ‰ç»„ä»¶ï¼Œä»å•è§†è§’è§†é¢‘æ¢å¤å…¨èº«è¿åŠ¨ã€‚
7. é€šè¿‡æµ‹è¯•æ—¶ç½‘æ ¼ç»†åŒ–ï¼Œç¡®ä¿å‡ ä½•å½¢çŠ¶å¿ å®æ˜ å°„åˆ°è‡ªè§†è§’è§†å›¾ã€‚
8. æå‡ºæ–°çš„åŸºå‡†ï¼Œæä¾›é…å¯¹çš„è‡ªè§†è§’å’Œå¯†é›†å¤šè§†è§’è§†é¢‘è¿›è¡ŒéªŒè¯ã€‚
9. æ–¹æ³•ä¼˜äºåŸºçº¿åŠç«äº‰æ–¹æ³•ï¼Œå‘è‡ªè§†è§’å’Œé€¼çœŸè¿œç¨‹å‘ˆç°è¿ˆè¿›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**


7. æ–¹æ³•è®ºï¼š

(1) ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºè‡ªæˆ‘è§†è§’çš„è§†é¢‘é©±åŠ¨è™šæ‹Ÿå½¢è±¡ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡è‡ªæˆ‘è§†è§’çš„è§†é¢‘è¾“å…¥æ¥é©±åŠ¨è™šæ‹Ÿè§’è‰²çš„åŠ¨ä½œå’Œè¡¨æƒ…ã€‚

(2) æ–¹æ³•é¦–å…ˆè¿›è¡Œå§¿æ€é¢„æµ‹çš„ä¸ªäººåŒ–è°ƒæ•´ï¼ˆPersonalization of Pose Predictionï¼‰ã€‚é€šè¿‡å¯¹ç‰¹å®šä¸ªä½“çš„æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œæé«˜æµ‹è¯•æ—¶çš„å‡†ç¡®æ€§ã€‚

(3) æ¥ç€ï¼Œç ”ç©¶å¼•å…¥äº†IKSolverä¸­çš„æ­£åˆ™åŒ–é¡¹ERegã€‚è¯¥æ­£åˆ™åŒ–é¡¹ä½¿ç”¨å¹³å‡è¿åŠ¨Â¯ğœ½ä½œä¸ºç®€å•çš„è¿åŠ¨å…ˆéªŒï¼Œæœ‰æ•ˆæé«˜äº†è¿åŠ¨è·Ÿè¸ªçš„å‡†ç¡®æ€§ã€‚

(4) ä¸ºäº†å¤„ç†å¤æ‚çš„æœè£…å˜å½¢ï¼Œç ”ç©¶å¼•å…¥äº†MotionDeformerå’ŒEgoDeformerä¸¤ä¸ªæ¨¡å—ã€‚è¿™ä¸¤ä¸ªæ¨¡å—èƒ½å¤Ÿé¢„æµ‹åˆç†çš„æœè£…åŠ¨ç”»ç»“æœï¼Œç”šè‡³åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„èº«ä½“ç§»åŠ¨ä¸‹ä¹Ÿèƒ½ä¿æŒæ•ˆæœã€‚

(5) ç ”ç©¶è¿˜è¿›è¡Œäº†é²æ£’æ€§æµ‹è¯•ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨ä¸åŒç…§æ˜æ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§ã€‚åœ¨æˆ·å¤–åœºæ™¯ä¸­ï¼Œå°½ç®¡ç…§æ˜æ¡ä»¶ä¸è®­ç»ƒæ•°æ®å·®å¼‚æ˜¾è‘—ï¼Œä½†ä¼°è®¡çš„å§¿æ€å’Œæ¸²æŸ“è´¨é‡ä»ç„¶è¡¨ç°è‰¯å¥½ã€‚

ä»¥ä¸Šå³ä¸ºè¯¥ç ”ç©¶çš„æ ¸å¿ƒæ–¹æ³•è®ºæ€è·¯ã€‚
8. Conclusion:

(1) å·¥ä½œæ„ä¹‰ï¼šè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè‡ªæˆ‘è§†è§’çš„è§†é¢‘é©±åŠ¨è™šæ‹Ÿå½¢è±¡ç”Ÿæˆæ–¹æ³•ï¼Œå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå®æ—¶ç”Ÿæˆé€¼çœŸçš„å…¨èº«è™šæ‹Ÿå½¢è±¡ï¼Œä¸ºè¿œç¨‹æ²‰æµ¸ä½“éªŒã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸçš„åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒï¼Œå¦‚åœ¨çº¿æ•™å­¦ã€ç”µå½±åˆ¶ä½œå’Œæ¸¸æˆç­‰ã€‚

(2) ä¼˜ç¼ºç‚¹åˆ†æï¼š

     - åˆ›æ–°ç‚¹ï¼šè¯¥ç ”ç©¶åœ¨åˆ›æ–°ç‚¹æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å®ƒå¼•å…¥äº†ä¸€ç§ä¸ªæ€§åŒ–çš„å§¿æ€é¢„æµ‹è°ƒæ•´æ–¹æ³•ï¼Œæé«˜äº†æµ‹è¯•å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†æ­£åˆ™åŒ–é¡¹ERegã€MotionDeformerå’ŒEgoDeformerç­‰æ¨¡å—ï¼Œæœ‰æ•ˆæé«˜äº†è¿åŠ¨è·Ÿè¸ªçš„å‡†ç¡®æ€§å’Œå¤„ç†å¤æ‚æœè£…å˜å½¢çš„èƒ½åŠ›ã€‚
     
     - æ€§èƒ½ï¼šè¯¥æ–‡ç« åœ¨æ€§èƒ½æ–¹é¢è¡¨ç°è‰¯å¥½ã€‚ç ”ç©¶éªŒè¯äº†è¯¥æ–¹æ³•åœ¨ä¸åŒç…§æ˜æ¡ä»¶ä¸‹çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”åœ¨æˆ·å¤–åœºæ™¯ä¸­ï¼Œå³ä½¿ç…§æ˜æ¡ä»¶ä¸è®­ç»ƒæ•°æ®å·®å¼‚æ˜¾è‘—ï¼Œä¼°è®¡çš„å§¿æ€å’Œæ¸²æŸ“è´¨é‡ä»ç„¶è¡¨ç°è‰¯å¥½ã€‚
     
     - å·¥ä½œé‡ï¼šä»æ–‡ç« æè¿°æ¥çœ‹ï¼Œè¯¥ç ”ç©¶å·¥ä½œé‡å¤§ï¼Œæ¶‰åŠå¤šä¸ªæ¨¡å—çš„è®¾è®¡å’Œå®ç°ï¼Œä»¥åŠå¤§é‡çš„å®éªŒéªŒè¯å’Œæ€§èƒ½æµ‹è¯•ã€‚

ä»¥ä¸Šæ˜¯å¯¹è¯¥æ–‡ç« çš„æ€»ç»“å’Œåˆ†æï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="http://article.biliimg.com/bfs/new_dyn/6654ccfa71018884181f857eea6a0629241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/2aca4cd5df0d0b4b13be2e77ac909391241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/3c6f0e51cfd9c66af35abd86a7aa2fba241286257.jpg" align="middle">
</details>




## Towards Native Generative Model for 3D Head Avatar

**Authors:Yiyu Zhuang, Yuxiao He, Jiawei Zhang, Yanwen Wang, Jiahe Zhu, Yao Yao, Siyu Zhu, Xun Cao, Hao Zhu**

Creating 3D head avatars is a significant yet challenging task for many applicated scenarios. Previous studies have set out to learn 3D human head generative models using massive 2D image data. Although these models are highly generalizable for human appearance, their result models are not 360$^\circ$-renderable, and the predicted 3D geometry is unreliable. Therefore, such results cannot be used in VR, game modeling, and other scenarios that require 360$^\circ$-renderable 3D head models. An intuitive idea is that 3D head models with limited amount but high 3D accuracy are more reliable training data for a high-quality 3D generative model. In this vein, we delve into how to learn a native generative model for 360$^\circ$ full head from a limited 3D head dataset. Specifically, three major problems are studied: 1) how to effectively utilize various representations for generating the 360$^\circ$-renderable human head; 2) how to disentangle the appearance, shape, and motion of human faces to generate a 3D head model that can be edited by appearance and driven by motion; 3) and how to extend the generalization capability of the generative model to support downstream tasks. Comprehensive experiments are conducted to verify the effectiveness of the proposed model. We hope the proposed models and artist-designed dataset can inspire future research on learning native generative 3D head models from limited 3D datasets. 

[PDF](http://arxiv.org/abs/2410.01226v1) 

**Summary**
3Då¤´åƒç”Ÿæˆæ¨¡å‹ç ”ç©¶ï¼šä»æœ‰é™3Dæ•°æ®é›†å­¦ä¹ 360åº¦å…¨å¤´åƒç”Ÿæˆã€‚

**Key Takeaways**
1. 2Då›¾åƒæ•°æ®ç”Ÿæˆçš„3Då¤´åƒæ¨¡å‹éš¾ä»¥360åº¦æ¸²æŸ“ã€‚
2. é«˜ç²¾åº¦3Dæ¨¡å‹æ˜¯é«˜è´¨é‡ç”Ÿæˆæ¨¡å‹æ›´å¯é çš„è®­ç»ƒæ•°æ®ã€‚
3. ç ”ç©¶å¦‚ä½•ä»æœ‰é™3Dæ•°æ®é›†å­¦ä¹ 360åº¦å…¨å¤´åƒç”Ÿæˆæ¨¡å‹ã€‚
4. è§£å†³å¦‚ä½•æœ‰æ•ˆç”Ÿæˆ360åº¦å¯æ¸²æŸ“çš„äººå¤´é—®é¢˜ã€‚
5. å¦‚ä½•åˆ†ç¦»äººè„¸çš„å¤–è§‚ã€å½¢çŠ¶å’Œè¿åŠ¨ï¼Œä»¥ç¼–è¾‘3Då¤´åƒæ¨¡å‹ã€‚
6. å¦‚ä½•æ‰©å±•ç”Ÿæˆæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»¥æ”¯æŒä¸‹æ¸¸ä»»åŠ¡ã€‚
7. æå‡ºçš„æ¨¡å‹å’Œè‰ºæœ¯å®¶è®¾è®¡çš„æ•°æ®é›†æœ‰æœ›æ¿€å‘æœªæ¥ç ”ç©¶ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. Title: é¢å‘æœ‰é™æ•°æ®é›†çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹ç ”ç©¶ï¼ˆTowards Native Generative Model for 3D Head Avatarï¼‰

2. Authors: Yiyu Zhuang, Yuxiao He, Jiawei Zhang, Yanwen Wang, Jiahe Zhu, Yao Yao, Siyu Zhu, Xun Cao, Hao Zhuç­‰ã€‚

3. Affiliation: å—äº¬å¤§å­¦æ•™æˆï¼ˆProfessor from Nanjing Universityï¼‰ã€‚

4. Keywords: ä¸‰ç»´å¤´éƒ¨æ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ï¼Œå›¾åƒæ‹Ÿåˆï¼Œæ–‡æœ¬ç¼–è¾‘ï¼Œé¢éƒ¨åŠ¨ç”»ç­‰ï¼ˆ3D head model, generative model, image-based fitting, text-based editing, facial animationï¼‰ã€‚

5. Urls: æ–‡ç« é“¾æ¥ï¼ˆå…·ä½“é“¾æ¥éœ€æ ¹æ®å®é™…æƒ…å†µå¡«å†™ï¼‰ï¼ŒGitHubä»£ç é“¾æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå¦åˆ™å¡«å†™GitHub:Noneï¼‰ã€‚

6. Summary: 

    - (1) ç ”ç©¶èƒŒæ™¯ï¼šæœ¬æ–‡ç ”ç©¶äº†åœ¨æœ‰é™çš„ä¸‰ç»´å¤´éƒ¨æ•°æ®é›†ä¸Šå­¦ä¹ åŸç”Ÿç”Ÿæˆæ¨¡å‹çš„é—®é¢˜ã€‚éšç€è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦çš„å‘å±•ï¼Œåˆ›å»ºä¸‰ç»´å¤´éƒ¨æ¨¡å‹åœ¨è®¸å¤šé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼Œå¦‚ç”µå½±åˆ¶ä½œã€æ•°å­—åŒ–èº«ç­‰ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ä¸‰ç»´å¤´éƒ¨å»ºæ¨¡æ–¹æ³•æˆæœ¬é«˜ä¸”éœ€è¦å¤§é‡æ‰‹åŠ¨å¤„ç†ï¼Œå› æ­¤å¯»æ±‚ä¸€ç§ç»æµæœ‰æ•ˆçš„å»ºæ¨¡æ–¹æ³•æˆä¸ºäº†ä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘ä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„åŸç”Ÿç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ã€‚
    
    - (2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•ä¸»è¦åˆ†ä¸ºåŸºäºäºŒç»´å›¾åƒçš„æ–¹æ³•å’ŒåŸºäºä¸‰ç»´æ•°æ®çš„æ–¹æ³•ã€‚è™½ç„¶åŸºäºäºŒç»´å›¾åƒçš„æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†å®ƒä»¬ç”Ÿæˆçš„æ¨¡å‹æ— æ³•åšåˆ°å…¨æ–¹ä½çš„æ¸²æŸ“ï¼Œé¢„æµ‹çš„ä¸‰ç»´å‡ ä½•ç»“æ„ä¹Ÿä¸å¯é ã€‚å› æ­¤ï¼Œè¿™äº›æ–¹æ³•æ— æ³•åº”ç”¨äºéœ€è¦å…¨æ–¹ä½æ¸²æŸ“çš„ä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„åœºæ™¯ï¼Œå¦‚è™šæ‹Ÿç°å®ã€æ¸¸æˆå»ºæ¨¡ç­‰ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³åœ¨æœ‰é™çš„ä¸‰ç»´å¤´éƒ¨æ•°æ®é›†ä¸Šå­¦ä¹ é«˜è´¨é‡çš„ä¸‰ç»´ç”Ÿæˆæ¨¡å‹çš„é—®é¢˜ã€‚
    
    - (3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé¢å‘å…¨æ–¹ä½çš„ä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ã€‚ä¸»è¦ç ”ç©¶äº†ä¸‰ä¸ªå…³é”®é—®é¢˜ï¼šä¸€æ˜¯å¦‚ä½•åˆ©ç”¨å„ç§è¡¨ç¤ºæ³•ç”Ÿæˆå…¨æ–¹ä½å¯æ¸²æŸ“çš„ä¸‰ç»´å¤´éƒ¨ï¼›äºŒæ˜¯å¦‚ä½•è§£è€¦äººè„¸çš„å¤–è§‚ã€å½¢çŠ¶å’Œè¿åŠ¨ä»¥ç”Ÿæˆèƒ½å¤Ÿè¢«ç¼–è¾‘å’Œé©±åŠ¨çš„æ¨¡å‹ï¼›ä¸‰æ˜¯å¦‚ä½•æ‰©å±•ç”Ÿæˆæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»¥æ”¯æŒä¸‹æ¸¸ä»»åŠ¡ã€‚æœ¬æ–‡è®¾è®¡äº†ä¸€ç§æ–°å‹çš„æ¨¡å‹ç»“æ„å’Œæ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚
    
    - (4) ä»»åŠ¡ä¸æ€§èƒ½ï¼šæœ¬æ–‡çš„å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚æ‰€æå‡ºçš„æ–¹æ³•å’Œè‰ºæœ¯å®¶è®¾è®¡çš„æ•°æ®é›†ä¸ºä»æœ‰é™çš„ä¸‰ç»´æ•°æ®é›†å­¦ä¹ åŸç”Ÿç”Ÿæˆä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„ç ”ç©¶æä¾›äº†çµæ„Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æœ‰é™çš„è®­ç»ƒæ•°æ®ä¸‹ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿå’Œå…¨æ–¹ä½æ¸²æŸ“èƒ½åŠ›çš„ä¸‰ç»´å¤´éƒ¨æ¨¡å‹ï¼ŒåŒæ—¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½å’Œåº”ç”¨æ•ˆæœã€‚å®éªŒç»“æœæ”¯æŒæ–‡ç« çš„ç›®æ ‡ï¼Œå³é€šè¿‡å¼•å…¥ä¸€ç§æ–°çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹æ–¹æ³•ï¼Œå®ç°æ›´é«˜æ•ˆå’Œç»æµçš„äººè„¸å»ºæ¨¡ã€‚
7. æ–¹æ³•è®ºæ¦‚è¿°ï¼š

æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘ä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„åŸç”Ÿç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š

    - (1) ç ”ç©¶èƒŒæ™¯ä¸é—®é¢˜å®šä¹‰ï¼šæ–‡ç« é¦–å…ˆä»‹ç»äº†ç ”ç©¶èƒŒæ™¯ï¼ŒæŒ‡å‡ºäº†ä¼ ç»Ÿä¸‰ç»´å¤´éƒ¨å»ºæ¨¡æ–¹æ³•çš„é«˜æˆæœ¬å’Œå¤§æ‰‹åŠ¨å¤„ç†éœ€æ±‚ï¼Œä»è€Œæå‡ºç ”ç©¶é—®é¢˜ï¼Œå³åœ¨æœ‰é™çš„ä¸‰ç»´å¤´éƒ¨æ•°æ®é›†ä¸Šå­¦ä¹ é«˜è´¨é‡çš„ä¸‰ç»´ç”Ÿæˆæ¨¡å‹ã€‚
    
    - (2) æ•°æ®é›†ä¸æ¨¡å‹æ„å»ºï¼šæ–‡ç« ä½¿ç”¨äº†ç‰¹å®šæ•°æ®é›†è¿›è¡Œç ”ç©¶ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°å‹çš„æ¨¡å‹ç»“æ„æ¥è§£å†³æ‰€æå‡ºçš„é—®é¢˜ã€‚è¯¥æ¨¡å‹ç»“æ„è€ƒè™‘äº†å¦‚ä½•åˆ©ç”¨å„ç§è¡¨ç¤ºæ³•ç”Ÿæˆå…¨æ–¹ä½å¯æ¸²æŸ“çš„ä¸‰ç»´å¤´éƒ¨ã€å¦‚ä½•è§£è€¦äººè„¸çš„å¤–è§‚ã€å½¢çŠ¶å’Œè¿åŠ¨ä»¥ç”Ÿæˆèƒ½å¤Ÿè¢«ç¼–è¾‘å’Œé©±åŠ¨çš„æ¨¡å‹ä»¥åŠå¦‚ä½•æ‰©å±•ç”Ÿæˆæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»¥æ”¯æŒä¸‹æ¸¸ä»»åŠ¡ç­‰å…³é”®é—®é¢˜ã€‚
    
    - (3) å®éªŒè®¾è®¡ä¸å®ç°ï¼šæ–‡ç« é€šè¿‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚PSNRã€SSIMã€LPIPSç­‰ï¼‰æ¥å®šé‡è¯„ä¼°ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜ä»‹ç»äº†æ¨¡å‹çš„æ‹Ÿåˆæ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºæ··åˆæ–¹æ³•ã€åŸºäºç‚¹çš„æ–¹æ³•å’Œä¼˜åŒ–è¿‡ç¨‹ç­‰ã€‚è¿™äº›æ–¹æ³•è€ƒè™‘äº†å¦‚ä½•é€‚åº”ä¸åŒæ•°æ®é›†ã€å¦‚ä½•å¤„ç†ç›®æ ‡å›¾åƒä¸åˆæˆæ•°æ®ä¹‹é—´çš„å·®å¼‚ç­‰é—®é¢˜ã€‚
    
    - (4) åŠ¨ç”»ä¸è¯„ä¼°ï¼šç”Ÿæˆçš„æˆ–æ‹Ÿåˆçš„å¤´éƒ¨å¯ä»¥é€šè¿‡æ ‡å‡†52é¢éƒ¨blendshapesè¿›è¡Œç›´æ¥åŠ¨ç”»å¤„ç†ã€‚æ–‡ç« è¿˜é€šè¿‡å®šé‡è¯„ä¼°ç»“æœè¡¨ï¼ˆå¦‚è¡¨æ ¼IVå’ŒVï¼‰å±•ç¤ºäº†ä¸åŒæ–¹æ³•çš„æ€§èƒ½å·®å¼‚ã€‚è¿™äº›è¯„ä¼°ç»“æœè¯æ˜äº†æ‰€æå‡ºæ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿå’Œå…¨æ–¹ä½æ¸²æŸ“èƒ½åŠ›çš„ä¸‰ç»´å¤´éƒ¨æ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

æ•´ä½“è€Œè¨€ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘æœ‰é™æ•°æ®é›†çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡è®¾è®¡æ–°å‹æ¨¡å‹ç»“æ„å’Œå®éªŒæ–¹æ³•ï¼Œå®ç°äº†é«˜æ•ˆå’Œç»æµçš„äººè„¸å»ºæ¨¡ã€‚
8. Conclusion:

- (1) è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ç§é¢å‘æœ‰é™æ•°æ®é›†çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³äº†ä¼ ç»Ÿä¸‰ç»´å¤´éƒ¨å»ºæ¨¡æ–¹æ³•æˆæœ¬é«˜ã€éœ€è¦å¤§é‡æ‰‹åŠ¨å¤„ç†çš„é—®é¢˜ï¼Œä¸ºç”µå½±åˆ¶ä½œã€æ•°å­—åŒ–èº«ç­‰é¢†åŸŸæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ç»æµçš„å»ºæ¨¡æ–¹æ³•ã€‚
- (2) åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³äº†åœ¨æœ‰é™çš„ä¸‰ç»´å¤´éƒ¨æ•°æ®é›†ä¸Šå­¦ä¹ é«˜è´¨é‡çš„ä¸‰ç»´ç”Ÿæˆæ¨¡å‹çš„é—®é¢˜ï¼Œå¹¶è®¾è®¡äº†é’ˆå¯¹å…¨æ–¹ä½ä¸‰ç»´å¤´éƒ¨æ¨¡å‹çš„ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³äº†å¦‚ä½•åˆ©ç”¨å„ç§è¡¨ç¤ºæ³•ç”Ÿæˆå…¨æ–¹ä½å¯æ¸²æŸ“çš„ä¸‰ç»´å¤´éƒ¨ã€å¦‚ä½•è§£è€¦äººè„¸çš„å¤–è§‚ã€å½¢çŠ¶å’Œè¿åŠ¨ä»¥åŠå¦‚ä½•æ‰©å±•ç”Ÿæˆæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ç­‰å…³é”®é—®é¢˜ã€‚
- æ€§èƒ½ï¼šè¯¥æ–‡ç« æ‰€æå‡ºçš„æ–¹æ³•å’Œè®¾è®¡å¸ˆçš„æ•°æ®é›†å®éªŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿå’Œå…¨æ–¹ä½æ¸²æŸ“èƒ½åŠ›çš„ä¸‰ç»´å¤´éƒ¨æ¨¡å‹ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§èƒ½å’Œåº”ç”¨æ•ˆæœã€‚
- å·¥ä½œé‡ï¼šæ–‡ç« è¿›è¡Œäº†å¤§é‡çš„å®éªŒå’Œæ¨¡å‹è®¾è®¡ï¼ŒåŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ¨¡å‹ç»“æ„çš„è®¾è®¡ã€å®éªŒæ–¹æ³•çš„æ¢ç´¢ç­‰ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚

æ€»ä½“æ¥è¯´ï¼Œè¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§é¢å‘æœ‰é™æ•°æ®é›†çš„ä¸‰ç»´å¤´éƒ¨ç”Ÿæˆæ¨¡å‹å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡è®¾è®¡æ–°å‹æ¨¡å‹ç»“æ„å’Œå®éªŒæ–¹æ³•ï¼Œå®ç°äº†é«˜æ•ˆå’Œç»æµçš„äººè„¸å»ºæ¨¡ï¼Œå¯¹äºç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨å…·æœ‰ä¸€å®šçš„æ¨åŠ¨ä½œç”¨ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="http://article.biliimg.com/bfs/new_dyn/2b71abe1df110df40ccd43476cc4a065241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/3ac3c264593382fa80ebf9db5cf1ec99241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/f8bde6c79530a404dbb2eaaa2de76cea241286257.jpg" align="middle">
</details>




## Subjective and Objective Quality Assessment of Rendered Human Avatar   Videos in Virtual Reality

**Authors:Yu-Chih Chen, Avinab Saha, Alexandre Chapiro, Christian HÃ¤ne, Jean-Charles Bazin, Bo Qiu, Stefano Zanetti, Ioannis Katsavounidis, Alan C. Bovik**

We study the visual quality judgments of human subjects on digital human avatars (sometimes referred to as "holograms" in the parlance of virtual reality [VR] and augmented reality [AR] systems) that have been subjected to distortions. We also study the ability of video quality models to predict human judgments. As streaming human avatar videos in VR or AR become increasingly common, the need for more advanced human avatar video compression protocols will be required to address the tradeoffs between faithfully transmitting high-quality visual representations while adjusting to changeable bandwidth scenarios. During transmission over the internet, the perceived quality of compressed human avatar videos can be severely impaired by visual artifacts. To optimize trade-offs between perceptual quality and data volume in practical workflows, video quality assessment (VQA) models are essential tools. However, there are very few VQA algorithms developed specifically to analyze human body avatar videos, due, at least in part, to the dearth of appropriate and comprehensive datasets of adequate size. Towards filling this gap, we introduce the LIVE-Meta Rendered Human Avatar VQA Database, which contains 720 human avatar videos processed using 20 different combinations of encoding parameters, labeled by corresponding human perceptual quality judgments that were collected in six degrees of freedom VR headsets. To demonstrate the usefulness of this new and unique video resource, we use it to study and compare the performances of a variety of state-of-the-art Full Reference and No Reference video quality prediction models, including a new model called HoloQA. As a service to the research community, we publicly releases the metadata of the new database at https://live.ece.utexas.edu/research/LIVE-Meta-rendered-human-avatar/index.html. 

[PDF](http://arxiv.org/abs/2408.07041v2) Accepted to IEEE Transactions on Image Processing, 2024

**Summary**
ç ”ç©¶äººç±»å¯¹æ‰­æ›²åçš„æ•°å­—äººå¶è§†è§‰è´¨é‡åˆ¤æ–­ï¼Œå¹¶è¯„ä¼°è§†é¢‘è´¨é‡æ¨¡å‹é¢„æµ‹äººç±»åˆ¤æ–­çš„èƒ½åŠ›ã€‚

**Key Takeaways**
1. ç ”ç©¶å¯¹è±¡ä¸ºVR/ARç³»ç»Ÿä¸­çš„æ•°å­—äººå¶è§†è§‰è´¨é‡åˆ¤æ–­ã€‚
2. è¯„ä¼°è§†é¢‘è´¨é‡æ¨¡å‹å¯¹äººç±»åˆ¤æ–­çš„é¢„æµ‹èƒ½åŠ›ã€‚
3. éœ€è¦æ›´å…ˆè¿›çš„è§†é¢‘å‹ç¼©åè®®æ¥å¹³è¡¡é«˜è§†è§‰è´¨é‡å’Œå¯å˜å¸¦å®½ã€‚
4. å‹ç¼©è§†é¢‘çš„ä¼ è¾“è¿‡ç¨‹ä¸­ï¼Œè§†è§‰è´¨é‡å¯èƒ½å—åˆ°ä¸¥é‡æŸå®³ã€‚
5. è§†é¢‘è´¨é‡è¯„ä¼°æ¨¡å‹å¯¹ä¼˜åŒ–æ„ŸçŸ¥è´¨é‡å’Œæ•°æ®é‡è‡³å…³é‡è¦ã€‚
6. ç¼ºä¹é’ˆå¯¹äººä½“avatarè§†é¢‘çš„VQAç®—æ³•å’Œç»¼åˆæ•°æ®é›†ã€‚
7. å¼•å…¥LIVE-Meta Rendered Human Avatar VQAæ•°æ®åº“ä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚
8. ä½¿ç”¨æ•°æ®åº“ç ”ç©¶å¹¶æ¯”è¾ƒäº†å¤šç§è§†é¢‘è´¨é‡é¢„æµ‹æ¨¡å‹ã€‚
9. å…¬å¼€å‘å¸ƒæ•°æ®åº“çš„å…ƒæ•°æ®ï¼Œä»¥æœåŠ¡ç ”ç©¶ç¤¾åŒºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**


8. Conclusion:

(1) æ­¤ä½œå“çš„æ„ä¹‰åœ¨äºxxxï¼ˆæ ¹æ®æ–‡ç« å†…å®¹å¡«å†™å…·ä½“çš„æ„ä¹‰ï¼Œå¦‚æ¢è®¨æŸä¸€æ–‡å­¦ä¸»é¢˜ã€åæ˜ æŸä¸€ç¤¾ä¼šç°è±¡ç­‰ï¼‰ã€‚

(2) Innovation point: æœ¬æ–‡åœ¨åˆ›æ–°ç‚¹æ–¹é¢çš„è¡¨ç°å¯æ¦‚æ‹¬ä¸ºxxxï¼ˆå¦‚é‡‡ç”¨æ–°çš„æ–‡å­¦æ‰‹æ³•ã€æå‡ºç‹¬ç‰¹çš„è§‚ç‚¹ç­‰ï¼‰ã€‚ç„¶è€Œï¼Œä¹Ÿå­˜åœ¨ä¸€äº›åˆ›æ–°ç‚¹ä¸å¤Ÿçªå‡ºæˆ–è€…ç¼ºä¹æ–°é¢–æ€§çš„é—®é¢˜ã€‚
Performance: åœ¨æ€§èƒ½è¡¨ç°æ–¹é¢ï¼Œæœ¬æ–‡å±•ç°äº†xxxï¼ˆå¦‚æ·±å…¥çš„äººç‰©åˆ»ç”»ã€ç´§å‡‘çš„æƒ…èŠ‚å®‰æ’ç­‰ï¼‰ã€‚ä½†åŒæ—¶ï¼Œå¯èƒ½å­˜åœ¨æŸäº›æ–¹é¢å¦‚è¯­è¨€è¡¨è¾¾ã€æƒ…èŠ‚é€»è¾‘ç­‰æ–¹é¢çš„ä¸å¤Ÿå®Œç¾ã€‚
Workload: æ–‡ç« åœ¨å·¥ä½œé‡æ–¹é¢è¡¨ç°å‡ºè¾ƒå¤§çš„æŠ•å…¥ï¼Œæ¶µç›–äº†xxxæ–¹é¢çš„å†…å®¹ï¼ˆå¦‚å¹¿æ³›çš„ä¸»é¢˜ã€å¤§é‡çš„ç»†èŠ‚æå†™ç­‰ï¼‰ã€‚ç„¶è€Œï¼Œä¹Ÿå¯èƒ½å­˜åœ¨å†…å®¹è¿‡äºç¹çæˆ–å†—ä½™çš„æƒ…å†µã€‚

è¯·æ³¨æ„ï¼Œä»¥ä¸Šå›ç­”ä¸­çš„"xxx"éœ€è¦æ ¹æ®å®é™…æ–‡ç« å†…å®¹å¡«å†™ã€‚åœ¨æ€»ç»“æ—¶ï¼Œå°½é‡ä¿æŒå®¢è§‚ã€ä¸­ç«‹çš„ç«‹åœºï¼Œé¿å…ä¸»è§‚åè§ã€‚åŒæ—¶ï¼Œç¡®ä¿ä½¿ç”¨å­¦æœ¯ã€ç®€æ´çš„è¯­è¨€è¡¨è¾¾ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="http://article.biliimg.com/bfs/new_dyn/52882f3388cc5983b5b6e4c5613ac33f241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/0045bc7437a20cb334c47ffc6e46939b241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/9a5406b6a61a01a0f0a1a56a381e00e6241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/feabb392da3830f75ced1d44fe2521e2241286257.jpg" align="middle">
<img src="http://article.biliimg.com/bfs/new_dyn/b9116cf345385d220f1745bd747f7fcc241286257.jpg" align="middle">
</details>




