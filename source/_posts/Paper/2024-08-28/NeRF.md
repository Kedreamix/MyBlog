
---
title: NeRF
date: 2024-08-28 08:15:46
author: Kedreamix
cover: https://picx.zhimg.com/v2-3b823e090b6fbf3ecd424eb0aeb13e9e.jpg
categories: Paper
tags:
    - NeRF
description: NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-08-28  TranSplat Generalizable 3D Gaussian Splatting from Sparse Multi-View   Images with Transformers  
keywords: NeRF
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-08-28 æ›´æ–°


## TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View   Images with Transformers

**Authors:Chuanrui Zhang, Yingshuang Zou, Zhuoling Li, Minmin Yi, Haoqian Wang**

Compared with previous 3D reconstruction methods like Nerf, recent Generalizable 3D Gaussian Splatting (G-3DGS) methods demonstrate impressive efficiency even in the sparse-view setting. However, the promising reconstruction performance of existing G-3DGS methods relies heavily on accurate multi-view feature matching, which is quite challenging. Especially for the scenes that have many non-overlapping areas between various views and contain numerous similar regions, the matching performance of existing methods is poor and the reconstruction precision is limited. To address this problem, we develop a strategy that utilizes a predicted depth confidence map to guide accurate local feature matching. In addition, we propose to utilize the knowledge of existing monocular depth estimation models as prior to boost the depth estimation precision in non-overlapping areas between views. Combining the proposed strategies, we present a novel G-3DGS method named TranSplat, which obtains the best performance on both the RealEstate10K and ACID benchmarks while maintaining competitive speed and presenting strong cross-dataset generalization ability. Our code, and demos will be available at: https://xingyoujun.github.io/transplat. 

[PDF](http://arxiv.org/abs/2408.13770v1) 

**Summary**
å¼€å‘äº†ä¸€ç§åä¸ºTranSplatçš„æ–°G-3DGSæ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹æ·±åº¦ç½®ä¿¡å›¾å’Œç»“åˆå•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æ¥æé«˜ç¨€ç–è§†è§’ä¸‹çš„3Dé‡å»ºæ•ˆç‡ã€‚

**Key Takeaways**
- G-3DGSæ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚
- ç°æœ‰æ–¹æ³•ä¾èµ–ç²¾ç¡®çš„å¤šè§†å›¾ç‰¹å¾åŒ¹é…ï¼Œå…·æœ‰æŒ‘æˆ˜æ€§ã€‚
- TranSplaté€šè¿‡æ·±åº¦ç½®ä¿¡å›¾å¼•å¯¼å±€éƒ¨ç‰¹å¾åŒ¹é…ã€‚
- åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çŸ¥è¯†ä½œä¸ºå…ˆéªŒæ¥æå‡æ·±åº¦ä¼°è®¡ã€‚
- TranSplatåœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ã€‚
- ä¿æŒç«äº‰æ€§é€Ÿåº¦ï¼Œå…·æœ‰å¼ºè·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚
- æä¾›äº†ä»£ç å’Œæ¼”ç¤ºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers (åŸºäºTransformerçš„ç¨€ç–å¤šè§†å›¾å›¾åƒ3Dé«˜æ–¯æ•£ç‚¹é‡å»º)

2. Authors: Chuanrui Zhang, Yingshuang Zou, Zhuoling Li, Minmin Yi, Haoqian Wang

3. Affiliation: æ¸…åå¤§å­¦

4. Keywords: 3Dé‡å»ºï¼Œé«˜æ–¯æ•£ç‚¹é‡å»ºï¼ŒTransformerï¼Œå¤šè§†å›¾å›¾åƒï¼Œç¨€ç–åœºæ™¯

5. Urls: https://arxiv.org/abs/2408.13770 or https://xingyoujun.github.io/transplat

6. Summary:

   - (1): è¯¥æ–‡ç« çš„ç ”ç©¶èƒŒæ™¯æ˜¯ç¨€ç–å¤šè§†å›¾å›¾åƒçš„3Dé‡å»ºï¼Œå³ä»å°‘é‡å›¾åƒä¸­æ¢å¤åœºæ™¯çš„3Dç»“æ„ï¼Œè¿™åœ¨è™šæ‹Ÿç°å®ç­‰é¢†åŸŸéå¸¸é‡è¦ã€‚

   - (2): è¿‡å»çš„æ–¹æ³•å¦‚NeRFå’Œ3Dé«˜æ–¯æ•£ç‚¹é‡å»ºï¼ˆ3DGSï¼‰åœ¨ç¨€ç–è§†å›¾åœºæ™¯ä¸‹è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä¾èµ–äºç²¾ç¡®çš„å¤šè§†å›¾ç‰¹å¾åŒ¹é…ï¼Œè¿™åœ¨å…·æœ‰å¤§é‡éé‡å åŒºåŸŸå’Œç›¸ä¼¼åŒºåŸŸçš„åœºæ™¯ä¸­éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰æ–¹æ³•çš„åŒ¹é…æ€§èƒ½è¾ƒå·®ï¼Œé‡å»ºç²¾åº¦æœ‰é™ã€‚è¯¥æ–¹æ³•å…·æœ‰å¾ˆå¥½çš„åŠ¨æœºã€‚

   - (3): è¯¥æ–‡ç« æå‡ºäº†TranSplatæ–¹æ³•ï¼Œåˆ©ç”¨é¢„æµ‹çš„æ·±åº¦ç½®ä¿¡å›¾æ¥å¼•å¯¼ç²¾ç¡®çš„å±€éƒ¨ç‰¹å¾åŒ¹é…ï¼Œå¹¶åˆ©ç”¨ç°æœ‰å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„çŸ¥è¯†ä½œä¸ºå…ˆéªŒæ¥æé«˜éé‡å åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚

   - (4): è¯¥æ–¹æ³•åœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰ç«äº‰åŠ›çš„é€Ÿåº¦å’Œå¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ€§èƒ½ã€‚
7. Methods:

    - (1): TranSplat é‡‡ç”¨ Transformer æ¶æ„æ¥å¤„ç†ç¨€ç–å¤šè§†å›¾å›¾åƒçš„3Dé‡å»ºä»»åŠ¡ï¼Œé€šè¿‡è‡ªç¼–ç å™¨å­¦ä¹ å›¾åƒçš„æ·±åº¦ç½®ä¿¡å›¾ï¼ˆDepth Confidence Map, DCMï¼‰ã€‚

    - (2): åˆ©ç”¨æ·±åº¦ç½®ä¿¡å›¾æ¥å¼•å¯¼å±€éƒ¨ç‰¹å¾åŒ¹é…ï¼Œæé«˜ç‰¹å¾åŒ¹é…çš„å‡†ç¡®æ€§ã€‚

    - (3): ç»“åˆå•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„çŸ¥è¯†ä½œä¸ºå…ˆéªŒä¿¡æ¯ï¼Œä¼˜åŒ–éé‡å åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ã€‚

    - (4): é€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨RealEstate10Kå’ŒACIDç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°é«˜æ•ˆçš„3Dé‡å»ºã€‚

    - (5): é‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œæé«˜æ¨¡å‹åœ¨è·¨æ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

    - (6): è¯„ä¼°æ¨¡å‹æ€§èƒ½æ—¶ï¼Œè€ƒè™‘é‡å»ºç²¾åº¦ã€é€Ÿåº¦å’Œè·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ç­‰å¤šä¸ªæŒ‡æ ‡ã€‚


8. Conclusion:

                    - (1): è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºä¸ºç¨€ç–å¤šè§†å›¾å›¾åƒçš„3Dé‡å»ºæä¾›äº†ä¸€ä¸ªåˆ›æ–°çš„æ–¹æ³•ï¼Œå³åŸºäºTransformerçš„TranSplatç½‘ç»œï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»å°‘é‡å›¾åƒä¸­æ¢å¤åœºæ™¯çš„3Dç»“æ„ï¼Œä¸ºè™šæ‹Ÿç°å®ç­‰åº”ç”¨é¢†åŸŸæä¾›äº†æ–°çš„æŠ€æœ¯æ”¯æŒã€‚

                    - (2): Innovation point: TranSplatå¼•å…¥äº†Transformeræ¶æ„ï¼Œé€šè¿‡è‡ªç¼–ç å™¨å­¦ä¹ æ·±åº¦ç½®ä¿¡å›¾ï¼Œå®ç°äº†å¯¹ç¨€ç–åœºæ™¯çš„é«˜ç²¾åº¦3Dé‡å»ºï¼Œæ˜¯ä¸€ä¸ªåˆ›æ–°æ€§çš„ç ”ç©¶ç‚¹ï¼›Performance: åœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­ï¼ŒTranSplatå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰ç«äº‰åŠ›çš„é€Ÿåº¦å’Œè·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼›Workload: TranSplatä½¿ç”¨äº†ç«¯åˆ°ç«¯è®­ç»ƒå’Œè‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œè™½ç„¶éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºï¼Œä½†é€šè¿‡é¢„è®­ç»ƒå’Œè¿ç§»å­¦ä¹ ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡è½»è®­ç»ƒè´Ÿæ‹…ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ecbda3794044b1fb3aca4b4ffc1bb8eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d55dcb38e34530616db89245b06a460.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-458727f2577853b54e06bad458c47c62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae408529b2ccebe80b3bb00ff8d57b92.jpg" align="middle">
</details>




## G3DST: Generalizing 3D Style Transfer with Neural Radiance Fields across   Scenes and Styles

**Authors:Adil Meric, Umut Kocasari, Matthias NieÃŸner, Barbara Roessle**

Neural Radiance Fields (NeRF) have emerged as a powerful tool for creating highly detailed and photorealistic scenes. Existing methods for NeRF-based 3D style transfer need extensive per-scene optimization for single or multiple styles, limiting the applicability and efficiency of 3D style transfer. In this work, we overcome the limitations of existing methods by rendering stylized novel views from a NeRF without the need for per-scene or per-style optimization. To this end, we take advantage of a generalizable NeRF model to facilitate style transfer in 3D, thereby enabling the use of a single learned model across various scenes. By incorporating a hypernetwork into a generalizable NeRF, our approach enables on-the-fly generation of stylized novel views. Moreover, we introduce a novel flow-based multi-view consistency loss to preserve consistency across multiple views. We evaluate our method across various scenes and artistic styles and show its performance in generating high-quality and multi-view consistent stylized images without the need for a scene-specific implicit model. Our findings demonstrate that this approach not only achieves a good visual quality comparable to that of per-scene methods but also significantly enhances efficiency and applicability, marking a notable advancement in the field of 3D style transfer. 

[PDF](http://arxiv.org/abs/2408.13508v1) GCPR 2024, Project page: https://mericadil.github.io/G3DST/

**Summary**
åˆ©ç”¨å¯æ³›åŒ–NeRFæ¨¡å‹å®ç°æ— éœ€åœºæ™¯æˆ–é£æ ¼ä¼˜åŒ–çš„3Dé£æ ¼è¿ç§»ï¼Œæ˜¾è‘—æé«˜æ•ˆç‡å’Œé€‚ç”¨æ€§ã€‚

**Key Takeaways**
- NeRFåœ¨åˆ›å»ºé«˜ç»†èŠ‚ã€é€¼çœŸåœºæ™¯æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
- ç°æœ‰NeRFé£æ ¼è¿ç§»æ–¹æ³•éœ€å¤§é‡ä¼˜åŒ–ï¼Œé™åˆ¶æ•ˆç‡ã€‚
- æœ¬ç ”ç©¶é€šè¿‡å¯æ³›åŒ–NeRFæ¨¡å‹å®ç°æ— éœ€ä¼˜åŒ–ã€‚
- å¼•å…¥è¶…ç½‘ç»œå®ç°å³æ—¶é£æ ¼åŒ–è§†å›¾ç”Ÿæˆã€‚
- ä»‹ç»åŸºäºæµçš„è§†å›¾ä¸€è‡´æ€§æŸå¤±ï¼Œä¿è¯å¤šè§†è§’ä¸€è‡´æ€§ã€‚
- æ–¹æ³•åœ¨å¤šåœºæ™¯å’Œé£æ ¼ä¸­è¡¨ç°è‰¯å¥½ï¼Œæ— éœ€åœºæ™¯ç‰¹å®šæ¨¡å‹ã€‚
- å®ç°è§†è§‰è´¨é‡ä¸åœºæ™¯æ–¹æ³•ç›¸å½“ï¼Œæ•ˆç‡æ›´é«˜ï¼Œåº”ç”¨æ›´å¹¿ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: G3DST: Generalizing 3D Style Transfer with Neural Radiance Fields across Scenes and Styles (G3DSTï¼šåŸºäºåœºæ™¯å’Œé£æ ¼è·¨åœºæ™¯çš„3Dé£æ ¼è¿ç§»ä¸ç¥ç»è¾å°„åœº)
2. Authors: Adil Meric, Umut Kocasari, Matthias NieÃŸner, and Barbara Roessle
3. Affiliation: Technical University of Munich (æ…•å°¼é»‘å·¥ä¸šå¤§å­¦)
4. Keywords: 3D Style Transfer, Generalization, Neural Radiance Fields
5. Urls: arXiv:2408.13508v1 [cs.CV], Github: None
6. Summary:

    - (1):è¯¥æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰åœ¨åˆ›å»ºé«˜åº¦è¯¦ç»†å’Œé€¼çœŸçš„åœºæ™¯æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºNeRFçš„3Dé£æ ¼è¿ç§»æ–¹æ³•éœ€è¦å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œå¤§é‡çš„ä¼˜åŒ–ï¼Œé™åˆ¶äº†3Dé£æ ¼è¿ç§»çš„åº”ç”¨å’Œæ•ˆç‡ã€‚
 
    - (2)ï¼šè¿‡å»çš„æ–¹æ³•éœ€è¦é’ˆå¯¹å•ä¸ªæˆ–å¤šä¸ªé£æ ¼è¿›è¡Œæ¯ä¸ªåœºæ™¯çš„ä¼˜åŒ–ï¼Œè¿™é™åˆ¶äº†3Dé£æ ¼è¿ç§»çš„åº”ç”¨å’Œæ•ˆç‡ã€‚è¯¥æ–¹æ³•çš„åŠ¨æœºåœ¨äºé€šè¿‡ä¸è¿›è¡Œåœºæ™¯æˆ–é£æ ¼çš„ä¼˜åŒ–æ¥æ¸²æŸ“é£æ ¼åŒ–çš„æ–°è§†å›¾ï¼Œä»è€Œå…‹æœç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚
 
    - (3)ï¼šè¯¥æ–‡æå‡ºçš„æ–¹æ³•åˆ©ç”¨å¯æ³›åŒ–çš„NeRFæ¨¡å‹æ¥ä¿ƒè¿›3Dä¸­çš„é£æ ¼è¿ç§»ï¼Œä»è€Œä½¿å¾—å•ä¸ªå­¦ä¹ æ¨¡å‹å¯ä»¥è·¨è¶Šå„ç§åœºæ™¯ä½¿ç”¨ã€‚æ­¤å¤–ï¼Œé€šè¿‡å°†è¶…ç½‘ç»œé›†æˆåˆ°å¯æ³›åŒ–çš„NeRFä¸­ï¼Œè¯¥æ–¹æ³•å¯ä»¥å®æ—¶ç”Ÿæˆé£æ ¼åŒ–çš„æ–°è§†å›¾ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºæµçš„è§†å›¾ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥ä¿æŒå¤šä¸ªè§†å›¾çš„ä¸€è‡´æ€§ã€‚
 
    - (4)ï¼šè¯¥æ–‡çš„æ–¹æ³•åœ¨å„ç§åœºæ™¯å’Œè‰ºæœ¯é£æ ¼ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶åœ¨ç”Ÿæˆé«˜è´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´çš„é£æ ¼åŒ–å›¾åƒæ–¹é¢çš„æ€§èƒ½ï¼Œæ— éœ€ä¸ºç‰¹å®šåœºæ™¯çš„éšå¼æ¨¡å‹è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½ä¸ä»…ä¸åœºæ™¯ç‰¹å®šæ–¹æ³•ç›¸å½“ï¼Œè€Œä¸”æ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œé€‚ç”¨æ€§ï¼Œæ ‡å¿—ç€3Dé£æ ¼è¿ç§»é¢†åŸŸçš„é‡å¤§è¿›æ­¥ã€‚
7. Methods:

    - (1): è¯¥æ–¹æ³•ä»¥ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰ä¸ºåŸºç¡€ï¼Œæå‡ºäº†ä¸€ç§é€šç”¨çš„3Dé£æ ¼è¿ç§»æ¡†æ¶G3DSTï¼Œæ—¨åœ¨é€šè¿‡å­¦ä¹ ä¸€ä¸ªå¯æ³›åŒ–çš„NeRFæ¨¡å‹ï¼Œå®ç°åœºæ™¯å’Œé£æ ¼ä¹‹é—´çš„é£æ ¼è¿ç§»ã€‚

    - (2): å°†è¶…ç½‘ç»œé›†æˆåˆ°å¯æ³›åŒ–çš„NeRFä¸­ï¼Œé€šè¿‡å­¦ä¹ åœºæ™¯å’Œé£æ ¼çš„æ½œåœ¨ç©ºé—´ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼çš„æ–°åœºæ™¯è§†å›¾ã€‚

    - (3): å¼•å…¥åŸºäºæµçš„è§†å›¾ä¸€è‡´æ€§æŸå¤±ï¼Œç¡®ä¿ç”Ÿæˆçš„å¤šä¸ªè§†å›¾åœ¨è§†è§‰ä¸Šä¿æŒä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚

    - (4): ä½¿ç”¨å¤šä¸ªé£æ ¼åŒ–çš„NeRFæ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–è¶…ç½‘ç»œå‚æ•°ï¼Œå®ç°é£æ ¼åŒ–çš„æ–°è§†å›¾ç”Ÿæˆã€‚

    - (5): åœ¨å¤šä¸ªåœºæ™¯å’Œè‰ºæœ¯é£æ ¼ä¸Šè¿›è¡Œå®éªŒï¼ŒéªŒè¯äº†G3DSTæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚


8. Conclusion:

                    - (1):è¯¥ç ”ç©¶å·¥ä½œçš„é‡è¦æ€§åœ¨äºæå‡ºäº†ä¸€ç§é€šç”¨çš„3Dé£æ ¼è¿ç§»æ–¹æ³•ï¼Œèƒ½å¤Ÿè·¨è¶Šåœºæ™¯å’Œé£æ ¼çš„é™åˆ¶ï¼Œå®ç°é«˜æ•ˆä¸”é«˜è´¨é‡çš„3Dé£æ ¼åŒ–å›¾åƒç”Ÿæˆã€‚

                    - (2):Innovation point: åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†ç¥ç»ç½‘ç»œè¾å°„åœºå’Œè¶…ç½‘ç»œç»“æ„ï¼Œé€šè¿‡å­¦ä¹ åœºæ™¯å’Œé£æ ¼çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†å¯¹å¤šç§åœºæ™¯å’Œé£æ ¼çš„æ³›åŒ–é£æ ¼è¿ç§»ï¼›Performance: æ€§èƒ½æ–¹é¢ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåœºæ™¯å’Œè‰ºæœ¯é£æ ¼ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç”Ÿæˆçš„å›¾åƒè´¨é‡é«˜ï¼Œå¤šè§†å›¾ä¸€è‡´æ€§è‰¯å¥½ï¼›Workload: å·¥ä½œé‡æ–¹é¢ï¼Œè¯¥æ–¹æ³•ä»…éœ€è¿›è¡Œä¸€æ¬¡åœºæ™¯æ— å…³çš„é¢„è®­ç»ƒï¼Œå³å¯åº”ç”¨äºæ–°çš„åœºæ™¯å’Œé£æ ¼ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šåœºæ™¯æˆ–é£æ ¼è¿›è¡Œé¢å¤–çš„è®­ç»ƒã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f013891eb232561c6fdfade5440bb3ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-756f4545733f1887124443ff519bf650.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9db33a6e21e0a6bc47da3cb6f8e7f65f.jpg" align="middle">
</details>




## SIn-NeRF2NeRF: Editing 3D Scenes with Instructions through Segmentation   and Inpainting

**Authors:Jiseung Hong, Changmin Lee, Gyusang Yu**

TL;DR Perform 3D object editing selectively by disentangling it from the background scene. Instruct-NeRF2NeRF (in2n) is a promising method that enables editing of 3D scenes composed of Neural Radiance Field (NeRF) using text prompts. However, it is challenging to perform geometrical modifications such as shrinking, scaling, or moving on both the background and object simultaneously. In this project, we enable geometrical changes of objects within the 3D scene by selectively editing the object after separating it from the scene. We perform object segmentation and background inpainting respectively, and demonstrate various examples of freely resizing or moving disentangled objects within the three-dimensional space. 

[PDF](http://arxiv.org/abs/2408.13285v1) Code is available at: https://github.com/KAISTChangmin/SIn-NeRF2NeRF

**Summary**
é€šè¿‡é€‰æ‹©æ€§ç¼–è¾‘åˆ†ç¦»å¯¹è±¡ï¼Œå®ç°3Då¯¹è±¡ç¼–è¾‘ã€‚

**Key Takeaways**
1. ä½¿ç”¨Instruct-NeRF2NeRF (in2n)é€šè¿‡æ–‡æœ¬æç¤ºç¼–è¾‘NeRFåœºæ™¯ã€‚
2. é¢ä¸´åŒæ—¶ä¿®æ”¹èƒŒæ™¯å’Œå¯¹è±¡å‡ ä½•å½¢çŠ¶çš„æŒ‘æˆ˜ã€‚
3. é€šè¿‡å¯¹è±¡åˆ†å‰²å’ŒèƒŒæ™¯ä¿®å¤å®ç°å¯¹è±¡å‡ ä½•å˜åŒ–ã€‚
4. æ”¯æŒåœ¨ä¸‰ç»´ç©ºé—´ä¸­è‡ªç”±è°ƒæ•´åˆ†ç¦»å¯¹è±¡çš„å°ºå¯¸å’Œä½ç½®ã€‚
5. æ–¹æ³•èƒ½å¤„ç†ç¼©å°ã€ç¼©æ”¾æˆ–ç§»åŠ¨ç­‰å‡ ä½•ä¿®æ”¹ã€‚
6. æä¾›äº†å¤šç§ç¼–è¾‘ç¤ºä¾‹ã€‚
7. æ”¹è¿›äº†å¯¹3Dåœºæ™¯ä¸­å¯¹è±¡çš„ç¼–è¾‘èƒ½åŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: SIn-NeRF2NeRF: é€šè¿‡åˆ†å‰²è¿›è¡Œ3Dåœºæ™¯ç¼–è¾‘çš„æŒ‡ä»¤å­¦ä¹ 
2. Authors: Jiseung Hong, Changmin Lee, Gyusang Yu
3. Affiliation: éŸ©å›½KAISTï¼ˆKorea Advanced Institute of Science and Technologyï¼‰
4. Keywords: 3Dåœºæ™¯ç¼–è¾‘ï¼Œç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåˆ†å‰²ï¼Œå›¾åƒä¿®å¤ï¼ŒæŒ‡ä»¤å­¦ä¹ 
5. Urls: https://arxiv.org/abs/2408.13285v1 or Github: None
6. Summary:

   - (1):æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯3Dåœºæ™¯ç¼–è¾‘åœ¨è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®åº”ç”¨ä¸­çš„é‡è¦æ€§ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•é€šè¿‡æ–‡æœ¬æŒ‡ä»¤ç¼–è¾‘ç”±ç¥ç»ç½‘ç»œè¾å°„åœºï¼ˆNeRFï¼‰æ„æˆçš„3Dåœºæ™¯ã€‚
 
   - (2):è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬Instruct-NeRF2NeRFï¼ˆin2nï¼‰ï¼Œå®ƒå…è®¸ç”¨æˆ·é€šè¿‡æ–‡æœ¬æç¤ºç¼–è¾‘3Dåœºæ™¯ï¼Œä½†éš¾ä»¥åŒæ—¶å¯¹èƒŒæ™¯å’Œå¯¹è±¡è¿›è¡Œå‡ ä½•ä¿®æ”¹ï¼Œå¦‚ç¼©æ”¾ã€å¹³ç§»ç­‰ã€‚è¿™ç§æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨å¤„ç†å‡ ä½•å˜åŒ–æ—¶å­˜åœ¨å±€é™æ€§ã€‚æœ¬æ–‡æå‡ºçš„è§£å†³æ–¹æ¡ˆæ˜¯åˆç†çš„ï¼Œå› ä¸ºå®ƒè§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚
 
   - (3)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•SIn-NeRF2NeRFé€šè¿‡åˆ†å‰²å’Œå›¾åƒä¿®å¤æŠ€æœ¯ï¼Œå°†å¯¹è±¡ä»åœºæ™¯ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œç„¶ååˆ†åˆ«ç¼–è¾‘å¯¹è±¡å’ŒèƒŒæ™¯ã€‚é¦–å…ˆè¿›è¡Œå¯¹è±¡åˆ†å‰²ï¼Œç„¶åè¿›è¡ŒèƒŒæ™¯å›¾åƒä¿®å¤ï¼Œæœ€åå¯¹åˆ†å‰²å‡ºçš„å¯¹è±¡è¿›è¡Œç¼–è¾‘ã€‚
 
   - (4)ï¼šè¯¥æ–¹æ³•åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œå±•ç¤ºäº†å…¶åœ¨è‡ªç”±ç¼©æ”¾å’Œç§»åŠ¨å¯¹è±¡æ–¹é¢çš„èƒ½åŠ›ã€‚æ€§èƒ½è¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å®ç°3Dåœºæ™¯çš„ç²¾ç¡®ç¼–è¾‘ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚


8. Conclusion:

                    - (1)ï¼šè¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼Œå®ƒä¸º3Dåœºæ™¯ç¼–è¾‘æä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡æŒ‡ä»¤å­¦ä¹ å’Œå›¾åƒä¿®å¤æŠ€æœ¯ï¼Œå®ç°äº†å¯¹NeRFåœºæ™¯ä¸­å¯¹è±¡çš„ç²¾ç¡®ç¼–è¾‘ï¼Œå°¤å…¶æ˜¯åœ¨å‡ ä½•å˜æ¢æ–¹é¢ï¼Œå¦‚ç¼©æ”¾å’Œå¹³ç§»ï¼Œè¿™å¯¹äºè™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åº”ç”¨é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚

                    - (2): Innovation point: SIn-NeRF2NeRFé€šè¿‡åˆ†å‰²å’Œå›¾åƒä¿®å¤æŠ€æœ¯ï¼Œå®ç°äº†å¯¹3Dåœºæ™¯ä¸­å¯¹è±¡çš„ç‹¬ç«‹ç¼–è¾‘ï¼Œæ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼›Performance: åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šçš„éªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‡ªç”±ç¼©æ”¾å’Œç§»åŠ¨å¯¹è±¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨è¿­ä»£æ•°æ®é›†æ›´æ–°æ—¶ï¼Œå¯¹è±¡ç¼–è¾‘çš„æ•ˆæœå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œæ€§èƒ½æœ‰å¾…æå‡ï¼›Workload: è¯¥æ–¹æ³•æ¶‰åŠå¤æ‚çš„NeRFå­¦ä¹ å’Œå›¾åƒä¿®å¤è¿‡ç¨‹ï¼Œè®¡ç®—å’Œå­˜å‚¨èµ„æºéœ€æ±‚è¾ƒé«˜ï¼Œå·¥ä½œè´Ÿè½½è¾ƒå¤§ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b7773453e3afb52af81c4b0eec73f437.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e22a651ec9c59e3f03264248272668d7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3a461a07bea9318b8b86b9ee31f111c8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e08dd0360570ea94c92cd4e71915196e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c6119a0a37206fda12103b11315944c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b0722cdb5a25d604a6bb61bbabd180e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75100f2ad6b99c88cc9bdebf2d4c4394.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3b823e090b6fbf3ecd424eb0aeb13e9e.jpg" align="middle">
</details>




