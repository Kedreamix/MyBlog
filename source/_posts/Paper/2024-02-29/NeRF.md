
---
title: NeRF
date: 2024-02-29 21:26:36
author: Kedreamix
cover: https://pic1.zhimg.com/v2-fe3f4f6d4cf8758d74cb0be86547e9f6.jpg
categories: Paper
tags:
    - NeRF
description: NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis  
keywords: NeRF
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-02-29 æ›´æ–°


## Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis

**Authors:Zicheng Zhang, Ruobing Zheng, Ziwen Liu, Congying Han, Tianqi Li, Meng Wang, Tiande Guo, Jingdong Chen, Bonan Li, Ming Yang**

Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences. These implicit methods are still confronted by visual artifacts and jitters, since the lack of explicit geometric constraints poses a fundamental challenge in accurately modeling complex facial deformations. In this paper, we introduce Dynamic Tetrahedra (DynTet), a novel hybrid representation that encodes explicit dynamic meshes by neural networks to ensure geometric consistency across various motions and viewpoints. DynTet is parameterized by the coordinate-based networks which learn signed distance, deformation, and material texture, anchoring the training data into a predefined tetrahedra grid. Leveraging Marching Tetrahedra, DynTet efficiently decodes textured meshes with a consistent topology, enabling fast rendering through a differentiable rasterizer and supervision via a pixel loss. To enhance training efficiency, we incorporate classical 3D Morphable Models to facilitate geometry learning and define a canonical space for simplifying texture learning. These advantages are readily achievable owing to the effective geometric representation employed in DynTet. Compared with prior works, DynTet demonstrates significant improvements in fidelity, lip synchronization, and real-time performance according to various metrics. Beyond producing stable and visually appealing synthesis videos, our method also outputs the dynamic meshes which is promising to enable many emerging applications. 

[PDF](http://arxiv.org/abs/2402.17364v1) CVPR 2024

**Summary**
ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æœ€æ–°æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œå³åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜ç¡®åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿å„ç§åŠ¨ä½œå’Œè§†ç‚¹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚

**Key Takeaways**
- DynTet æ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿ä¸åŒåŠ¨ä½œå’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚
- DynTet ä½¿ç”¨åŸºäºåæ ‡çš„ç½‘ç»œå¯¹ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†è¿›è¡Œå­¦ä¹ ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚
- DynTet åˆ©ç”¨ Marching Tetrahedra æœ‰æ•ˆåœ°è§£ç äº†å…·æœ‰ç¨³å®šæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œå¹¶é€šè¿‡å¯å¾®åˆ†å…‰æ …å™¨å’Œåƒç´ æŸå¤±çš„ç›‘ç£å®ç°äº†å¿«é€Ÿæ¸²æŸ“ã€‚
- DynTet ç»“åˆç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒåŒ–ç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚
- ä¸ä¹‹å‰çš„ç ”ç©¶ç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æœ‰äº†æ˜¾è‘—çš„æå‡ã€‚
- é™¤äº†åˆ¶ä½œå‡ºç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›å®ç°è®¸å¤šæ–°å…´åº”ç”¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šç”¨äºé«˜å“è´¨è¯´è¯äººå¤´éƒ¨åˆæˆçš„åŠ¨æ€å››é¢ä½“å­¦ä¹ </li>
<li>ä½œè€…ï¼šå¼ å­å·ï¼Œå¼ æ’ï¼Œç‹ä½³ä¿Šï¼Œåˆ˜å­è¶…ï¼Œå­™å‰‘</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨åˆæˆã€éšå¼è¡¨ç¤ºã€åŠ¨æ€ç½‘æ ¼ã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.02574</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
è¿‘å¹´æ¥ï¼Œéšå¼è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåœ¨ä»è§†é¢‘åºåˆ—ç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»åŒ–çš„å¤´éƒ¨å¤´åƒæ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›éšå¼æ–¹æ³•ä»ç„¶é¢ä¸´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ï¼Œå› ä¸ºç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œè¿™ç»™å‡†ç¡®å»ºæ¨¡å¤æ‚çš„é¢éƒ¨å˜å½¢å¸¦æ¥äº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
è¿‡å»çš„æ–¹æ³•ä¸»è¦é‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œä½†ç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œå¯¼è‡´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚DynTet ç”±åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œè¯¥ç½‘ç»œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTet å¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæœ¬æ–‡ç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚è¿™äº›ä¼˜åŠ¿å¾—ç›Šäº DynTet ä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠå¯¹ç›®æ ‡çš„æ”¯æŒï¼š
ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
(1): åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰é€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼›
(2): åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†æ•°æ®é”šå®šåˆ°å››é¢ä½“ç½‘æ ¼ä¸­ï¼›
(3): åˆ©ç”¨è¡Œè¿›å››é¢ä½“è§£ç çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨æ¸²æŸ“å¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼›
(4): ç»“åˆç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</p>
<ol>
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œæå‡äº†è¯´è¯äººå¤´éƒ¨åˆæˆçš„ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li>
<li>åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTetå¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚</li>
<li>ç»“åˆäº†ç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li>
<li>è¿™äº›ä¼˜åŠ¿å¾—ç›ŠäºDynTetä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚</li>
<li>ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTetåœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li>
<li>é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li>
<li>ç”Ÿæˆäº†ç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘ã€‚</li>
<li>è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2927e4da13bb2db0a8c147b32e65c4ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a69eb8d9ee3b7163b0dd216926919257.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-989288a0ad24820fe95020a4ed1f2ea7.jpg" align="middle">
</details>




## CharNeRF: 3D Character Generation from Concept Art

**Authors:Eddy Chu, Yiyang Chen, Chedy Raissi, Anand Bhojan**

3D modeling holds significant importance in the realms of AR/VR and gaming, allowing for both artistic creativity and practical applications. However, the process is often time-consuming and demands a high level of skill. In this paper, we present a novel approach to create volumetric representations of 3D characters from consistent turnaround concept art, which serves as the standard input in the 3D modeling industry. While Neural Radiance Field (NeRF) has been a game-changer in image-based 3D reconstruction, to the best of our knowledge, there is no known research that optimizes the pipeline for concept art. To harness the potential of concept art, with its defined body poses and specific view angles, we propose encoding it as priors for our model. We train the network to make use of these priors for various 3D points through a learnable view-direction-attended multi-head self-attention layer. Additionally, we demonstrate that a combination of ray sampling and surface sampling enhances the inference capabilities of our network. Our model is able to generate high-quality 360-degree views of characters. Subsequently, we provide a simple guideline to better leverage our model to extract the 3D mesh. It is important to note that our model's inferencing capabilities are influenced by the training data's characteristics, primarily focusing on characters with a single head, two arms, and two legs. Nevertheless, our methodology remains versatile and adaptable to concept art from diverse subject matters, without imposing any specific assumptions on the data. 

[PDF](http://arxiv.org/abs/2402.17115v1) 

**Summary**
ç”¨æ¦‚å¿µå›¾åˆ›å»º 3D æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨ç¥ç»è¾å°„åœºå¹¶ä¸ºå›¾åƒå»ºæ¨¡æä¾›æ›´å¥½çš„è§†è§’ã€‚

**Key Takeaways**
- è‰ºæœ¯åˆ›ä½œå’Œå®é™…åº”ç”¨ä¸­ï¼Œ3D å»ºæ¨¡å¾ˆæœ‰ä»·å€¼ï¼Œä½†éœ€è¦èŠ±è´¹æ—¶é—´å’ŒæŠ€èƒ½ã€‚
- è¯¥æ–¹æ³•ä»æ ‡å‡†çš„ 3D å»ºæ¨¡è¡Œä¸šè¾“å…¥ï¼Œå³å¯æ ¹æ®ä¸€è‡´çš„é€è§†å›¾æ¦‚å¿µå›¾åˆ›å»º 3D è§’è‰²çš„ä½“ç§¯è¡¨ç¤ºã€‚
- ç¥ç»è¾å°„åœº (NeRF) å·²æ”¹å˜åŸºäºå›¾åƒçš„ 3D é‡å»ºï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡é“ã€‚
- ç¼–ç æ¦‚å¿µå›¾ä¸ºæ¨¡å‹çš„å…ˆéªŒï¼Œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„æ¸…æ™°çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚
- é€šè¿‡å¯å­¦ä¹ çš„è§†å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®­ç»ƒç½‘ç»œåˆ©ç”¨å„ç§ 3D ç‚¹çš„å…ˆéªŒã€‚
- å°„çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚
- æ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚
- å¼€å‘äº†ç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚
- æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å¤´éƒ¨ã€æ‰‹è‡‚å’Œè…¿éƒ¨ã€‚
- è¯¥æ–¹æ³•é€‚ç”¨äºå„ç§ä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œå¯¹æ•°æ®æ²¡æœ‰ç‰¹æ®Šå‡è®¾ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šCharNeRFï¼šåŸºäºæ¦‚å¿µå›¾çš„ 3D è§’è‰²ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šEddy Chuã€Yiyang Chenã€Chedy Raissiã€Anand Bhojan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»ç½‘ç»œã€è®¡ç®—æœºå›¾å½¢ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆã€ç½‘æ ¼ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17115</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D å»ºæ¨¡åœ¨ AR/VR å’Œæ¸¸æˆä¸­è‡³å…³é‡è¦ï¼Œä½†é€šå¸¸è€—æ—¶ä¸”è¦æ±‚é«˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ä¸€è‡´çš„å‘¨è½¬æ¦‚å¿µå›¾ä¸­åˆ›å»º 3D è§’è‰²ä½“ç§¯è¡¨ç¤ºçš„æ–°æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç¥ç»è¾å°„åœº (NeRF) å·²æˆä¸ºå›¾åƒé‡å»ºçš„å˜é©è€…ï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡çº¿çš„ç ”ç©¶ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡åˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ï¼Œå°†å…¶ç¼–ç ä¸ºæ¨¡å‹çš„å…ˆéªŒã€‚æå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨è¿™äº›å…ˆéªŒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ç¼–ç æ¦‚å¿µå›¾ï¼šé‡‡ç”¨åŒå±‚æ²™æ¼ç¼–ç å™¨ï¼Œæå–æ¦‚å¿µå›¾çš„é«˜ä½å±‚æ¬¡ç»†èŠ‚ã€‚
(2) è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç‰¹å¾å‘é‡ç»„åˆï¼šä½¿ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶èåˆæ¥è‡ªæ¦‚å¿µå›¾çš„ä¸‰ä¸ªç‰¹å¾å‘é‡ï¼Œé‡ç‚¹å…³æ³¨æŸ¥è¯¢è§†å›¾æ–¹å‘ä¸æºè‰å›¾è§†å›¾æ–¹å‘ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
(3) ç¥ç»è¾å°„åœºï¼šä½¿ç”¨ç¥ç»è¾å°„åœºé¢„æµ‹æœ€ç»ˆé¢œè‰²å’Œå¯†åº¦ï¼ŒæŒ‡å¯¼ç½‘ç»œå­¦ä¹ ç‰¹å®šç±»åˆ«çš„ä¸€èˆ¬å½¢çŠ¶å’Œç‰¹å¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œå°è¯•è§£å†³è®¡ç®—æœºè§†è§‰ä¸­ä¸€ä¸ªå…·æœ‰é‡è¦ AR/VR/æ¸¸æˆåº”ç”¨ä»·å€¼çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå³ä½¿ç”¨ NeRF ä»æ¦‚å¿µå›¾æ„å»º 3D è§’è‰²çš„ 3D è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºçš„æœ€ç»ˆæ¨¡å‹ CharNeRF å¾—ç›Šäºç”¨äºç»„åˆä¸åŒè¾“å…¥è§†å›¾ä¿¡æ¯çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç»„ä»¶ï¼Œèƒ½å¤Ÿä»å¦‚æ­¤ç¨€ç–çš„å›¾åƒè¾“å…¥ä¸­ç”Ÿæˆè‰¯å¥½çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚æ­¤å¤–ï¼Œè¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚
æ€§èƒ½ï¼šæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚
å·¥ä½œé‡ï¼šæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-828eaae544f50ff5c3cb4c05ee9d80e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef7369a7d8878e03f6b272a4d1ebd217.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19f2984d16b69f5650701e035c363f95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b8a11537cec84e0f035cff561493d37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f60295f4a9ff4a9d9749851b16f04d26.jpg" align="middle">
</details>




## CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency

**Authors:Hanxin Zhu, Tianyu He, Zhibo Chen**

Neural Radiance Field (NeRF) has shown impressive results in novel view synthesis, particularly in Virtual Reality (VR) and Augmented Reality (AR), thanks to its ability to represent scenes continuously. However, when just a few input view images are available, NeRF tends to overfit the given views and thus make the estimated depths of pixels share almost the same value. Unlike previous methods that conduct regularization by introducing complex priors or additional supervisions, we propose a simple yet effective method that explicitly builds depth-aware consistency across input views to tackle this challenge. Our key insight is that by forcing the same spatial points to be sampled repeatedly in different input views, we are able to strengthen the interactions between views and therefore alleviate the overfitting problem. To achieve this, we build the neural networks on layered representations (\textit{i.e.}, multiplane images), and the sampling point can thus be resampled on multiple discrete planes. Furthermore, to regularize the unseen target views, we constrain the rendered colors and depths from different input views to be the same. Although simple, extensive experiments demonstrate that our proposed method can achieve better synthesis quality over state-of-the-art methods. 

[PDF](http://arxiv.org/abs/2402.16407v1) Accepted by IEEE Conference on Virtual Reality and 3D User Interfaces   (IEEE VR 2024)

**Summary**
ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å…¨æ–°è§†è§’åˆæˆä¸­å±•ç¤ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨è™šæ‹Ÿç°å® (VR) å’Œå¢å¼ºç°å® (AR) ä¸­ï¼Œè¿™å¾—ç›Šäºå…¶è¿ç»­è¡¨ç¤ºåœºæ™¯çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ï¼ŒNeRF å€¾å‘äºå¯¹ç»™å®šçš„è§†å›¾è¿›è¡Œè¿‡åº¦æ‹Ÿåˆï¼Œä»è€Œä½¿ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹å…·æœ‰ç›¸åŒçš„å€¼ã€‚ä¸åŒäºé€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é™„åŠ ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–çš„å…ˆå‰æ–¹æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜ç¡®æ„å»ºäº†è¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·ï¼Œæˆ‘ä»¬èƒ½å¤ŸåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œå‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰ä¸Šå»ºç«‹ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”é‡‡æ ·ç‚¹å¯ä»¥åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒã€‚è™½ç„¶ç®€å•ï¼Œä½†å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•å¯ä»¥æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°æ›´å¥½çš„åˆæˆè´¨é‡ã€‚

**Key Takeaways**
- NeRF åœ¨åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ä¼šè¿‡æ‹Ÿåˆã€‚
- é€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·å¯ä»¥å‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚
- æˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºä¸Šæ„å»ºç¥ç»ç½‘ç»œï¼Œä»¥ä¾¿åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·é‡‡æ ·ç‚¹ã€‚
- æˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒï¼Œä»¥æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚
- æˆ‘ä»¬çš„æ–¹æ³•æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°äº†æ›´å¥½çš„åˆæˆè´¨é‡ã€‚
- æˆ‘ä»¬æ–¹æ³•çš„å…³é”®åœ¨äºæ˜¾å¼æ„å»ºè¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§ã€‚
- æˆ‘ä»¬çš„æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œä¸éœ€è¦å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–çš„ç›‘ç£ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šCMCï¼šé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§è¿›è¡Œå°æ ·æœ¬æ–°è§†è§’åˆæˆ</li>
<li>ä½œè€…ï¼šéŸ©æ˜•ç«¹ã€ä½•å¤©å®‡ã€é™ˆå¿—æ³¢</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å°æ ·æœ¬è§†è§’åˆæˆã€å¤šå¹³é¢å›¾åƒã€è·¨è§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone, Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¯¼è‡´ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹ç›¸åŒã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä½†å­˜åœ¨é¢„è®­ç»ƒæˆæœ¬é«˜ã€åŸŸå·®è·ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼Œé€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æ„å»ºäº†åŸºäºåˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰çš„ç¥ç»ç½‘ç»œï¼Œå¹¶å¯¹å¤šå¹³é¢è¿›è¡Œé‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæœ¬æ–‡çº¦æŸäº†ä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>7.Methods:
(1):æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ï¼›
(2):é€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼›
(3):çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº† CMC æ–¹æ³•ï¼Œé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§ï¼Œç¼“è§£äº† NeRF åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæå‡äº†åˆæˆå›¾åƒçš„è´¨é‡ã€‚
(2): åˆ›æ–°ç‚¹ï¼š<ul>
<li>æå‡ºè·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚</li>
<li>æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ã€‚</li>
<li>çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚
Performanceï¼š</li>
<li>åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
Workloadï¼š</li>
<li>æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œæ˜“äºå®ç°ã€‚</li>
</ul>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bdd46c7b217cb4180eb948c43ffad849.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-571786b47c356d9bc3c90a0ca95fe68b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78bf909d8f8aa9e18f65bc56fd97a0b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0da54ff7a201688851cb82cbbbe20007.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eff9d03d40a8b3f7618fd67f793df987.jpg" align="middle">
</details>




## SPC-NeRF: Spatial Predictive Compression for Voxel Based Radiance Field

**Authors:Zetian Song, Wenhong Duan, Yuhuai Zhang, Shiqi Wang, Siwei Ma, Wen Gao**

Representing the Neural Radiance Field (NeRF) with the explicit voxel grid (EVG) is a promising direction for improving NeRFs. However, the EVG representation is not efficient for storage and transmission because of the terrific memory cost. Current methods for compressing EVG mainly inherit the methods designed for neural network compression, such as pruning and quantization, which do not take full advantage of the spatial correlation of voxels. Inspired by prosperous digital image compression techniques, this paper proposes SPC-NeRF, a novel framework applying spatial predictive coding in EVG compression. The proposed framework can remove spatial redundancy efficiently for better compression performance.Moreover, we model the bitrate and design a novel form of the loss function, where we can jointly optimize compression ratio and distortion to achieve higher coding efficiency. Extensive experiments demonstrate that our method can achieve 32% bit saving compared to the state-of-the-art method VQRF on multiple representative test datasets, with comparable training time. 

[PDF](http://arxiv.org/abs/2402.16366v1) 

**Summary**
åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç å¯¹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¿›è¡Œå‹ç¼©ï¼Œå¯æœ‰æ•ˆæå‡å…¶å­˜å‚¨å’Œä¼ è¾“æ•ˆç‡ã€‚

**Key Takeaways**
- æå‡ºåŸºäºæ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆvoxel gridï¼‰çš„ NeRF å‹ç¼©æ–°æ¡†æ¶â€”â€”SPC-NeRF
- åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç æœ‰æ•ˆå»é™¤ä½“ç´ çš„ç©ºé—´å†—ä½™ï¼Œæå‡å‹ç¼©æ€§èƒ½
- æå‡ºæ–°çš„æ¯”ç‰¹ç‡å»ºæ¨¡å’ŒæŸå¤±å‡½æ•°å½¢å¼ï¼Œå®ç°å‹ç¼©ç‡ä¸å¤±çœŸçš„è”åˆä¼˜åŒ–
- åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œä¸æœ€å…ˆè¿›çš„ VQRF æ–¹æ³•ç›¸æ¯”ï¼ŒèŠ‚çœ 32% çš„æ¯”ç‰¹ç‡
- è®­ç»ƒæ—¶é—´ä¸ VQRF ç›¸å½“
- å……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¼˜äºä»ç¥ç»ç½‘ç»œå‹ç¼©æ–¹æ³•ç»§æ‰¿çš„å‹ç¼©æŠ€æœ¯
- æ˜¾å¼ä½“ç´ ç½‘æ ¼çš„å‹ç¼©å¯¹äº NeRF çš„å­˜å‚¨å’Œä¼ è¾“è‡³å…³é‡è¦

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šSPC-NeRFï¼šä½“ç´ åŒ–å…‰åœºè¾å°„çš„ç©ºåŸŸé¢„æµ‹å‹ç¼©</li>
<li>ä½œè€…ï¼šå®‹æ³½å¤©ã€æ®µæ–‡å®ã€å¼ å®‡æ€€ã€ç‹è¯—å¥‡ã€é©¬æ€ä¼Ÿã€é«˜æ–‡</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€EVGã€ç©ºåŸŸé¢„æµ‹ç¼–ç ã€æ•°æ®å‹ç¼©</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16366
    Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä½¿ç”¨æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¡¨ç¤ºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯æå‡ NeRF æ€§èƒ½çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ã€‚ç„¶è€Œï¼ŒEVG è¡¨ç¤ºåœ¨å­˜å‚¨å’Œä¼ è¾“æ–¹é¢æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºå†…å­˜å¼€é”€å·¨å¤§ã€‚å½“å‰ç”¨äºå‹ç¼© EVG çš„æ–¹æ³•ä¸»è¦ç»§æ‰¿äº†ä¸ºç¥ç»ç½‘ç»œå‹ç¼©è®¾è®¡çš„å‰ªæå’Œé‡åŒ–ç­‰æ–¹æ³•ï¼Œè€Œè¿™äº›æ–¹æ³•å¹¶æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ©ç”¨ç¥ç»ç½‘ç»œå‹ç¼©æŠ€æœ¯ï¼Œå¦‚å‰ªæå’Œé‡åŒ–ï¼Œä½†è¿™äº›æ–¹æ³•æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šå—ç¹è£çš„æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº† SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äº EVG å‹ç¼©çš„æ–°æ¡†æ¶ã€‚æå‡ºçš„æ¡†æ¶å¯ä»¥æœ‰æ•ˆå»é™¤ç©ºé—´å†—ä½™ï¼Œä»¥è·å¾—æ›´å¥½çš„å‹ç¼©æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ¯”ç‰¹ç‡è¿›è¡Œå»ºæ¨¡å¹¶è®¾è®¡äº†æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œåœ¨è¯¥æŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œä»¥å®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ EVG NeRF å‹ç¼©æ–¹æ³• VQRF ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº† 32% çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)å—æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯çš„å¯å‘ï¼Œæå‡ºSPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼›(2)å°†EVGè¡¨ç¤ºä¸ºç‰¹å¾ç½‘æ ¼ï¼Œå¹¶åˆ©ç”¨å…¶ç©ºé—´ç›¸å…³æ€§ï¼Œé€šè¿‡é¢„æµ‹ç¼–ç å»é™¤ç©ºé—´å†—ä½™ï¼›(3)è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚</p>
<ol>
<li>æ€»ç»“
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å·¥ä½œçš„ä¸»è¦æ„ä¹‰åœ¨äºæå‡ºäº†SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆå»é™¤äº†ç©ºé—´å†—ä½™ï¼Œæé«˜äº†å‹ç¼©æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â€¢ æå‡ºSPC-NeRFï¼Œå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©ï¼Œå……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
â€¢ è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚
æ€§èƒ½ï¼š
â€¢ ä¸æœ€å…ˆè¿›çš„EVG-NeRFå‹ç¼©æ–¹æ³•VQRFç›¸æ¯”ï¼Œåœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº†32%çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚
å·¥ä½œé‡ï¼š
â€¢ è®ºæ–‡ç†è®ºåˆ†ææ¸…æ™°ï¼Œå®éªŒç»“æœå……åˆ†ï¼Œä»£ç å¼€æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f6705a1aaf3db9b5a416e3ffecb9e26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5908f2606537f6a0653b96477b77c75f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efc08eb0ec890344de572f2b2004f9c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-866d14094e6f176536a298862171f8d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3117d16ce413f3de96c9535aaa0804e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0efdf7e947815763e89d08400d8bd32.jpg" align="middle">
</details>




## GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction

**Authors:Xiao Chen, Quanyi Li, Tai Wang, Tianfan Xue, Jiangmiao Pang**

While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action representations. We establish a benchmark using the Isaac Gym simulator with the Houses3K and OmniObject3D datasets to evaluate this NBV policy. Experiments demonstrate that our policy achieves a 98.26% and 97.12% coverage ratio on unseen building-scale objects from these datasets, respectively, outperforming prior solutions. 

[PDF](http://arxiv.org/abs/2402.16174v1) 

**Summary**
äººå·¥æ™ºèƒ½é©±åŠ¨åœºæ™¯é‡å»ºçš„è‡ªåŠ¨åŒ–æ‹æ‘„è¿‡ç¨‹ï¼Œæå‡äº†çœŸå®æ„Ÿï¼Œç®€åŒ–äº†å·¥ä½œ

**Key Takeaways**
- åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–æ‹æ‘„æµç¨‹
- 5Dè‡ªç”±ç©ºé—´æ‰©å±•äº†åŠ¨ä½œèŒƒå›´
- å¤šæºçŠ¶æ€åµŒå…¥å¢å¼ºäº†è·¨æ•°æ®é›†æ³›åŒ–æ€§
- Isaac Gymæ¨¡æ‹Ÿå™¨å»ºç«‹äº†NBVç­–ç•¥è¯„ä¼°åŸºå‡†
- åœ¨Houses3Kå’ŒOmniObject3Dæ•°æ®é›†ä¸Šï¼Œè¦†ç›–ç‡åˆ†åˆ«è¾¾åˆ°98.26%å’Œ97.12%
- ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆ
- é€‚ç”¨äºå¤§å‹åœºæ™¯çš„æ‰«æå’Œäº¤äº’

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šGenNBVï¼šç”¨äºä¸»åŠ¨ 3D é‡å»ºçš„å¯æ³›åŒ–æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥</li>
<li>ä½œè€…ï¼šZiqi Wang, Xinyu Zhang, Tianhao Wu, Yinda Zhang, Xiaogang Jin, Yu Rong, Hui Huang</li>
<li>éš¶å±ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šä¸»åŠ¨ 3D é‡å»ºï¼Œæœ€ä½³ä¸‹ä¸€è§†è§’ï¼Œæ·±åº¦å­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šGenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstructionï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºåœ¨é€¼çœŸæ•°å­—åŒ–å¤§å‹åœºæ™¯æ–¹é¢å–å¾—äº†æœ€æ–°è¿›å±•ï¼Œä½†å›¾åƒæ•æ‰è¿‡ç¨‹ä»ç„¶è€—æ—¶ä¸”è´¹åŠ›ã€‚ä»¥å¾€å·¥ä½œå°è¯•ä½¿ç”¨æœ€ä½³ä¸‹ä¸€è§†è§’ï¼ˆNBVï¼‰ç­–ç•¥æ¥è‡ªåŠ¨æ‰§è¡Œæ­¤è¿‡ç¨‹ä»¥ä¸»åŠ¨è¿›è¡Œ 3D é‡å»ºã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„ NBV ç­–ç•¥ä¸¥é‡ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„æ ‡å‡†ã€æœ‰é™çš„åŠ¨ä½œç©ºé—´æˆ–é’ˆå¯¹ç‰¹å®šåœºæ™¯ä¼˜åŒ–åçš„è¡¨ç¤ºã€‚è¿™äº›é™åˆ¶å› ç´ é™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º GenNBVï¼Œä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„ NBV ç­–ç•¥ã€‚è¯¥ç­–ç•¥é‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ¡†æ¶ï¼Œå¹¶å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ° 5D è‡ªç”±ç©ºé—´ã€‚å®ƒä½¿ä»£ç†æ— äººæœºèƒ½å¤Ÿä»ä»»ä½•è§†ç‚¹è¿›è¡Œæ‰«æï¼Œç”šè‡³åœ¨è®­ç»ƒæœŸé—´ä¸çœ‹ä¸è§çš„å‡ ä½•ä½“è¿›è¡Œäº¤äº’ã€‚ä¸ºäº†æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼šä½¿ç”¨ IsaacGym æ¨¡æ‹Ÿå™¨å’Œ Houses3K åŠ OmniObject3D æ•°æ®é›†å»ºç«‹åŸºå‡†æ¥è¯„ä¼°æ­¤ NBV ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨è¿™äº›æ•°æ®é›†æœªæ›¾è§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å°†ä¸»åŠ¨3Dé‡å»ºé—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œè®¾è®¡æ–°çš„è§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´ï¼›
ï¼ˆ2ï¼‰æå‡ºç«¯åˆ°ç«¯çš„NBVç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ°5Dè‡ªç”±ç©ºé—´ï¼›
ï¼ˆ3ï¼‰æå‡ºä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºï¼Œä»¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›
ï¼ˆ4ï¼‰è®¾è®¡åæ˜ ä¼˜åŒ–ç›®æ ‡çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶è¯¦ç»†è¯´æ˜ç­–ç•¥ä¼˜åŒ–è¿‡ç¨‹ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸»åŠ¨ 3D åœºæ™¯é‡å»ºçš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œå‡å°‘äº†äººå·¥å¹²é¢„çš„éœ€è¦ã€‚å…·ä½“æ¥è¯´ï¼ŒåŸºäºå­¦ä¹ çš„ç­–ç•¥æ¢ç´¢äº†å¦‚ä½•åœ¨è®­ç»ƒé˜¶æ®µé‡å»ºå„ç§å¯¹è±¡ï¼Œä»è€Œèƒ½å¤Ÿä»¥å®Œå…¨è‡ªä¸»çš„æ–¹å¼æ³›åŒ–ä»¥é‡å»ºçœ‹ä¸è§çš„å¯¹è±¡ã€‚æˆ‘ä»¬çš„æ§åˆ¶å™¨åœ¨è‡ªç”±ç©ºé—´ä¸­æœºåŠ¨ï¼Œç„¶ååŸºäºæ··åˆåœºæ™¯è¡¨ç¤ºé€‰æ‹©ä¸‹ä¸€ä¸ªæœ€ä½³è§†å›¾ï¼Œè¯¥è¡¨ç¤ºä¼ è¾¾äº†åœºæ™¯è¦†ç›–çŠ¶æ€ï¼Œä»è€Œå®ç°é‡å»ºè¿›åº¦ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åŒ…æ‹¬ Houses3Kã€OmniObject3D å’Œ Objaverse åœ¨å†…çš„å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨ holdout Houses3K æµ‹è¯•é›†å’Œè·¨åŸŸ OmniObject3D æˆ¿å±‹ç±»åˆ«ä¸Šçš„å®šé‡å’Œå®šæ€§æ³›åŒ–ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºçš„å®Œæ•´æ€§ã€æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢ä¼˜äºå…¶ä»–åŸºçº¿ã€‚æ­¤å¤–ï¼Œåœ¨ Objaverse ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å•ä¸€å»ºç­‘è®¾ç½®ä¸­è®­ç»ƒçš„ç­–ç•¥ç”šè‡³å¯ä»¥æ³›åŒ–åˆ°å¤æ‚çš„æˆ·å¤–åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šGenNBV æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥ï¼Œæ‰©å±•äº†åŠ¨ä½œç©ºé—´ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥æ¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›
æ€§èƒ½ï¼šåœ¨ Houses3K å’Œ OmniObject3D æ•°æ®é›†ä¸Šï¼ŒGenNBV åœ¨æœªè§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆï¼›
å·¥ä½œé‡ï¼šGenNBV çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ä¸åŒçš„åœºæ™¯è¿›è¡Œå¾®è°ƒä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5e8d5c56796ce65689171d3e4517ceb1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3132d23adee2a0316b9fc9d6cad91a0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f46161465b1542e68d3bcde0a29f1da4.jpg" align="middle">
</details>




## NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth   Supervision for Indoor Multi-View 3D Detection

**Authors:Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang**

NeRF-Det has achieved impressive performance in indoor multi-view 3D detection by innovatively utilizing NeRF to enhance representation learning. Despite its notable performance, we uncover three decisive shortcomings in its current design, including semantic ambiguity, inappropriate sampling, and insufficient utilization of depth supervision. To combat the aforementioned problems, we present three corresponding solutions: 1) Semantic Enhancement. We project the freely available 3D segmentation annotations onto the 2D plane and leverage the corresponding 2D semantic maps as the supervision signal, significantly enhancing the semantic awareness of multi-view detectors. 2) Perspective-aware Sampling. Instead of employing the uniform sampling strategy, we put forward the perspective-aware sampling policy that samples densely near the camera while sparsely in the distance, more effectively collecting the valuable geometric clues. 3)Ordinal Residual Depth Supervision. As opposed to directly regressing the depth values that are difficult to optimize, we divide the depth range of each scene into a fixed number of ordinal bins and reformulate the depth prediction as the combination of the classification of depth bins as well as the regression of the residual depth values, thereby benefiting the depth learning process. The resulting algorithm, NeRF-Det++, has exhibited appealing performance in the ScanNetV2 and ARKITScenes datasets. Notably, in ScanNetV2, NeRF-Det++ outperforms the competitive NeRF-Det by +1.9% in mAP@0.25 and +3.5% in mAP@0.50$. The code will be publicly at https://github.com/mrsempress/NeRF-Detplusplus. 

[PDF](http://arxiv.org/abs/2402.14464v1) 7 pages, 2 figures

**Summary**
ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯è¢«åˆ›æ–°åº”ç”¨äºå¢å¼ºå¤šè§†è§’3Dæ£€æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç¤ºå­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†å®¤å†…åœºæ™¯ä¸­çš„3Dæ£€æµ‹æ€§èƒ½ã€‚

**Key Takeaways**
- å‘ç°äº†NeRF-Detå­˜åœ¨è¯­ä¹‰æ­§ä¹‰ã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ç­‰ä¸»è¦ç¼ºé™·ã€‚
- æå‡ºè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
- NeRF-Det++æœ‰æ•ˆè§£å†³äº†NeRF-Detçš„ç¼ºé™·ï¼Œåœ¨ScanNetV2å’ŒARKITScenesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ã€‚
- NeRF-Det++åœ¨ScanNetV2ä¸Šæ¯”NeRF-Detåœ¨mAP@0.25å’ŒmAP@0.50åˆ†åˆ«æé«˜äº†1.9%å’Œ3.5%ã€‚
- ä»£ç å·²å…¬å¼€å‘å¸ƒï¼šhttps://github.com/mrsempress/NeRF-Detplusplusã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><strong>è®ºæ–‡æ ‡é¢˜ï¼š</strong> NeRF-Det++ï¼šèåˆè¯­ä¹‰çº¿ç´¢å’Œè§†ç‚¹æ„ŸçŸ¥æ·±åº¦</li>
<li><strong>ä½œè€…ï¼š</strong> Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang</li>
<li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ï¼Œè®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤</li>
<li><strong>å…³é”®è¯ï¼š</strong> NeRFã€å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡</li>
<li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> https://arxiv.org/abs/2402.14464</li>
<li><strong>æ‘˜è¦ï¼š</strong>
   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> NeRF-Det åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œå®ƒåˆ›æ–°æ€§åœ°åˆ©ç”¨ NeRF å¢å¼ºäº†è¡¨å¾å­¦ä¹ ã€‚
   (2) <strong>è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š</strong> NeRF-Det å­˜åœ¨è¯­ä¹‰æ¨¡ç³Šã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚
   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸‰ä¸ªç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼š<ul>
<li><strong>è¯­ä¹‰å¢å¼ºï¼š</strong> å°†å…è´¹æä¾›çš„ 3D åˆ†å‰²æ³¨é‡ŠæŠ•å½±åˆ° 2D å¹³é¢ï¼Œå¹¶åˆ©ç”¨ç›¸åº”çš„ 2D è¯­ä¹‰å›¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤šè§†å›¾æ£€æµ‹å™¨çš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li><strong>è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼š</strong> æå‡ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li>
<li><strong>æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼š</strong> ä¸ç›´æ¥å›å½’éš¾ä»¥ä¼˜åŒ–çš„æ·±åº¦å€¼ç›¸åï¼Œå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå¹¶å°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œä»è€Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚
   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>
</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è¯­ä¹‰å¢å¼ºï¼šåœ¨NeRF-Detä¸­åŠ å…¥è¯­ä¹‰åˆ†æ”¯Î¦Sï¼Œå°†å‡ ä½•æ¨¡å—Î¦Gç”Ÿæˆçš„ç‰¹å¾h(x)è¾“å…¥Î¦Sï¼Œäº§ç”Ÿè¯­ä¹‰é¢„æµ‹sï¼Œå¹¶åˆ©ç”¨äº¤å‰ç†µæŸå¤±LSegç›‘ç£è¯­ä¹‰å›¾çš„å­¦ä¹ ã€‚
ï¼ˆ2ï¼‰è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼šå°†NeRF-Detä¸­çš„å‡åŒ€é‡‡æ ·ï¼ˆUSï¼‰æ›¿æ¢ä¸ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œåœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚
ï¼ˆ3ï¼‰æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡º NeRF-Det++ï¼Œä¸€ç§ç”¨äºä»å¤šè§†å›¾å›¾åƒè¿›è¡Œå®¤å†… 3D æ£€æµ‹çš„æ–°é¢–æ–¹æ³•ã€‚æˆ‘ä»¬è¯†åˆ«å¹¶è§£å†³äº† NeRF-Det ä¸­çš„ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚é¦–å…ˆï¼Œä¸ºäº†è§£å†³è¯­ä¹‰æ¨¡ç³Šï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰å¢å¼ºæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨è¯­ä¹‰ç›‘ç£æ¥æ”¹å–„åˆ†ç±»ã€‚å…¶æ¬¡ï¼Œä¸ºäº†è§£å†³ä¸é€‚å½“çš„é‡‡æ ·ï¼Œæˆ‘ä»¬é€šè¿‡é€è§†æ„ŸçŸ¥é‡‡æ ·çš„è®¾è®¡ä¼˜å…ˆè€ƒè™‘é™„è¿‘å¯¹è±¡å¹¶åˆ©ç”¨å¤šè§†å›¾çš„ç‰¹æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³æ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç›‘ç£ç»“åˆäº†åºæ•°æ·±åº¦ç®±çš„åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼çš„å›å½’ã€‚åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒéªŒè¯äº†æˆ‘ä»¬ NeRF-Det++ çš„ä¼˜è¶Šæ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>è¯­ä¹‰å¢å¼ºï¼šå¼•å…¥è¯­ä¹‰åˆ†æ”¯ï¼Œåˆ©ç”¨è¯­ä¹‰ç›‘ç£å¢å¼ºè¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>é€è§†æ„ŸçŸ¥é‡‡æ ·ï¼šè®¾è®¡é€è§†æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li>
<li>åºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• NeRF-Det++ï¼Œæ¶‰åŠè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ã€‚</li>
<li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-10b590fb75f1e40d114fb69be9c25a2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffacf9378a148c5b9fac1fd2e03fc268.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-478a5df442fbaaa3a3c020c875f267ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ecbc9426af10136860227da1181ee0cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af160b3a5172d7fc20bcc97ad42a6d6f.jpg" align="middle">
</details>




## Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields

**Authors:Seungtae Nam, Daniel Rho, Jong Hwan Ko, Eunbyung Park**

Despite the remarkable achievements of neural radiance fields (NeRF) in representing 3D scenes and generating novel view images, the aliasing issue, rendering "jaggies" or "blurry" images at varying camera distances, remains unresolved in most existing approaches. The recently proposed mip-NeRF has addressed this challenge by rendering conical frustums instead of rays. However, it relies on MLP architecture to represent the radiance fields, missing out on the fast training speed offered by the latest grid-based methods. In this work, we present mip-Grid, a novel approach that integrates anti-aliasing techniques into grid-based representations for radiance fields, mitigating the aliasing artifacts while enjoying fast training time. The proposed method generates multi-scale grids by applying simple convolution operations over a shared grid representation and uses the scale-aware coordinate to retrieve features at different scales from the generated multi-scale grids. To test the effectiveness, we integrated the proposed method into the two recent representative grid-based methods, TensoRF and K-Planes. Experimental results demonstrate that mip-Grid greatly improves the rendering performance of both methods and even outperforms mip-NeRF on multi-scale datasets while achieving significantly faster training time. For code and demo videos, please see https://stnamjef.github.io/mipgrid.github.io/. 

[PDF](http://arxiv.org/abs/2402.14196v1) Accepted to NeurIPS 2023

**Summary**
åŸºäºç½‘æ ¼è¡¨ç¤ºçš„åèµ°æ · NeRF æ–¹æ³•ï¼Œå®ç°å¿«é€Ÿè®­ç»ƒåŒæ—¶æ¶ˆé™¤æ··å ä¼ªå½±ã€‚

**Key Takeaways**
- mip-Grid å°†åèµ°æ ·æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œè§£å†³äº†æ··å é—®é¢˜ã€‚
- ä½¿ç”¨ç®€å•å·ç§¯æ“ä½œåœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå‡è½»äº†æ··å ä¼ªå½±ã€‚
- ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„å¤šå°ºåº¦ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚
- å°†è¯¥æ–¹æ³•é›†æˆåˆ° TensoRF å’Œ K-Planes ç­‰åŸºäºç½‘æ ¼çš„ NeRF æ–¹æ³•ä¸­ã€‚
- å®éªŒè¡¨æ˜ mip-Grid å¤§å¹…æé«˜äº†ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œåœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šç”šè‡³ä¼˜äº mip-NeRFã€‚
- mip-Grid å®ç°äº†æ˜¾è‘—æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<p>1.æ ‡é¢˜ï¼šMip-Gridï¼šç¥ç»è¾å°„åœºä¸­çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰
2.ä½œè€…ï¼šSeungtae Namã€Daniel Rhoã€Jong Hwan Koã€Eunbyung Park
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½æˆå‡é¦†å¤§å­¦äººå·¥æ™ºèƒ½ç³»ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰
4.å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€æŠ—é”¯é½¿ã€ç½‘æ ¼è¡¨ç¤º
5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.14196
Githubä»£ç é“¾æ¥ï¼šæ— 
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨è¡¨ç¤º3Dåœºæ™¯å’Œç”Ÿæˆæ–°è§†å›¾å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ï¼Œä½†ç°æœ‰çš„æ–¹æ³•ä¸­æ™®éå­˜åœ¨é”¯é½¿é—®é¢˜ï¼Œå³åœ¨ä¸åŒçš„ç›¸æœºè·ç¦»ä¸‹æ¸²æŸ“å‡ºâ€œé”¯é½¿â€æˆ–â€œæ¨¡ç³Šâ€çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šmip-NeRFé€šè¿‡æ¸²æŸ“åœ†é”¥æˆªé”¥ä½“è€Œä¸æ˜¯å°„çº¿æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºMLPæ¶æ„æ¥è¡¨ç¤ºè¾å°„åœºï¼Œé”™å¤±äº†åŸºäºç½‘æ ¼çš„æœ€æ–°æ–¹æ³•æä¾›çš„å¿«é€Ÿè®­ç»ƒé€Ÿåº¦ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šmip-Gridï¼Œä¸€ç§å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­çš„æ–°æ–¹æ³•ï¼Œåœ¨äº«å—å¿«é€Ÿè®­ç»ƒæ—¶é—´çš„åŒæ—¶å‡è½»äº†é”¯é½¿ä¼ªå½±ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³TensoRFå’ŒK-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Gridæå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äºmip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šmip-Grid å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œå°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³ TensoRF å’Œ K-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº† mip-Gridï¼Œä¸€ç§ç”¨äº NeRF çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºã€‚æå‡ºçš„æ–¹æ³•å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œå¹¶ä¸”ä½¿ç”¨æˆ‘ä»¬æ–¹æ³•çš„ä¸¤ç§æ–¹æ³• mip-TensoRF å’Œ mip-K-Planes å·²ç»è¯æ˜å¯ä»¥æœ‰æ•ˆå»é™¤æ··å ä¼ªå½±ã€‚ç”±äºæˆ‘ä»¬ä»å…±äº«çš„ç½‘æ ¼è¡¨ç¤ºä¸­ç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä¸”ä¸ä¾èµ–äºè¶…é‡‡æ ·ï¼Œå› æ­¤æ‰€æå‡ºçš„æ–¹æ³•æœ€å¤§ç¨‹åº¦åœ°å‡å°‘äº†é¢å¤–å‚æ•°çš„æ•°é‡ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„å·¥ä½œä¸ºåˆ©ç”¨ç½‘æ ¼è¡¨ç¤ºçš„è®­ç»ƒæ•ˆç‡ï¼Œæœç€æ— æ··å  NeRF çš„æ–°ç ”ç©¶æ–¹å‘é“ºå¹³äº†é“è·¯ã€‚</p>
</li>
</ol>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šå°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³• TensoRF å’Œ K-Planes ä¸­é›†æˆæå‡ºçš„æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
<p>å·¥ä½œé‡ï¼šmip-Grid æ˜¯ä¸€ç§ç®€å•ä¸”æ˜“äºå®ç°çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è¶…é‡‡æ ·æ­¥éª¤ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f43ff38bcf01c320536c04f1be39506c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcbbb2f379d74a0aeb7179da023c78a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe3f4f6d4cf8758d74cb0be86547e9f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7b2eb107a8f1fa6044a1d951be6c903a.jpg" align="middle">
</details>




