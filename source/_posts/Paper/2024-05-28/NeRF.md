
---
title: NeRF
date: 2024-05-28 02:05:14
author: Kedreamix
cover: https://picx.zhimg.com/v2-46b90894aa28846d98c1eef5c5a89f0c.jpg
categories: Paper
tags:
    - NeRF
description: NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-28  NeRF-Casting Improved View-Dependent Appearance with Consistent   Reflections  
keywords: NeRF
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-05-28 æ›´æ–°


## NeRF-Casting: Improved View-Dependent Appearance with Consistent   Reflections

**Authors:Dor Verbin, Pratul P. Srinivasan, Peter Hedman, Ben Mildenhall, Benjamin Attal, Richard Szeliski, Jonathan T. Barron**

Neural Radiance Fields (NeRFs) typically struggle to reconstruct and render highly specular objects, whose appearance varies quickly with changes in viewpoint. Recent works have improved NeRF's ability to render detailed specular appearance of distant environment illumination, but are unable to synthesize consistent reflections of closer content. Moreover, these techniques rely on large computationally-expensive neural networks to model outgoing radiance, which severely limits optimization and rendering speed. We address these issues with an approach based on ray tracing: instead of querying an expensive neural network for the outgoing view-dependent radiance at points along each camera ray, our model casts reflection rays from these points and traces them through the NeRF representation to render feature vectors which are decoded into color using a small inexpensive network. We demonstrate that our model outperforms prior methods for view synthesis of scenes containing shiny objects, and that it is the only existing NeRF method that can synthesize photorealistic specular appearance and reflections in real-world scenes, while requiring comparable optimization time to current state-of-the-art view synthesis models. 

[PDF](http://arxiv.org/abs/2405.14871v1) Project page: http://nerf-casting.github.io

**Summary**
NeRFæ–¹æ³•é€šè¿‡å…‰çº¿è¿½è¸ªæŠ€æœ¯è§£å†³äº†é«˜åº¦å…‰æ»‘ç‰©ä½“çš„æ¸²æŸ“é—®é¢˜ï¼Œå®ç°äº†é€¼çœŸçš„é•œé¢æ•ˆæœå’Œåå°„ã€‚

**Key Takeaways**
- NeRFæ–¹æ³•æ”¹è¿›äº†æ¸²æŸ“è¿œå¤„ç¯å¢ƒå…‰ç…§ç»†èŠ‚çš„èƒ½åŠ›ï¼Œä½†æ— æ³•åˆæˆè¾ƒè¿‘å†…å®¹çš„ä¸€è‡´åå°„ã€‚
- é‡‡ç”¨å…‰çº¿è¿½è¸ªæŠ€æœ¯ï¼Œä»ç‚¹ä¸ŠæŠ•å°„åå°„å…‰çº¿å¹¶è·Ÿè¸ªå®ƒä»¬é€šè¿‡NeRFè¡¨ç¤ºï¼Œä»¥å‘ˆç°ç‰¹å¾å‘é‡ï¼Œå¹¶ä½¿ç”¨å°å‹å»‰ä»·ç½‘ç»œå°†å…¶è§£ç ä¸ºé¢œè‰²ï¼Œè§£å†³äº†å¤§è§„æ¨¡ç¥ç»ç½‘ç»œçš„ä¼˜åŒ–å’Œæ¸²æŸ“é€Ÿåº¦å—é™çš„é—®é¢˜ã€‚
- è¯¥æ¨¡å‹åœ¨åˆæˆå«æœ‰å…‰äº®ç‰©ä½“åœºæ™¯çš„è§†å›¾åˆæˆæ–¹é¢ä¼˜äºå…ˆå‰æ–¹æ³•ï¼Œæ˜¯å”¯ä¸€å¯ä»¥åœ¨ç°å®åœºæ™¯ä¸­åˆæˆé€¼çœŸçš„é•œé¢æ•ˆæœå’Œåå°„çš„NeRFæ–¹æ³•ï¼Œä¸”æ‰€éœ€ä¼˜åŒ–æ—¶é—´ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**






1. Title: NeRF-Castingï¼šImproved View-Dependent Appearance with Consistent Reflectionsï¼ˆNeRF-Castingï¼šå…·æœ‰consistentåå°„çš„è§†å›¾ç›¸å…³å¤–è§‚æ”¹è¿›ï¼‰

2. Authors: DOR VERBIN, PRATUL P. SRINIVASAN, PETER HEDMAN, BEN MILDENHALL, BENJAMIN ATTAL, RICHARD SZELISKI, JONATHAN T. BARRON

3. Affiliation: è°·æ­Œç¾å›½

4. Keywords: View synthesis, neural radiance fields, reflections

5. Urls: https://nerf-casting.github.io, Github:None

6. Summary:


- (1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯Neural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å¤„ç†å…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡ã€‚

- (2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨å¤§å‹ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿè§†å›¾ç›¸å…³çš„radianceï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼šä¸€æ˜¯åªèƒ½åˆæˆè¿œè·ç¦»ç¯å¢ƒç…§æ˜çš„åå°„ï¼ŒäºŒæ˜¯è®¡ç®—å¼€é”€å¾ˆå¤§ã€‚æœ¬æ–‡çš„æ–¹æ³•motivated byè¿™äº›é—®é¢˜ã€‚

- (3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯åŸºäºray tracingçš„NeRF-Castingï¼Œé€šè¿‡castingåå°„å…‰çº¿å¹¶å°†å…¶è¿½è¸ªåˆ°NeRFè¡¨ç¤ºä¸­ï¼Œç”Ÿæˆç‰¹å¾å‘é‡ï¼Œç„¶åä½¿ç”¨å°å‹ç¥ç»ç½‘ç»œè§£ç æˆé¢œè‰²ã€‚

- (4):æœ¬æ–‡çš„æ–¹æ³•åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­å–å¾—äº†state-of-the-artçš„æ€§èƒ½ï¼Œèƒ½å¤Ÿåˆæˆå…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡çš„åå°„ï¼Œä¸”è®¡ç®—å¼€é”€ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ã€‚





8. Conclusion:

- (1):è¯¥ç¯‡å·¥ä½œçš„æ„ä¹‰åœ¨äºè§£å†³äº†Neural Radiance Fieldsï¼ˆNeRFï¼‰åœ¨è§†å›¾åˆæˆä»»åŠ¡ä¸­çš„åå°„é—®é¢˜ï¼Œæé«˜äº†è§†å›¾ç›¸å…³å¤–è§‚çš„åˆæˆè´¨é‡å’Œæ•ˆç‡ã€‚

- (2):åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºray tracingçš„NeRF-Castingæ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡åå°„ï¼›æ€§èƒ½ï¼šå–å¾—äº†state-of-the-artçš„è§†å›¾åˆæˆæ€§èƒ½ï¼Œèƒ½å¤Ÿåˆæˆå…·æœ‰é«˜é¢‘è§†å›¾ç›¸å…³å¤–è§‚çš„é•œé¢å¯¹è±¡åå°„ï¼›å·¥ä½œè´Ÿè½½ï¼šè®¡ç®—å¼€é”€ä¸å½“å‰æœ€å…ˆè¿›çš„è§†å›¾åˆæˆæ¨¡å‹ç›¸å½“ï¼Œå…·æœ‰è‰¯å¥½çš„å®æ—¶æ€§å’Œå¯æ‰©å±•æ€§ã€‚







<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-323e45f3162c2c7c913df9dc30275d1a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7da742d6de299d161600adf6fdb2df43.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46b90894aa28846d98c1eef5c5a89f0c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2faaf26739f0521731fa46fe33bfa637.jpg" align="middle">
</details>




## Neural Directional Encoding for Efficient and Accurate View-Dependent   Appearance Modeling

**Authors:Liwen Wu, Sai Bi, Zexiang Xu, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi**

Novel-view synthesis of specular objects like shiny metals or glossy paints remains a significant challenge. Not only the glossy appearance but also global illumination effects, including reflections of other objects in the environment, are critical components to faithfully reproduce a scene. In this paper, we present Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects. NDE transfers the concept of feature-grid-based spatial encoding to the angular domain, significantly improving the ability to model high-frequency angular signals. In contrast to previous methods that use encoding functions with only angular input, we additionally cone-trace spatial features to obtain a spatially varying directional encoding, which addresses the challenging interreflection effects. Extensive experiments on both synthetic and real datasets show that a NeRF model with NDE (1) outperforms the state of the art on view synthesis of specular objects, and (2) works with small networks to allow fast (real-time) inference. The project webpage and source code are available at: \url{https://lwwu2.github.io/nde/}. 

[PDF](http://arxiv.org/abs/2405.14847v1) Accepted to CVPR 2024

**Summary**
æå‡ºäº†ä¸€ç§åä¸ºNeural Directional Encodingï¼ˆNDEï¼‰çš„è§†å›¾ç›¸å…³å¤–è§‚ç¼–ç æ–¹æ³•ï¼Œç”¨äºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¸²æŸ“é•œé¢å¯¹è±¡ï¼Œæé«˜äº†å¯¹é«˜é¢‘è§’ä¿¡å·çš„å»ºæ¨¡èƒ½åŠ›ã€‚

**Key Takeaways**
â€¢ é•œé¢å¯¹è±¡çš„æ–°è§†å›¾åˆæˆä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œéœ€è¦è€ƒè™‘å…¨çƒç…§æ˜æ•ˆæœå’Œå…¶ä»–å¯¹è±¡çš„åå°„ã€‚
â€¢ æå‡ºäº†Neural Directional Encodingï¼ˆNDEï¼‰ï¼Œä¸€ç§è§†å›¾ç›¸å…³çš„å¤–è§‚ç¼–ç æ–¹æ³•ï¼Œç”¨äºNeRFæ¸²æŸ“é•œé¢å¯¹è±¡ã€‚
â€¢ NDEå°†ç‰¹å¾ç½‘æ ¼åŸºäºçš„ç©ºé—´ç¼–ç æ¦‚å¿µè½¬ç§»åˆ°è§’åŸŸï¼Œæé«˜äº†å¯¹é«˜é¢‘è§’ä¿¡å·çš„å»ºæ¨¡èƒ½åŠ›ã€‚
â€¢ NDEä½¿ç”¨è§’è¾“å…¥å’Œç©ºé—´ç‰¹å¾æ¥è·å¾—ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ï¼Œè§£å†³äº†æŒ‘æˆ˜æ€§çš„äº¤å‰åå°„æ•ˆæœã€‚
â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨NDEçš„NeRFæ¨¡å‹åœ¨é•œé¢å¯¹è±¡çš„è§†å›¾åˆæˆæ–¹é¢ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
â€¢ ä½¿ç”¨å°ç½‘ç»œå¯ä»¥å®ç°å¿«é€Ÿï¼ˆå®æ—¶ï¼‰æ¨ç†ã€‚
â€¢ é¡¹ç›®ç½‘é¡µå’Œæºä»£ç å·²ç»å…¬å¼€ï¼Œç½‘å€ä¸ºhttps://lwwu2.github.io/nde/ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**




1. Title: ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNeural Directional Encodingï¼‰

2. Authors: Liwen Wu, Sai Bi, Zexiang Xu, Fujun Luan, Kai Zhang, Iliyan Georgiev, Kalyan Sunkavalli, Ravi Ramamoorthi

3. Affiliation: åŠ å·å¤§å­¦åœ£åœ°äºšå“¥åˆ†æ ¡ï¼ˆUC San Diegoï¼‰

4. Keywords: Neural Radiance Fields, View-Dependent Appearance, Specular Objects, Novel-View Synthesis

5. Urls: https://lwwu2.github.io/nde/, Github:None

6. Summary:


- (1):æœ¬æ–‡ç ”ç©¶èƒŒæ™¯æ˜¯æ–°è§†å›¾åˆæˆé¢†åŸŸï¼Œç‰¹åˆ«æ˜¯ specular å¯¹è±¡çš„æ–°è§†å›¾åˆæˆï¼Œæ—¨åœ¨æ¢å¤ç‰©ä½“çš„é«˜é¢‘è§†å›¾ä¾èµ–å¤–è§‚å’Œå…¨çƒç…§æ˜æ•ˆæœã€‚

- (2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨åˆ†æå‡½æ•°å¯¹è§†å›¾æ–¹å‘è¿›è¡Œç¼–ç ï¼Œéœ€è¦å¤§å‹å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ï¼Œæ— æ³•æ¨¡æ‹Ÿå¤æ‚çš„åå°„æ•ˆæœã€‚è¿™äº›æ–¹æ³•ä¹Ÿå¿½è§†äº†ç©ºé—´ç‰¹å¾å¯¹è§†å›¾ä¾èµ–å¤–è§‚çš„å½±å“ã€‚

- (3):æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNDEï¼‰æ–¹æ³•ï¼Œå°†ç‰¹å¾ç½‘æ ¼ç¼–ç æ¦‚å¿µåº”ç”¨äºè§’åº¦åŸŸï¼Œé€šè¿‡ Ù…Ø®Ø±ÙˆØ·è¿½è¸ªç©ºé—´ç‰¹å¾è·å–ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ï¼Œè§£å†³äº† interreflection æ•ˆæœçš„æŒ‘æˆ˜ã€‚

- (4):æœ¬æ–‡æ–¹æ³•åœ¨åˆæˆ specular å¯¹è±¡çš„æ–°è§†å›¾ä»»åŠ¡ä¸Šå–å¾—äº† state-of-the-art çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨å°å‹ç½‘ç»œå®ç°å®æ—¶æ¨ç†ï¼Œæ»¡è¶³äº†å¿«é€Ÿåˆæˆçš„éœ€æ±‚ã€‚
7. Methods:

   - (1): è¯¥æ–¹æ³•ä½¿ç”¨ç¥ç»æ–¹å‘ç¼–ç ï¼ˆNDEï¼‰æ¥å¯¹ç‰¹å¾ç½‘æ ¼è¿›è¡Œè§’åº¦åŸŸçš„ç¼–ç ï¼Œé€šè¿‡Ù…Ø®Ø±ÙˆØ·è¿½è¸ªç©ºé—´ç‰¹å¾è·å–ç©ºé—´å˜åŒ–çš„æ–¹å‘ç¼–ç ã€‚
   
   - (2): NDEæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè§£å†³interreflectionæ•ˆæœçš„æŒ‘æˆ˜ï¼Œæ¢å¤ç‰©ä½“çš„é«˜é¢‘è§†å›¾ä¾èµ–å¤–è§‚å’Œå…¨çƒç…§æ˜æ•ˆæœï¼Œè€Œæ— éœ€ä½¿ç”¨å¤§å‹å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚

   - (3): è¯¥æ–¹æ³•å…·æœ‰å®æ—¶æ¨ç†çš„èƒ½åŠ›ï¼Œå¯ä»¥ä½¿ç”¨å°å‹ç½‘ç»œå®ç°å¿«é€Ÿåˆæˆï¼Œå¹¶åœ¨åˆæˆspecularå¯¹è±¡çš„æ–°è§†å›¾ä»»åŠ¡ä¸Šå–å¾—äº†state-of-the-artçš„æ€§èƒ½ã€‚





8. Conclusion: 

   - (1):This piece of work is significant in advancing the field of novel-view synthesis, particularly in the synthesis of specular objects, by introducing a novel method, Neural Directional Encoding (NDE), which efficiently models complex reflections and achieves state-of-the-art performance.
     
   - (2):Innovation point: The article innovatively introduces the NDE method to efficiently model complex reflections for novel-view synthesis, addressing the limitations of previous methods. 
     Performance: The proposed method achieves state-of-the-art performance in synthesizing specular objects with the ability for real-time inference using a small network. 
     Workload: The workload is reduced as the method eliminates the need for large multi-layer perceptrons and enables real-time synthesis.







<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b069231775fc8a2bd10f93cb80d839ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-75b217587db527ee5663a4499270caf9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-abc9cca95d286eab225c623b7babb05b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2fce7139aa953d9627454cfadef62958.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-87061bf3e19ae720c7a849195745380a.jpg" align="middle">
</details>




## Camera Relocalization in Shadow-free Neural Radiance Fields

**Authors:Shiyao Xu, Caiyun Liu, Yuantao Chen, Zhenxin Zhu, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou**

Camera relocalization is a crucial problem in computer vision and robotics. Recent advancements in neural radiance fields (NeRFs) have shown promise in synthesizing photo-realistic images. Several works have utilized NeRFs for refining camera poses, but they do not account for lighting changes that can affect scene appearance and shadow regions, causing a degraded pose optimization process. In this paper, we propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization. We implement our scene representation upon a hash-encoded NeRF which significantly boosts up the pose optimization process. To account for the noisy image gradient computing problem in grid-based NeRFs, we further propose a re-devised truncated dynamic low-pass filter (TDLF) and a numerical gradient averaging technique to smoothen the process. Experimental results on several datasets with varying lighting conditions demonstrate that our method achieves state-of-the-art results in camera relocalization under varying lighting conditions. Code and data will be made publicly available. 

[PDF](http://arxiv.org/abs/2405.14824v1) Accepted by ICRA 2024. 8 pages, 5 figures, 3 tables. Codes and   dataset: https://github.com/hnrna/ShadowfreeNeRF-CameraReloc

**Summary**
æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µæµæ°´çº¿ï¼Œç”¨äºè§„èŒƒå…·æœ‰ä¸åŒå…‰ç…§å’Œé˜´å½±æ¡ä»¶çš„å›¾åƒï¼Œä»¥æ”¹å–„ç›¸æœºé‡å®šä½ï¼Œå®ç°äº†åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹ç›¸æœºé‡å®šä½çš„æœ€æ–°æˆæœã€‚

**Key Takeaways**
- ç›¸æœºé‡å®šä½åœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººé¢†åŸŸæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚
- è¿‘æœŸå…³äºç¥ç»è¾å°„åœºï¼ˆNeRFsï¼‰çš„è¿›å±•æ˜¾ç¤ºå‡ºåˆæˆé€¼çœŸå›¾åƒçš„æ½œåŠ›ã€‚
- ä¹‹å‰çš„å·¥ä½œåˆ©ç”¨NeRFsä¼˜åŒ–ç›¸æœºå§¿æ€ï¼Œä½†æœªè€ƒè™‘å¯èƒ½å½±å“åœºæ™¯å¤–è§‚å’Œé˜´å½±åŒºåŸŸçš„å…‰ç…§å˜åŒ–ï¼Œå¯¼è‡´å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ä¸‹é™ã€‚
- è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå“ˆå¸Œç¼–ç çš„NeRFæ¥å®ç°åœºæ™¯è¡¨ç¤ºï¼Œæ˜¾è‘—æå‡äº†å§¿æ€ä¼˜åŒ–è¿‡ç¨‹ã€‚
- ä¸ºè§£å†³ç½‘æ ¼å‹NeRFä¸­çš„å™ªå£°å›¾åƒæ¢¯åº¦è®¡ç®—é—®é¢˜ï¼Œè¿›ä¸€æ­¥æå‡ºäº†é‡æ–°è®¾è®¡çš„æˆªæ–­åŠ¨æ€ä½é€šæ»¤æ³¢å™¨ï¼ˆTDLFï¼‰å’Œæ•°å€¼æ¢¯åº¦å¹³å‡æŠ€æœ¯æ¥å¹³æ»‘å¤„ç†ã€‚
- åœ¨å¤šä¸ªå…·æœ‰ä¸åŒå…‰ç…§æ¡ä»¶çš„æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹çš„ç›¸æœºé‡å®šä½ä¸­å–å¾—äº†æœ€æ–°çš„æˆæœã€‚
- ä»£ç å’Œæ•°æ®å°†å…¬å¼€å‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**






1. Title: ç›¸æœºé‡å®šä½åœ¨æ— é˜´å½±ç¥ç»è¾å°„åœºä¸­ï¼ˆCamera Relocalization in Shadow-free Neural Radiance Fieldsï¼‰

2. Authors: Shiyao Xu, Caiyun Liu, Yuantao Chen, Zhenxin Zhu, Zike Yan, Yongliang Shi, Hao Zhao, Guyue Zhou

3. Affiliation: æ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢

4. Keywords: Camera Relocalization, Neural Radiance Fields, Shadow Removal

5. Urls: arXiv:2405.14824v1, Github: None

6. Summary:

    - (1):æœ¬æ–‡ç ”ç©¶çš„èƒŒæ™¯æ˜¯è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººå­¦é¢†åŸŸä¸­çš„ç›¸æœºé‡å®šä½é—®é¢˜ï¼Œç›®æ ‡æ˜¯ä»ç»™å®šçš„å›¾åƒä¸­æ¢å¤æ‘„åƒæœºçš„ä½å§¿ã€‚

    - (2):è¿‡å»çš„æ–¹æ³•ä½¿ç”¨åˆ¤åˆ«ç½‘ç»œæˆ–NeRFæ¥refineæ‘„åƒæœºä½å§¿ï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•ä¸èƒ½å¤„ç†å…‰ç…§å˜åŒ–å’Œé˜´å½±åŒºåŸŸå¯¹åœºæ™¯å¤–è§‚çš„å½±å“ï¼Œå¯¼è‡´ä½å§¿ä¼˜åŒ–è¿‡ç¨‹ä¸ç¨³å®šã€‚

    - (3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„pipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œå¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œç„¶åä½¿ç”¨hashç¼–ç çš„NeRFæ¥refineæ‘„åƒæœºä½å§¿ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ”¹è¿›çš„æ¢¯åº¦è®¡ç®—æ–¹æ³•æ¥å¹³æ»‘ä¼˜åŒ–è¿‡ç¨‹ã€‚

    - (4):å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº† state-of-the-art çš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚
7. æ–¹æ³•ï¼š

- (1)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„pipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œï¼ˆShadow Removal Networkï¼ŒNshadowï¼‰å¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œå¾—åˆ°é˜´å½±-freeå›¾åƒI(l0)ã€‚

- (2)ï¼šç„¶åï¼Œä½¿ç”¨hashç¼–ç çš„NeRFï¼ˆNeural Radiance Fieldsï¼‰æ¨¡å‹å¯¹é˜´å½±-freeå›¾åƒI(l0)è¿›è¡Œåœºæ™¯é‡å»ºï¼Œå¾—åˆ°ä¸‰ç»´ç¥ç»åœºæ™¯å›¾Fã€‚

- (3)ï¼šåœ¨poseä¼˜åŒ–é˜¶æ®µï¼Œä½¿ç”¨åŒæ ·çš„é˜´å½±ç§»é™¤ç½‘ç»œNshadowå¯¹æµ‹è¯•å›¾åƒè¿›è¡Œé˜´å½±ç§»é™¤ï¼Œå¾—åˆ°é˜´å½±-freeæµ‹è¯•å›¾åƒI(l0)ï¼Œç„¶åä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•ä¼˜åŒ–æ‘„åƒæœºposeï¼Œç›´åˆ°æ¸²æŸ“å›¾åƒË†I(l0)ä¸é˜´å½±-freeæµ‹è¯•å›¾åƒI(l0)ä¹‹é—´çš„å…‰åº¦lossè¾¾åˆ°æœ€å°ã€‚

- (4)ï¼šä¸ºäº†æé«˜poseä¼˜åŒ–çš„ç¨³å®šæ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„æ¢¯åº¦è®¡ç®—æ–¹æ³•ï¼Œä½¿ç”¨numerical gradient averagingæŠ€æœ¯æ¥å¹³æ»‘ä¼˜åŒ–è¿‡ç¨‹ã€‚

- (5)ï¼šåœ¨poseä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œæ–‡è¿˜ä½¿ç”¨äº†ä¸€ç§ç²—åˆ°ç»†çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä½¿ç”¨truncated dynamic low-pass filterï¼ˆTDLFï¼‰æ¥åˆ†ç¦»é«˜é¢‘å’Œä½é¢‘å›¾åƒç»„ä»¶ï¼Œå¹¶é€æ¸å¢åŠ é«˜é¢‘ç»„ä»¶çš„æƒé‡ï¼Œä»¥é¿å…å±€éƒ¨æœ€ä¼˜è§£ã€‚

- (6)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†state-of-the-artçš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚





8. Conclusion:

- (1):æœ¬æ–‡çš„å·¥ä½œå¯¹äºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººå­¦é¢†åŸŸä¸­çš„ç›¸æœºé‡å®šä½é—®é¢˜å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿåœ¨æ— é˜´å½±ç¥ç»è¾å°„åœºä¸­å®ç°é«˜ç²¾åº¦çš„æ‘„åƒæœºé‡å®šä½ï¼Œä»è€Œæé«˜æœºå™¨äººçš„å¯¼èˆªå’Œå®šä½èƒ½åŠ›ã€‚

- (2):Innovation point: æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä¸¤é˜¶æ®µpipelineï¼Œé¦–å…ˆä½¿ç”¨é˜´å½±ç§»é™¤ç½‘ç»œå¯¹å›¾åƒè¿›è¡Œ normalizationï¼Œç„¶åä½¿ç”¨hashç¼–ç çš„NeRFæ¨¡å‹å¯¹é˜´å½±-freeå›¾åƒè¿›è¡Œåœºæ™¯é‡å»ºï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†å…‰ç…§å˜åŒ–å’Œé˜´å½±åŒºåŸŸå¯¹åœºæ™¯å¤–è§‚çš„å½±å“Performance: å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº† state-of-the-art çš„ç»“æœï¼Œè¯æ˜äº†å…¶åœ¨ç›¸æœºé‡å®šä½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼›Workload: æœ¬æ–‡çš„æ–¹æ³•éœ€è¦åœ¨è®­ç»ƒå’Œæµ‹è¯•é˜¶æ®µè¿›è¡Œå¤§é‡çš„è®¡ç®—å’Œä¼˜åŒ–ï¼Œéœ€è¦é«˜æ€§èƒ½çš„è®¡ç®—è®¾å¤‡å’Œå¤§é‡çš„æ•°æ®é›†æ”¯æŒã€‚







<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6d260d5b744a5039554f8c6aaee9bc01.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0ac90b20b3733ad747ec11650e963cf5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5a7748ef501582a143e2301b2e39f951.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0770bb34500dd5dd1e4632f197e96d71.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fdb4265248fa23783d77c10c673a037.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1113a2498657772fa4f4f86d7876ebfc.jpg" align="middle">
</details>






