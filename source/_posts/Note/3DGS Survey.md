# 3DGS综述：A Survey on 3D Gaussian Splatting


今天想介绍的是`ZJU`带来的`3DGS`的首篇综述`A Survey on 3D Gaussian Splatting` 这是论文链接 [arXiv:2401.03890](https://arxiv.org/abs/2401.03890)

趁这个机会好好学习一下3DGS，加油入坑！！！

首先说一些自己的理解，3DGS之所以爆火，很大程度在于他的实时性，而这一部分极大程度得益于他定制的算法与自定义 CUDA 内核。除此之外，**Gaussian Splatting**根本不涉及任何神经网络，甚至没有一个小型的 MLP，也没有什么 "神经"的东西，场景本质上只是空间中的一组点。在大家都在研究数十亿个参数组成的模型的人工智能世界里，这种方法越来越受欢迎，令人耳目一新。它的想法源于 "Surface splatting"（2001 年），说明经典的计算机视觉方法仍然可以激发相关的解决方案。它简单明了的表述方式使**Gaussian Splatting**特别容易解释，这也是为什么在某些应用中选择它而不是 NeRFs。

## 引言 INTRODUCTION

NeRF自从2020年开始，在多视角合成中做出来巨大的贡献，他利用神经网络，实现了空间坐标到颜色和密度的映射的，然NeRF的方法是计算密集型的，通常需要大量的训练时间和大量的渲染资源，特别是高分辨率的输出。

![NeRF](https://pic1.zhimg.com/80/v2-c828848317a156fc6dd17c9a5310dd03.png)

针对这些问题，3DGS出现了，3DGS 采用显式表示和高度并行的工作流程，有利于更高效的计算和渲染，其创新在于其独特地融合了可微分管道和基于点的渲染技术的优点，通过用可学习的 3D 高斯函数表示场景，保留了连续体积辐射场的理想特性，这对于高质量图像合成至关重要，同时避免了与空白空间渲染相关的计算开销，这是传统 NeRF 方法的常见缺点，而3DGS很好的解决了这个问题，在不影响视觉质量的情况下达到了实时渲染。

论文中也发现，自3DGS出现以来，2023年有很多的论文在arXiv中挂出来，所以基于此也写了这样一个综述，同时促进3DGS领域的进一步研究和创新

![The number of papers on 3D GS is increasing every month.](https://picx.zhimg.com/80/v2-167cd8779af5c5550c15156e2b9b52c0.png)

以下是论文架构的图，论文的大概架构如下所示，可以看到这篇综述撰写的一个逻辑，还是非常好的，接下来，我会顺着这个架构进行解读论文来学习

- 第2部分：主要是一些问题描述和相关研究领域的一些简要的背景
- 第3部分：介绍3DGS，包括3DGS的多视角的合成和3DGS的优化
- 第4部分：3DGS 产生重大影响的各种应用领域和任务，展示了其多功能性
- 第5部分：对3DGS进行了一些比较和分析
- 第6、7部分：对一些未来的开放性工作进行总结和调查

![Structure of the overall review.](https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png)



## 背景 BACKGROUND

背景主要分两部分讲解

- 辐射场的概念：隐式和显式
- 有关辐射场的场景重建、渲染等领域相关介绍

### 问题定义

#### 辐射场

辐射场是实际上是对三维空间中光分布的表示，它捕捉了光与环境中的表面和材质相互作用的方式。从数学上来说，辐射场可被描述为一个函数$L:\mathbb{R}^5\to\mathbb{R}^+$, 其中$L(x,y,z,\theta,\psi)$将点$(x,y,z)$和球坐标下的方向$(\theta,\phi)$映射为非负的辐射值。辐射场有显示表达和隐式表达，可用于场景表示和渲染。



#### 隐式辐射场

隐式辐射场是辐射场中的一种，在表示场景中的光分布时，不需显式定义场景的集合形状。这里面最常见的就是NeRF，使用神经网络来学习连续的体积表示。在NeRF中，使用MLP 网络用于将一组空间坐标 $(x, y, z)$ 和观察方向 $(\theta,\phi)$ 映射到颜色和密度值。任何点处的辐射不是显式存储的，而是通过查询神经网络实时计算得出。因此，该函数可以写成：
$$
L_\text{implicit}(x,y,z,\theta,\phi)=\text{NeuralNetwork}(x,y,z,\theta,\phi)
$$
这种方式的好处是构建了一个可微且紧凑的复杂场景，但是由于我们总是需要对光线进行采样和体渲染的计算，会导致计算负载比较高。



#### 显式辐射场

与隐式不同的是，显示是直接表示光在离散空间结构中的分布，比如体素网格或点云。该结构中的每个元素都存储了其在空间中相应位置的辐射信息，而不是像NeRF一样去执行查询的操作，所以他会更直接也更快的得到每个值，但是同时也需要更大内存使用和导致较低的分辨率。通常我们可以表示为：
$$
L_\text{explicit}{ ( x , y , z , \theta , \phi ) }=\text{DataStructure}[(x,y,z)]\cdot f(\theta,\phi)
$$
其中，`DataStructure`可以是网格或点云，而$f(θ, ϕ)$是一个根据观察视线方向修改辐射的函数。

#### 3D Gaussian Splatting （两全其美）

3DGS通过利用3D 高斯函数作为其表示形式，充分利用了显示辐射场和隐式辐射场的优势。这些高斯函数被优化用于准确表示场景，结合了基于神经网络的优化和显式结构化数据存储的优点。这种混合方法能进行高质量渲染，同时具有更快的训练和实时性能，3D高斯表达可表示为：
$$
L_{\mathrm{3DGS}}(x,y,z,\theta,\phi)=\sum_{i}G(x,y,z,\mu_{i},\Sigma_{i})\cdot c_{i}(\theta,\phi)
$$
其中 $G$ 是具有平均值 $μ_i$ 和协方差 $Σ_i$ 的高斯函数，$c$ 表示与视图相关的颜色。



这里放一张理解显示隐式图像的图片，我还是觉得相当不错的

![显式隐式表达](https://pic1.zhimg.com/80/v2-e79d0183806753d34863598e544a0517.jpeg)



### 背景和术语

许多技术和研究学科与 `3DGS` 有着密切的关系，以下各节将对此进行简要介绍。



#### 场景重建与渲染

**场景重建**：从一组图像集合或其它数据建立场景的三维模型。

**渲染**：将计算机可读取的信息（如场景中的3D物体）转化为图像。
早期技术基于光场生成逼真的图像，运动结构（SfM）与多视图立体匹配（MVS）算法通过从图像序列估计3D结构来增强光场。



#### 神经渲染和辐射场

**神经渲染**：将深度学习与传统图形技术结合生成逼真的图像。早期方法使用CNN估计混合权重或纹理空间解决方案。

**辐射场**：一种函数表达，描述从各方向穿过空间各点的光的量。NeRF使用神经网络建模辐射场。



#### 体积表示和光线行进

**体积表达**：不仅将物体和场景建模为表面，还将其其建模为充满材料或空白空间的体积。这样可以对如雾、烟或半透明材料进行更精确的渲染。

**光线行进**：是体积表达渲染图像的技术，通过增量跟踪穿过“体”的光线来渲染图像。NeRF引入重要性采样和位置编码增强合成图像的质量，虽然能得到高质量的图像，但这一方法计算量大。



#### 基于点的渲染

基于点的渲染是一种使用点而非传统多边形来可视化3D场景的技术。该方法特别适用于渲染复杂、非结构化或稀疏的几何数据。点可以通过添加额外属性，如可学习的神经描述符来进行增强，并且可以高效地进行渲染，但这种方法可能会出现渲染中的空洞或混叠效应等问题。3DGS通过使用各向异性高斯进行更连贯的场景表达。



## 用于显式辐射场的3DGS

3DGS能够实时渲染高分辨率的图像，并且不需要神经网络，是一个突破。

这一块主要围绕两块进行讲解

- 3DGS的前向过程
- 3DGS的优化过程



### 学习3D高斯函数进行新视角合成

假如现在有一个场景，目的是生成特定视角下的相机图像。NeRF对每一个像素使用光线行进和采样点，影响其实时性；而3DGS将3D高斯投影到图像平面，称为“泼溅”，如下图所示。然后对高斯进行排序并计算每个像素的值。NeRF和3DGS的渲染可视为互逆关系。

![3DGS的Splatting 泼溅](https://pic1.zhimg.com/80/v2-9d5fff5c2390526cd03e5a14fd13f4fe.png)

首先简单介绍一下，3DGS是如何表示真实场景的，前面也有提过，在**Gaussian Splatting**中，3D世界用一组3D点表示，实际上是数百万个，大致在0.5到5百万之间。每个点是一个3D高斯，具有其独特的参数，这些参数是为每个场景拟合的，以便该场景的渲染与已知数据集图像紧密匹配，接下来就介绍他的属性。

![Representing a 3D world](https://pica.zhimg.com/80/v2-f440b37ac00a08977b2b6e5514ffec1f.png)



- **3D高斯的属性**： 一个3D高斯主要包括，中心（位置）$x,y,z$的均值$μ$、不透明度 $α$、3D 协方差矩阵 $Σ$ 和颜色 $c$（一般是RGB或者是球谐（SH）系数）。 其中$c$与视角有关，$c$ 由球谐函数表示。所有属性均可学习，都可以通过反向传播来学习和优化。

- **视域剔除**：给定特定的相机姿态，该步骤会判断哪些高斯位于相机的视锥外，并在后续步骤中剔除之，以节省计算。

- **Splatting泼溅**：实际上只是3D高斯（椭圆体）投影到2D图像空间（椭圆）中进行渲染。给定视图变换 $W$ 和3D协方差矩阵$\Sigma$，我们可以使用使用以下公式计算投影 2D 协方差矩阵 $\Sigma^{\prime}$
  $$
  \Sigma^{\prime}=JW\Sigma W^\top J^\top
  $$
  其中 $J$ 为投影变换中仿射近似的雅可比矩阵。

- **像素渲染**：如果不考虑并行，采用最简单的方式：给定像素 $x$ 的位置，与其到所有重叠高斯函数的距离，即这些高斯函数的深度。这些可以通过观察变换 $W$ 计算出来，形成高斯函数的排序列表$N$。然后进行alpha混合，计算该像素的最终颜色：
  $$
  C=\sum_{i\in\mathcal{N}}c_i\alpha_i^{\prime}\prod_{j=1}^{i-1}\left(1-\alpha_j^{\prime}\right.)
  $$
  其中 $c_i$ 是学习到的颜色，最终的不透明度 $\alpha_i^{\prime}$ 是学习的不透明度 $\alpha_i$ 与高斯的乘积:
  $$
  \alpha_i'=\alpha_i\times\exp\left(-\frac12(x'-\mu_i')^\top\Sigma_i'^{-1}(x'-\mu_i')\right)
  $$
  其中 $x'$ 和 $μ'_i$ 是投影空间中的坐标，同时我也找了个gif来可视化了一下Gaussian Splatting对位置p的影响：

  ![3DGS](3DGS.gif)

  如果仔细看的话，我们会发现，实际上这个公式和[多变量正态分布的概率密度函数](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)十分相像，是忽略了带有协方差行列式的标准化项，而是用不透明度来加权。
  $$
  (2\pi)^{-k/2}\det(\boldsymbol{\Sigma})^{-1/2}\exp\biggl(-\frac12(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T}\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\biggr)
  $$
  
  
  不过如果考虑并行的话加快速度，这种列表排序实际上很难并行化，所以很有可能这个渲染程度比NeRF还慢。为了实现实时渲染，3DGS也做了一个tradeoff，3DGS做出了一些让步来适应**并行计算**。
  
  ![Tiles(Patches)](https://picx.zhimg.com/80/v2-7cea6c4b183982cd921c0456d1f689b7.png)
  
- **Tiles (Patches)**：为避免逐像素计算出现的成本，3DGS改为**patch**级别的渲染。具体来说，首先将图像分割为多个不重叠的patch，称为`tile`，每个图块包含 16×16 像素，如下图所示。3DGS然后确定`tile`与投影高斯的相交情况，由于投影高斯可能会与多个`tile`相交，需要进行复制，并为每个复制体分配相关tile的标识符（如`tile`的ID）。(不用判断每个像素与高斯的距离，而是判断tile就简单多了)
  
  ![3DGS排序](https://pic1.zhimg.com/80/v2-5c74958d484c1d2588c20c8c30b58411.png)
  
  ![3DGS排序例子](https://picx.zhimg.com/80/v2-3d6e3aec3a86c1d94354458830dbf17f.png)
  
- **并行渲染**：复制后，3DGS（对应字节的无序列表）结合包含了相关的tile ID（对应字节的高位）和深度信息（对应字节的低位），如上图所示。由于每一块和每一像素的计算是独立的，所以可以基于CUDA编程的块和线程来实现并行计算，同时有利于访问公共共享内存并保持统一的读取顺序。排序后的列表可直接用于渲染（alpha混合），如下图所示。
  
  ![并行渲染](https://pic1.zhimg.com/80/v2-6393ea51f715d0d0baa880cd1890a549.png)
  
  总的来说，3DGS在前向过程中做出了一些近似计算，以提高计算效率并保留图像合成的高质量。
  
  
  
### 3DGS的优化

3DGS的核心是**3D高斯集合的优化过程**。一方面需要通过可微渲染来使高斯符合场景纹理，另一方面表达场景需要的高斯数量是未知的。这分别对应参数优化与密度控制两步，这两步在优化过程中交替进行。优化过程中，需要手动设置很多超参数。

#### 参数优化 Parameter Optimization

- **损失函数**：图像合成后，计算渲染图像与真实图像的差异作为损失：
  $$
  \mathcal{L}=(1-\lambda)\mathcal{L}_1+\lambda\mathcal{L}_{D-SSIM}
  $$
  其中 $λ$ 是权重因子。与 NeRF 的损失函数略有不同，由于光线行进成本高昂，NeRF 通常在像素级别而不是图像级别进行计算，而3DGS是图像级别的。

- **参数更新**：3D高斯的多数参数可通过反向传播直接更新，但对于协方差矩阵 $\Sigma$来说，需要半正定矩阵，直接优化可能会产生非半正定矩阵，而只有半正定矩阵才有物理意义。因此，改为优化四元数$q$和3D向量$s$。将协方差矩阵分解：
  $$
  \Sigma=RSS^\top R^\top
  $$
  其中$R$与$S$分别由$q$和$s$推导得到的旋转和缩放矩阵。对于不透明度$α$, 其计算图较为复杂：$(q,s)\to\Sigma\to\Sigma^{\prime}\to\alpha$。为避免自动微分的计算消耗，3DGS还推导了$q$与$s$的梯度，在优化过程中直接计算之。
  
  

#### 密度控制 Density Control

- **初始化**：3DGS从SfM产生的稀疏点云初始化或随机初始化高斯。然后进行点的密集化和剪枝以控制3D高斯的密度。
- **点密集化**：在点密集化阶段，3DGS自适应地增加高斯的密度，以更好地捕捉场景的细节。该过程特别关注缺失几何特征或高斯过于分散的区域。密集化在一定数量的迭代后执行，针对在视图空间中具有较大位置梯度（即超过特定阈值）的高斯。其包括在未充分重建的区域克隆小高斯或在过度重建的区域分裂大高斯。对于克隆，创建高斯的复制体并朝着位置梯度移动。对于分裂，用两个较小的高斯替换一个大高斯，按照特定因子减小它们的尺度。这一步旨在在3D空间中寻求高斯的最佳分布和表示，增强重建的整体质量。
- **点的剪枝**：点的剪枝阶段移除冗余或影响较小的高斯，可以在某种程度上看作是一种正则化过程。一般消除几乎是透明的高斯（α低于指定阈值）和在世界空间或视图空间中过大的高斯。此外，为防止输入相机附近的高斯密度不合理地增加，这些高斯会在固定次数的迭代后将$\alpha$设置为接近0的值。该步骤在保证高斯的精度和有效性的情况下，能节约计算资源。



![](https://picx.zhimg.com/80/v2-58c80507588563289c26e2ea4066ad81.png)



  ![](https://miro.medium.com/v2/resize:fit:1400/0*rT4bEjhOZyCUqBuR)

![](https://cdj-happier.github.io/post-images/1671367950309.png)





![3DGS前向过程图解](https://pic1.zhimg.com/80/v2-12ef6f1896b86a772028e27774da2c5d.png)

参考文献

- https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362