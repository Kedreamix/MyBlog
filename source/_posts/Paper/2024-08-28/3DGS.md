
---
title: 3DGS
date: 2024-08-28 08:09:07
author: Kedreamix
cover: https://picx.zhimg.com/v2-b72c589cdf9131b150d1c25d4921e305.jpg
categories: Paper
tags:
    - 3DGS
description: 3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-08-28  Avatar Concept Slider Manipulate Concepts In Your Human Avatar With   Fine-grained Control  
keywords: 3DGS
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-08-28 æ›´æ–°


## Avatar Concept Slider: Manipulate Concepts In Your Human Avatar With   Fine-grained Control

**Authors:Yixuan He, Lin Geng Foo, Ajmal Saeed Mian, Hossein Rahmani, Jun Jiu**

Language based editing of 3D human avatars to precisely match user requirements is challenging due to the inherent ambiguity and limited expressiveness of natural language. To overcome this, we propose the Avatar Concept Slider (ACS), a 3D avatar editing method that allows precise manipulation of semantic concepts in human avatars towards a specified intermediate point between two extremes of concepts, akin to moving a knob along a slider track. To achieve this, our ACS has three designs. 1) A Concept Sliding Loss based on Linear Discriminant Analysis to pinpoint the concept-specific axis for precise editing. 2) An Attribute Preserving Loss based on Principal Component Analysis for improved preservation of avatar identity during editing. 3) A 3D Gaussian Splatting primitive selection mechanism based on concept-sensitivity, which updates only the primitives that are the most sensitive to our target concept, to improve efficiency. Results demonstrate that our ACS enables fine-grained 3D avatar editing with efficient feedback, without harming the avatar quality or compromising the avatar's identifying attributes. 

[PDF](http://arxiv.org/abs/2408.13995v1) 

**Summary**
åŸºäºè¯­ä¹‰æ¦‚å¿µçš„3Däººå¶ç¼–è¾‘æ–¹æ³•ï¼Œé€šè¿‡Avatar Concept Sliderï¼ˆACSï¼‰å®ç°ç²¾ç¡®ç¼–è¾‘ï¼Œæœ‰æ•ˆæå‡äº†äººå¶è´¨é‡å’Œèº«ä»½ç‰¹å¾çš„ä¿ç•™ã€‚

**Key Takeaways**
1. è‡ªç„¶è¯­è¨€ç¼–è¾‘3Däººå¶å­˜åœ¨æŒ‘æˆ˜ï¼Œå› è¯­è¨€æ¨¡ç³Šæ€§å’Œè¡¨è¾¾æœ‰é™ã€‚
2. æå‡ºAvatar Concept Slider (ACS)æ–¹æ³•ï¼Œç²¾ç¡®æ“æ§äººå¶çš„è¯­ä¹‰æ¦‚å¿µã€‚
3. ACSè®¾è®¡åŒ…æ‹¬æ¦‚å¿µæ»‘åŠ¨æŸå¤±ã€å±æ€§ä¿ç•™æŸå¤±å’Œ3Dé«˜æ–¯æ•£ç‚¹åŸè¯­é€‰æ‹©æœºåˆ¶ã€‚
4. æ¦‚å¿µæ»‘åŠ¨æŸå¤±åŸºäºçº¿æ€§åˆ¤åˆ«åˆ†æï¼Œå®šä½æ¦‚å¿µç‰¹å®šè½´ã€‚
5. å±æ€§ä¿ç•™æŸå¤±åŸºäºä¸»æˆåˆ†åˆ†æï¼Œæå‡ç¼–è¾‘ä¸­çš„äººå¶èº«ä»½ä¿ç•™ã€‚
6. 3Dé«˜æ–¯æ•£ç‚¹åŸè¯­é€‰æ‹©æœºåˆ¶åŸºäºæ¦‚å¿µæ•æ„Ÿæ€§ï¼Œæé«˜æ•ˆç‡ã€‚
7. ç»“æœè¡¨æ˜ACSå¯å®ç°ç²¾ç»†3Däººå¶ç¼–è¾‘ï¼Œæä¾›é«˜æ•ˆåé¦ˆï¼Œä¸å½±å“è´¨é‡æˆ–ç‰¹å¾ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: äººè„¸æ¦‚å¿µæ»‘åŠ¨å™¨ï¼šä»¥ç²¾ç»†æ§åˆ¶ç¼–è¾‘äººç±»å¤´åƒçš„è¯­ä¹‰æ¦‚å¿µ
2. Authors: Yixuan He, Lin Geng Foo, Ajmal Saeed Mian, Hossein Rahmani, Jun Jiu
3. Affiliation: æ–°åŠ å¡ç§‘æŠ€è®¾è®¡å¤§å­¦
4. Keywords: 3Däººç±»å¤´åƒç¼–è¾‘ï¼Œè¯­ä¹‰æ¦‚å¿µæ§åˆ¶ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œäººè„¸é›•åˆ»
5. Urls: https://arxiv.org/abs/2408.13995v1 or None, None
6. Summary:

    - (1):è¯¥æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯åˆ©ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œ3Däººç±»å¤´åƒçš„åŸºäºè¯­è¨€çš„ç¼–è¾‘å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè‡ªç„¶è¯­è¨€å›ºæœ‰çš„æ¨¡ç³Šæ€§å’Œæœ‰é™çš„è¡¨è¾¾åŠ›ã€‚ä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œAvatar Concept Slider (ACS)â€çš„3Då¤´åƒç¼–è¾‘æ–¹æ³•ã€‚
 
    - (2):è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬åˆ©ç”¨æŒ‡ä»¤å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¤´åƒç¼–è¾‘ï¼Œå¦‚HeadSculptå’ŒTECAã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºæ–‡æœ¬æç¤ºä½œä¸ºå”¯ä¸€çš„æŒ‡å¯¼ä¿¡å·ï¼Œæ–‡æœ¬æç¤ºçš„æ¨¡ç³Šæ€§å’Œæœ‰é™çš„è¡¨è¾¾åŠ›é™åˆ¶äº†ç¼–è¾‘çš„ç²¾åº¦å’Œæ§åˆ¶ã€‚è¯¥æ–¹æ³•çš„åŠ¨æœºæ˜¯åŸºäºå¯¹ç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œæå‡ºäº†ä¸€ç§æ›´ç²¾ç¡®å’Œé«˜æ•ˆçš„ç¼–è¾‘æ–¹æ³•ã€‚
 
    - (3)ï¼šè¯¥æ–‡æå‡ºçš„æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªè®¾è®¡ï¼š1ï¼‰åŸºäºçº¿æ€§åˆ¤åˆ«åˆ†æçš„â€œæ¦‚å¿µæ»‘åŠ¨æŸå¤±â€ï¼Œä»¥ç²¾ç¡®ç¡®å®šç¼–è¾‘çš„æ¦‚å¿µç‰¹å®šè½´ï¼›2ï¼‰åŸºäºä¸»æˆåˆ†åˆ†æçš„â€œå±æ€§ä¿æŒæŸå¤±â€ï¼Œä»¥åœ¨ç¼–è¾‘è¿‡ç¨‹ä¸­æ›´å¥½åœ°ä¿æŒå¤´åƒçš„èº«ä»½ï¼›3ï¼‰åŸºäºæ¦‚å¿µæ•æ„Ÿæ€§çš„3Dé«˜æ–¯å–·æº…åŸè¯­é€‰æ‹©æœºåˆ¶ï¼Œåªæ›´æ–°å¯¹ç›®æ ‡æ¦‚å¿µæœ€æ•æ„Ÿçš„åŸè¯­ï¼Œä»¥æé«˜æ•ˆç‡ã€‚
 
    - (4)ï¼šè¯¥æ–¹æ³•å®ç°äº†ç»†ç²’åº¦çš„3Då¤´åƒç¼–è¾‘ï¼Œå…·æœ‰é«˜æ•ˆçš„åé¦ˆï¼ŒåŒæ—¶ä¸ä¼šæŸå®³å¤´åƒè´¨é‡æˆ–æŸå®³å¤´åƒçš„è¯†åˆ«å±æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒäº†å…¶ç›®æ ‡ã€‚


8. Conclusion:

                    - (1):è¯¥ç ”ç©¶å…·æœ‰æ˜¾è‘—æ„ä¹‰ï¼Œå› ä¸ºå®ƒæå‡ºäº†ä¸€ç§æ–°çš„3Då¤´åƒç¼–è¾‘æ–¹æ³•ï¼Œèƒ½å¤Ÿä½¿ç”¨è‡ªç„¶è¯­è¨€ç²¾ç¡®æ§åˆ¶å¤´åƒçš„è¯­ä¹‰æ¦‚å¿µï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨ç¼–è¾‘ç²¾åº¦å’Œæ§åˆ¶æ–¹é¢çš„å±€é™æ€§ã€‚

                    - (2):Innovation point: è¯¥æ–¹æ³•åœ¨åˆ›æ–°ç‚¹æ–¹é¢ï¼Œé€šè¿‡ç»“åˆçº¿æ€§åˆ¤åˆ«åˆ†æå’Œä¸»æˆåˆ†åˆ†æï¼Œä»¥åŠæ¦‚å¿µæ•æ„Ÿæ€§çš„3Dé«˜æ–¯å–·æº…åŸè¯­é€‰æ‹©æœºåˆ¶ï¼Œå®ç°äº†å¯¹3Då¤´åƒçš„ç²¾ç»†ç¼–è¾‘ï¼Œå…·æœ‰åˆ›æ–°æ€§ï¼›Performance: åœ¨æ€§èƒ½æ–¹é¢ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„ç¼–è¾‘æ•ˆæœï¼Œä¿æŒäº†å¤´åƒè´¨é‡çš„åŒæ—¶å®ç°äº†é«˜æ•ˆçš„åé¦ˆï¼›Workload: åœ¨å·¥ä½œè´Ÿè½½æ–¹é¢ï¼Œè¯¥æ–¹æ³•çš„è®¡ç®—æ•ˆç‡è¾ƒé«˜ï¼Œå¯¹ç”¨æˆ·è€Œè¨€æ“ä½œç®€ä¾¿ï¼Œé™ä½äº†ç¼–è¾‘è¿‡ç¨‹ä¸­çš„å·¥ä½œè´Ÿæ‹…ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-16bf2abe47a9322d8a354326839ca5bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b10adc5ed7df959917b10ecc0d45ca0a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cb2a659c13c1c9e3088d34b4c1379847.jpg" align="middle">
</details>




## DynaSurfGS: Dynamic Surface Reconstruction with Planar-based Gaussian   Splatting

**Authors:Weiwei Cai, Weicai Ye, Peng Ye, Tong He, Tao Chen**

Dynamic scene reconstruction has garnered significant attention in recent years due to its capabilities in high-quality and real-time rendering. Among various methodologies, constructing a 4D spatial-temporal representation, such as 4D-GS, has gained popularity for its high-quality rendered images. However, these methods often produce suboptimal surfaces, as the discrete 3D Gaussian point clouds fail to align with the object's surface precisely. To address this problem, we propose DynaSurfGS to achieve both photorealistic rendering and high-fidelity surface reconstruction of dynamic scenarios. Specifically, the DynaSurfGS framework first incorporates Gaussian features from 4D neural voxels with the planar-based Gaussian Splatting to facilitate precise surface reconstruction. It leverages normal regularization to enforce the smoothness of the surface of dynamic objects. It also incorporates the as-rigid-as-possible (ARAP) constraint to maintain the approximate rigidity of local neighborhoods of 3D Gaussians between timesteps and ensure that adjacent 3D Gaussians remain closely aligned throughout. Extensive experiments demonstrate that DynaSurfGS surpasses state-of-the-art methods in both high-fidelity surface reconstruction and photorealistic rendering. 

[PDF](http://arxiv.org/abs/2408.13972v1) homepage: https://open3dvlab.github.io/DynaSurfGS/, code:   https://github.com/Open3DVLab/DynaSurfGS

**Summary**
åŠ¨æ€åœºæ™¯é‡å»ºé€šè¿‡DynaSurfGSå®ç°é«˜ä¿çœŸè¡¨é¢é‡å»ºå’Œé€¼çœŸæ¸²æŸ“ã€‚

**Key Takeaways**
- åŠ¨æ€åœºæ™¯é‡å»ºæŠ€æœ¯å¤‡å—å…³æ³¨ã€‚
- 4D-GSåœ¨é«˜è´¨é‡æ¸²æŸ“ä¸­æµè¡Œã€‚
- 3Dé«˜æ–¯ç‚¹äº‘ä¸ç‰©ä½“è¡¨é¢ä¸åŒ¹é…ã€‚
- DynaSurfGSæ—¨åœ¨è§£å†³æ­¤é—®é¢˜ã€‚
- ä½¿ç”¨4Dç¥ç»ä½“ç´ å’Œé«˜æ–¯Splattingè¿›è¡Œç²¾ç¡®é‡å»ºã€‚
- æ­£åˆ™åŒ–ç¡®ä¿è¡¨é¢å¹³æ»‘ã€‚
- ARAPçº¦æŸä¿æŒ3Dé«˜æ–¯ç‚¹äº‘çš„åˆšæ€§ã€‚
- å®éªŒè¯æ˜DynaSurfGSè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: DynaSurfGS: Dynamic Surface Reconstruction with Planar-based Gaussian Splatting (åŸºäºå¹³é¢é«˜æ–¯å–·ç»˜çš„åŠ¨æ€è¡¨é¢é‡å»º)
2. Authors: Weiwei Cai, Weicai Ye, Peng Ye, Tong He, Tao Chen
3. Affiliation: å¤æ—¦å¤§å­¦, æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤, ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤
4. Keywords: Dynamic Scene Reconstruction, Photorealistic Rendering, High-fidelity Surface Reconstruction, 4D Neural Voxels, Gaussian Splatting
5. Urls: https://open3dvlab.github.io/DynaSurfGS/ or Github: None
6. Summary:

   - (1):è¯¥æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯åŠ¨æ€åœºæ™¯é‡å»ºï¼Œè¿™é¡¹æŠ€æœ¯åœ¨ç”µå½±åˆ¶ä½œã€å¨±ä¹äº§ä¸šå’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨ã€‚åŠ¨æ€åœºæ™¯é‡å»ºè¦æ±‚åœ¨é«˜è´¨é‡å’Œå®æ—¶æ¸²æŸ“çš„åŒæ—¶ï¼Œèƒ½å¤Ÿç²¾ç¡®åœ°é‡å»ºåŠ¨æ€ç‰©ä½“çš„è¡¨é¢ã€‚
 
   - (2):è¿‡å»çš„åŠ¨æ€åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå¦‚4D-GSã€SC-GSå’ŒåŸºäº3Då˜å½¢çš„æ–¹æ³•ï¼Œä¸»è¦å…³æ³¨æ¸²æŸ“è´¨é‡ï¼Œè€Œå¿½ç•¥äº†åŠ¨æ€ç‰©ä½“çš„å‡ ä½•è¡¨é¢é‡å»ºã€‚è¿™äº›æ–¹æ³•å­˜åœ¨è¡¨é¢é‡å»ºä¸ç²¾ç¡®çš„é—®é¢˜ï¼Œå› ä¸ºç¦»æ•£çš„3Dé«˜æ–¯ç‚¹äº‘æ— æ³•ä¸ç‰©ä½“è¡¨é¢ç²¾ç¡®å¯¹é½ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•å¾ˆå¥½åœ°è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚
 
   - (3)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•DynaSurfGSé¦–å…ˆå°†4Dç¥ç»ä½“ç´ çš„é«˜æ–¯ç‰¹å¾ä¸åŸºäºå¹³é¢çš„é«˜æ–¯å–·ç»˜ç›¸ç»“åˆï¼Œä»¥ä¿ƒè¿›ç²¾ç¡®çš„è¡¨é¢é‡å»ºã€‚å®ƒåˆ©ç”¨æ³•çº¿æ­£åˆ™åŒ–æ¥å¼ºåˆ¶åŠ¨æ€ç‰©ä½“è¡¨é¢çš„å¹³æ»‘æ€§ã€‚åŒæ—¶ï¼Œå®ƒè¿˜å¼•å…¥äº†å°½å¯èƒ½åˆšæ€§çš„çº¦æŸï¼ˆARAPï¼‰ï¼Œä»¥ä¿æŒ3Dé«˜æ–¯ç‚¹åœ¨æ—¶é—´æ­¥ä¹‹é—´çš„è¿‘ä¼¼åˆšæ€§ï¼Œå¹¶ç¡®ä¿ç›¸é‚»çš„3Dé«˜æ–¯ç‚¹ä¿æŒç´§å¯†å¯¹é½ã€‚
 
   - (4)ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨é«˜è´¨é‡è¡¨é¢é‡å»ºå’Œé€¼çœŸæ¸²æŸ“æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDynaSurfGSåœ¨åŠ¨æ€åœºæ™¯é‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ”¯æŒäº†å…¶ç›®æ ‡ã€‚
7. Methods:

    - (1): DynaSurfGS æ–¹æ³•é¦–å…ˆåˆ©ç”¨ 4D ç¥ç»ä½“ç´ ï¼ˆ4D Neural Voxelsï¼‰æå–åŠ¨æ€åœºæ™¯ä¸­çš„é«˜æ–¯ç‰¹å¾ï¼Œå¹¶ç»“åˆå¹³é¢é«˜æ–¯å–·ç»˜ï¼ˆPlanar-based Gaussian Splattingï¼‰æŠ€æœ¯ï¼Œä»¥å®ç°æ›´ç²¾ç¡®çš„è¡¨é¢é‡å»ºã€‚

    - (2): åœ¨è¡¨é¢é‡å»ºè¿‡ç¨‹ä¸­ï¼Œæ–¹æ³•å¼•å…¥äº†æ³•çº¿æ­£åˆ™åŒ–ï¼ˆNormal Regularizationï¼‰æ¥ç¡®ä¿åŠ¨æ€ç‰©ä½“è¡¨é¢çš„å¹³æ»‘æ€§ã€‚

    - (3): æ­¤å¤–ï¼ŒDynaSurfGS è¿˜é‡‡ç”¨äº†è¿‘ä¼¼åˆšæ€§çº¦æŸï¼ˆApproximate Rigid Body Constraintsï¼ŒARAPï¼‰æ¥ç»´æŒ 3D é«˜æ–¯ç‚¹åœ¨ä¸åŒæ—¶é—´æ­¥ä¹‹é—´çš„åˆšæ€§ï¼Œå¹¶ä¿è¯ç›¸é‚»ç‚¹ä¹‹é—´çš„ç´§å¯†å¯¹é½ã€‚

    - (4): é€šè¿‡ä»¥ä¸Šæ­¥éª¤ï¼ŒDynaSurfGS èƒ½å¤Ÿåœ¨ä¿è¯é«˜è´¨é‡è¡¨é¢é‡å»ºçš„åŒæ—¶ï¼Œå®ç°é€¼çœŸçš„æ¸²æŸ“æ•ˆæœã€‚


8. Conclusion:

                    - (1)ï¼šè¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼ŒDynaSurfGSæ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºé¢†åŸŸæå‡ºäº†ä¸€ä¸ªåˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ç»“åˆ4Dç¥ç»ä½“ç´ å’ŒåŸºäºå¹³é¢çš„é«˜æ–¯å–·ç»˜æŠ€æœ¯ï¼Œå®ç°äº†é«˜ç²¾åº¦å‡ ä½•é‡å»ºå’Œé«˜è´¨é‡æ¸²æŸ“ï¼Œä¸ºç”µå½±åˆ¶ä½œã€å¨±ä¹äº§ä¸šå’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸæä¾›äº†æ–°çš„æŠ€æœ¯æ”¯æŒã€‚

                    - (2): Innovation point: DynaSurfGSçš„åˆ›æ–°ç‚¹åœ¨äºå°†4Dç¥ç»ä½“ç´ ä¸å¹³é¢é«˜æ–¯å–·ç»˜æŠ€æœ¯ç›¸ç»“åˆï¼Œæœ‰æ•ˆæé«˜äº†åŠ¨æ€åœºæ™¯é‡å»ºçš„ç²¾åº¦å’Œæ¸²æŸ“è´¨é‡ï¼›Performance: åœ¨æ€§èƒ½æ–¹é¢ï¼ŒDynaSurfGSåœ¨é«˜è´¨é‡è¡¨é¢é‡å»ºå’Œé€¼çœŸæ¸²æŸ“æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜å…¶æ€§èƒ½æ˜¾è‘—æå‡ï¼›Workload: DynaSurfGSåœ¨ä¿è¯é‡å»ºç²¾åº¦çš„åŒæ—¶ï¼Œå¼•å…¥äº†é¢å¤–çš„çº¦æŸæ¡ä»¶ï¼Œå¦‚æ³•çº¿æ­£åˆ™åŒ–å’ŒARAPçº¦æŸï¼Œå¯èƒ½ä¼šå¢åŠ ä¸€å®šçš„è®¡ç®—è´Ÿæ‹…ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-395b49689e5846d72f2066a2089880f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da111a5083cf8fad2682f3bc1dd35182.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b42d638448deb2bb040994bd53836cb7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3bb8211b03b171a8f4a7ce70802b43cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d457cc8c0fbaf20d5106b43a7f225ac.jpg" align="middle">
</details>




## Splatt3R: Zero-shot Gaussian Splatting from Uncalibarated Image Pairs

**Authors:Brandon Smart, Chuanxia Zheng, Iro Laina, Victor Adrian Prisacariu**

In this paper, we introduce Splatt3R, a pose-free, feed-forward method for in-the-wild 3D reconstruction and novel view synthesis from stereo pairs. Given uncalibrated natural images, Splatt3R can predict 3D Gaussian Splats without requiring any camera parameters or depth information. For generalizability, we start from a 'foundation' 3D geometry reconstruction method, MASt3R, and extend it to be a full 3D structure and appearance reconstructor. Specifically, unlike the original MASt3R which reconstructs only 3D point clouds, we predict the additional Gaussian attributes required to construct a Gaussian primitive for each point. Hence, unlike other novel view synthesis methods, Splatt3R is first trained by optimizing the 3D point cloud's geometry loss, and then a novel view synthesis objective. By doing this, we avoid the local minima present in training 3D Gaussian Splats from stereo views. We also propose a novel loss masking strategy that we empirically find is critical for strong performance on extrapolated viewpoints. We train Splatt3R on the ScanNet++ dataset and demonstrate excellent generalisation to uncalibrated, in-the-wild images. Splatt3R can reconstruct scenes at 4FPS at 512 x 512 resolution, and the resultant splats can be rendered in real-time. 

[PDF](http://arxiv.org/abs/2408.13912v1) Our project page can be found at: https://splatt3r.active.vision/

**Summary**
åŸºäºMASt3Rçš„Splatt3Rï¼šæ— éœ€æ ‡å®šï¼Œå®æ—¶3Dé‡å»ºä¸åˆæˆã€‚

**Key Takeaways**
- Splatt3Rä¸ºæ— æ ‡å®šé‡å¤–3Dé‡å»ºå’Œåˆæˆæä¾›æ–¹æ³•ã€‚
- æ— éœ€ç›¸æœºå‚æ•°å’Œæ·±åº¦ä¿¡æ¯ï¼Œé¢„æµ‹3Dé«˜æ–¯Splatã€‚
- ä»MASt3Ræ‰©å±•ï¼Œå®ç°å…¨3Dç»“æ„å’Œå¤–è§‚é‡å»ºã€‚
- é¢„æµ‹ç‚¹çš„é«˜æ–¯å±æ€§ï¼Œæ„å»ºé«˜æ–¯åŸè¯­ã€‚
- å…ˆä¼˜åŒ–3Dç‚¹äº‘å‡ ä½•æŸå¤±ï¼Œå†è¿›è¡Œåˆæˆç›®æ ‡ä¼˜åŒ–ã€‚
- é¿å…è®­ç»ƒ3Dé«˜æ–¯Splatçš„å±€éƒ¨æœ€å°å€¼ã€‚
- æå‡ºæ–°å‹æŸå¤±æ©ç ç­–ç•¥ï¼Œä¼˜åŒ–å¤–æ¨è§†ç‚¹æ€§èƒ½ã€‚
- åœ¨ScanNet++æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œä¼˜å¼‚æ³›åŒ–èƒ½åŠ›ã€‚
- å®æ—¶é‡å»ºåœºæ™¯ï¼Œæ¸²æŸ“é«˜æ–¯Splatã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: Splatt3R: Zero-shot Gaussian Splatting from Uncalibrated Image Pairs
                 2. Authors: Brandon Smart, Chuanxia Zheng, Iro Laina, Victor Adrian Prisacariu
                 3. Affiliation: University of Oxford
                 4. Keywords: 3D scene reconstruction, novel view synthesis, 3D Gaussian Splatting, uncalibrated images, deep learning
                 5. Urls: arXiv:2408.13912v1  [cs.CV]  25 Aug 2024
                 6. Summary:
                    - (1):This article studies the problem of 3D scene reconstruction and novel view synthesis from uncalibrated natural images, with a focus on stereo pairs. The research background lies in the limitations of traditional 3D reconstruction methods, which require dense image collections and are computationally expensive.
 
                    - (2):Previous methods, such as SRN, NeRF, LFN, and 3D Gaussian Splatting, often require a large number of images for training and are not accessible to general users due to their complexity. They also suffer from poor reconstruction quality when trained with only a pair of stereo images.
 
                    - (3):This paper proposes Splatt3R, a feed-forward model that can directly predict 3D Gaussian Splats from uncalibrated image pairs without requiring camera parameters or depth information. The model is based on the MASt3R method and avoids explicit prediction of camera poses, intrinsics, or monocular depth. It also proposes a novel loss masking strategy for extrapolated viewpoints.
 
                    - (4):Splatt3R is applied to the ScanNet++ dataset and demonstrates excellent generalization to uncalibrated, real-world images. It can reconstruct scenes at 4FPS at 512Ã—512 resolution, and the resulting splats can be rendered in real-time, which supports the effectiveness of the proposed method.
7. Methods:

    - (1): æå‡ºäº†ä¸€ç§åä¸ºSplatt3Rçš„å‰é¦ˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç›´æ¥ä»æœªæ ¡å‡†çš„å›¾åƒå¯¹ä¸­é¢„æµ‹3Dé«˜æ–¯Splatï¼Œæ— éœ€ç›¸æœºå‚æ•°æˆ–æ·±åº¦ä¿¡æ¯ã€‚
  
    - (2): Splatt3RåŸºäºMASt3Ræ–¹æ³•ï¼Œé¿å…äº†æ˜¾å¼é¢„æµ‹ç›¸æœºå§¿æ€ã€å†…å‚æˆ–å•ç›®æ·±åº¦ã€‚
  
    - (3): é‡‡ç”¨äº†æ–°é¢–çš„æŸå¤±æ©ç ç­–ç•¥ï¼Œç”¨äºå¤„ç†å¤–æ¨è§†ç‚¹ã€‚
  
    - (4): åœ¨ScanNet++æ•°æ®é›†ä¸Šåº”ç”¨Splatt3Rï¼Œå±•ç¤ºäº†å…¶å¯¹æœªæ ¡å‡†ã€çœŸå®ä¸–ç•Œå›¾åƒçš„ä¼˜å¼‚æ³›åŒ–èƒ½åŠ›ã€‚
  
    - (5): åœ¨512Ã—512åˆ†è¾¨ç‡ä¸‹ï¼ŒSplatt3Rèƒ½å¤Ÿä»¥4FPSçš„é€Ÿåº¦é‡å»ºåœºæ™¯ï¼Œä¸”ç”Ÿæˆçš„Splatå¯ä»¥å®æ—¶æ¸²æŸ“ã€‚


8. Conclusion:

                    - (1):è¯¥ç ”ç©¶å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼ŒSplatt3Ræ¨¡å‹é€šè¿‡ç›´æ¥ä»æœªæ ¡å‡†çš„ç«‹ä½“å›¾åƒå¯¹ä¸­é¢„æµ‹3Dé«˜æ–¯Splatï¼Œå…‹æœäº†ä¼ ç»Ÿ3Dé‡å»ºæ–¹æ³•å¯¹å¤§é‡å›¾åƒå’Œå¤æ‚è®¡ç®—çš„ä¾èµ–ï¼Œä¸º3Dåœºæ™¯é‡å»ºå’Œæ–°å‹è§†å›¾åˆæˆæä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

                    - (2):Innovation point: åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ— éœ€ç›¸æœºå†…å‚ã€å¤–å‚æˆ–æ·±åº¦ä¿¡æ¯çš„ç›´æ¥é¢„æµ‹3Dé«˜æ–¯Splatçš„æ¨¡å‹ï¼›Performance: æ€§èƒ½ä¸Šï¼ŒSplatt3Råœ¨ScanNet++æ•°æ®é›†ä¸Šå±•ç°å‡ºä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä»¥4FPSçš„é€Ÿåº¦é‡å»ºåœºæ™¯ï¼Œæ”¯æŒå®æ—¶æ¸²æŸ“ï¼›Workload: å·¥ä½œé‡ä¸Šï¼ŒSplatt3Ré¿å…äº†å¤æ‚çš„ç›¸æœºå‚æ•°å’Œæ·±åº¦ä¿¡æ¯è®¡ç®—ï¼Œé™ä½äº†è®¡ç®—è´Ÿæ‹…ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-042df1e0ad154772f12039a7bcc553f1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-94538e76db0bb26cfcac2a7e4c21a886.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0a399f08d3104c7e394aa27cecd0c623.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d593889f9c713dba37d964d5c6804ef.jpg" align="middle">
</details>




## TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View   Images with Transformers

**Authors:Chuanrui Zhang, Yingshuang Zou, Zhuoling Li, Minmin Yi, Haoqian Wang**

Compared with previous 3D reconstruction methods like Nerf, recent Generalizable 3D Gaussian Splatting (G-3DGS) methods demonstrate impressive efficiency even in the sparse-view setting. However, the promising reconstruction performance of existing G-3DGS methods relies heavily on accurate multi-view feature matching, which is quite challenging. Especially for the scenes that have many non-overlapping areas between various views and contain numerous similar regions, the matching performance of existing methods is poor and the reconstruction precision is limited. To address this problem, we develop a strategy that utilizes a predicted depth confidence map to guide accurate local feature matching. In addition, we propose to utilize the knowledge of existing monocular depth estimation models as prior to boost the depth estimation precision in non-overlapping areas between views. Combining the proposed strategies, we present a novel G-3DGS method named TranSplat, which obtains the best performance on both the RealEstate10K and ACID benchmarks while maintaining competitive speed and presenting strong cross-dataset generalization ability. Our code, and demos will be available at: https://xingyoujun.github.io/transplat. 

[PDF](http://arxiv.org/abs/2408.13770v1) 

**Summary**
é’ˆå¯¹3DGSé‡å»ºä¸­çš„ç‰¹å¾åŒ¹é…é—®é¢˜ï¼Œæå‡ºåŸºäºæ·±åº¦ç½®ä¿¡å›¾çš„å±€éƒ¨ç‰¹å¾åŒ¹é…ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æé«˜éé‡å åŒºåŸŸç²¾åº¦ï¼Œå®ç°é«˜æ•ˆè·¨æ•°æ®é›†é‡å»ºã€‚

**Key Takeaways**
1. G-3DGSæ–¹æ³•åœ¨ç¨€ç–è§†è§’ä¸‹æ•ˆç‡é«˜ï¼Œä½†ä¾èµ–ç²¾ç¡®çš„å¤šè§†å›¾ç‰¹å¾åŒ¹é…ã€‚
2. ç°æœ‰æ–¹æ³•åœ¨éé‡å åŒºåŸŸå’Œç›¸ä¼¼åŒºåŸŸåŒ¹é…æ€§èƒ½å·®ï¼Œç²¾åº¦æœ‰é™ã€‚
3. æå‡ºä½¿ç”¨é¢„æµ‹æ·±åº¦ç½®ä¿¡å›¾å¼•å¯¼å±€éƒ¨ç‰¹å¾åŒ¹é…ã€‚
4. åˆ©ç”¨ç°æœ‰å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çŸ¥è¯†ä½œä¸ºå…ˆéªŒæé«˜éé‡å åŒºåŸŸç²¾åº¦ã€‚
5. æå‡ºTranSplatæ–¹æ³•ï¼Œåœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°æœ€ä½³ã€‚
6. TranSplatæ–¹æ³•åœ¨é€Ÿåº¦å’Œè·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ä¸Šå…·æœ‰ç«äº‰åŠ›ã€‚
7. å¯è®¿é—®ä»£ç å’Œæ¼”ç¤ºï¼šhttps://xingyoujun.github.io/transplatã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers
2. Authors: Chuanrui Zhang, Yingshuang Zou, Zhuoling Li, Minmin Yi, Haoqian Wang
3. Affiliation: 
   - Tsinghua University
   - The University of Hong Kong
   - E-surfing Vision Technology Co., Ltd
4. Keywords: 3D reconstruction, Generalizable 3D Gaussian Splatting, Sparse Multi-View Images, Transformers
5. Urls: https://arxiv.org/abs/2408.13770v1 , Github: None
6. Summary:

   - (1): è¯¥æ–‡ç« ç ”ç©¶äº†ä»ç¨€ç–å¤šè§†è§’å›¾åƒä¸­è¿›è¡Œé€šç”¨3Dé‡å»ºçš„é—®é¢˜ï¼Œæ—¨åœ¨ä»å°‘é‡å›¾åƒä¸­æ¢å¤åœºæ™¯çš„3Dç»“æ„ã€‚
 
   - (2): ç°æœ‰çš„3Dé‡å»ºæ–¹æ³•ï¼Œå¦‚NeRFå’Œé€šç”¨3Dé«˜æ–¯åˆ†å±‚ï¼ˆG-3DGSï¼‰ï¼Œåœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸­è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆç‡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•çš„é‡å»ºæ€§èƒ½é«˜åº¦ä¾èµ–äºç²¾ç¡®çš„å¤šè§†å›¾ç‰¹å¾åŒ¹é…ï¼Œè¿™å¯¹äºåœºæ™¯ä¸­å­˜åœ¨å¤§é‡éé‡å åŒºåŸŸå’Œç›¸ä¼¼åŒºåŸŸçš„åœºæ™¯å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
 
   - (3): è¯¥æ–‡ç« æå‡ºäº†TranSplatæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„æµ‹çš„æ·±åº¦ç½®ä¿¡å›¾æ¥æŒ‡å¯¼ç²¾ç¡®çš„å±€éƒ¨ç‰¹å¾åŒ¹é…ï¼Œå¹¶åˆ©ç”¨ç°æœ‰å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„çŸ¥è¯†ä½œä¸ºå…ˆéªŒæ¥æé«˜éé‡å åŒºåŸŸçš„æ·±åº¦ä¼°è®¡ç²¾åº¦ã€‚
 
   - (4): TranSplatåœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰ç«äº‰åŠ›çš„é€Ÿåº¦ï¼Œå¹¶å±•ç°å‡ºå¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚
7. Methods:

    - (1): TranSplatæ–¹æ³•é¦–å…ˆåˆ©ç”¨Transformeræ¨¡å‹å¯¹ç¨€ç–å¤šè§†è§’å›¾åƒè¿›è¡Œç‰¹å¾æå–ï¼Œä»è€Œå¾—åˆ°å…¨å±€åœºæ™¯è¡¨ç¤ºã€‚
 
    - (2): æ¥ç€ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ·±åº¦ç½®ä¿¡å›¾é¢„æµ‹åœºæ™¯çš„æ·±åº¦ä¿¡æ¯ï¼Œå¹¶ä»¥æ­¤ä½œä¸ºä¾æ®è¿›è¡Œå±€éƒ¨ç‰¹å¾åŒ¹é…ï¼Œä»¥æé«˜åŒ¹é…çš„å‡†ç¡®æ€§ã€‚
 
    - (3): ä¸ºäº†è§£å†³éé‡å åŒºåŸŸçš„æ·±åº¦ä¼°è®¡é—®é¢˜ï¼ŒTranSplatç»“åˆäº†ç°æœ‰å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„çŸ¥è¯†ï¼Œä½œä¸ºå…ˆéªŒä¿¡æ¯æ¥ä¼˜åŒ–æ·±åº¦ä¼°è®¡ã€‚
 
    - (4): åœ¨ç‰¹å¾åŒ¹é…å’Œæ·±åº¦ä¼°è®¡çš„åŸºç¡€ä¸Šï¼ŒTranSplaté‡‡ç”¨3Dé«˜æ–¯åˆ†å±‚ï¼ˆG-3DGSï¼‰æŠ€æœ¯è¿›è¡Œåœºæ™¯é‡å»ºï¼Œä»¥å®ç°ä»ç¨€ç–è§†è§’åˆ°å®Œæ•´åœºæ™¯çš„è½¬æ¢ã€‚
 
    - (5): æœ€åï¼ŒTranSplatåœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†æ€§èƒ½è¯„ä¼°ï¼ŒéªŒè¯äº†å…¶æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚


8. Conclusion:

- (1): è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºæå‡ºäº†TranSplatï¼Œä¸€ç§åŸºäºTransformeræ¶æ„çš„é€šç”¨ç¨€ç–è§†å›¾åœºæ™¯é‡å»ºç½‘ç»œã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿä»å°‘é‡å¤šè§†è§’å›¾åƒä¸­æœ‰æ•ˆåœ°æ¢å¤åœºæ™¯çš„3Dç»“æ„ï¼Œå¯¹äºç¨€ç–è§†å›¾ä¸‹çš„3Dé‡å»ºä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚

- (2): Innovation point: TranSplatçš„åˆ›æ–°ç‚¹åœ¨äºå…¶åŸºäºTransformerçš„ç‰¹å¾æå–å’Œæ·±åº¦ç½®ä¿¡å›¾é¢„æµ‹æŠ€æœ¯ï¼Œèƒ½å¤Ÿæé«˜ç¨€ç–è§†å›¾ä¸‹çš„å±€éƒ¨ç‰¹å¾åŒ¹é…ç²¾åº¦ï¼›Performance: åœ¨RealEstate10Kå’ŒACIDåŸºå‡†æµ‹è¯•ä¸­ï¼ŒTranSplatå–å¾—äº†æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†æœ‰ç«äº‰åŠ›çš„é€Ÿåº¦ï¼Œå±•ç°äº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼›Workload: TranSplatåœ¨è®¡ç®—å·¥ä½œé‡ä¸Šç›¸å¯¹è¾ƒä½ï¼Œç”±äºé‡‡ç”¨äº†Transformeræ¶æ„ï¼Œå…¶è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒå¿«ï¼Œé€‚åˆåœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ecbda3794044b1fb3aca4b4ffc1bb8eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d55dcb38e34530616db89245b06a460.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-458727f2577853b54e06bad458c47c62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae408529b2ccebe80b3bb00ff8d57b92.jpg" align="middle">
</details>




## SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with   Panoramic Gaussian Splatting

**Authors:Wenrui Li, Yapeng Mi, Fucheng Cai, Zhe Yang, Wangmeng Zuo, Xingtao Wang, Xiaopeng Fan**

Text-driven 3D scene generation has seen significant advancements recently. However, most existing methods generate single-view images using generative models and then stitch them together in 3D space. This independent generation for each view often results in spatial inconsistency and implausibility in the 3D scenes. To address this challenge, we proposed a novel text-driven 3D-consistent scene generation model: SceneDreamer360. Our proposed method leverages a text-driven panoramic image generation model as a prior for 3D scene generation and employs 3D Gaussian Splatting (3DGS) to ensure consistency across multi-view panoramic images. Specifically, SceneDreamer360 enhances the fine-tuned Panfusion generator with a three-stage panoramic enhancement, enabling the generation of high-resolution, detail-rich panoramic images. During the 3D scene construction, a novel point cloud fusion initialization method is used, producing higher quality and spatially consistent point clouds. Our extensive experiments demonstrate that compared to other methods, SceneDreamer360 with its panoramic image generation and 3DGS can produce higher quality, spatially consistent, and visually appealing 3D scenes from any text prompt. Our codes are available at \url{https://github.com/liwrui/SceneDreamer360}. 

[PDF](http://arxiv.org/abs/2408.13711v1) 

**Summary**
SceneDreamer360é€šè¿‡å…¨æ™¯å›¾åƒç”Ÿæˆå’Œ3DGSï¼Œå®ç°ä»æ–‡æœ¬åˆ°é«˜è´¨ã€ä¸€è‡´æ€§çš„3Dåœºæ™¯ç”Ÿæˆã€‚

**Key Takeaways**
1. æ–‡æœ¬é©±åŠ¨3Dåœºæ™¯ç”ŸæˆæŠ€æœ¯å–å¾—è¿›å±•ã€‚
2. ç°æœ‰æ–¹æ³•å­˜åœ¨å•è§†å›¾ç”Ÿæˆå¯¼è‡´çš„3Dåœºæ™¯ä¸ä¸€è‡´é—®é¢˜ã€‚
3. æå‡ºSceneDreamer360æ¨¡å‹ï¼Œåˆ©ç”¨å…¨æ™¯å›¾åƒç”Ÿæˆæ¨¡å‹ä½œä¸ºå…ˆéªŒã€‚
4. åº”ç”¨3DGSç¡®ä¿å¤šè§†å›¾å…¨æ™¯å›¾åƒçš„ä¸€è‡´æ€§ã€‚
5. é‡‡ç”¨ä¸‰é˜¶æ®µå…¨æ™¯å¢å¼ºï¼Œæå‡Panfusionç”Ÿæˆå™¨æ€§èƒ½ã€‚
6. ä½¿ç”¨ç‚¹äº‘èåˆåˆå§‹åŒ–æ–¹æ³•ï¼Œæé«˜ç‚¹äº‘è´¨é‡ã€‚
7. å®éªŒè¯æ˜SceneDreamer360ç”Ÿæˆé«˜è´¨ã€ä¸€è‡´çš„3Dåœºæ™¯ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: SceneDreamer360: Text-Driven 3D-Consistent Scene Generation with Panoramic Gaussian Splatting
                 (ä¸­æ–‡ç¿»è¯‘ï¼šSceneDreamer360ï¼šåŸºäºå…¨æ™¯é«˜æ–¯æ•£ç‚¹çš„æ–‡æœ¬é©±åŠ¨3Dä¸€è‡´æ€§åœºæ™¯ç”Ÿæˆ)

2. Authors: Wenrui Li, Yapeng Mi, Fucheng Cai, Zhe Yang, Wangmeng Zuo, Xingtao Wang, Xiaopeng Fan

3. Affiliation: å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦

4. Keywords: Text-driven 3D scene generation, Panoramic Gaussian Splatting, 3D Gaussian Splatting, SceneDreamer360, Consistency

5. Urls: https://arxiv.org/abs/2408.13711v1, Github: https://github.com/liwrui/SceneDreamer360

6. Summary:

   - (1):è¯¥æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯æ–‡æœ¬é©±åŠ¨çš„3Dåœºæ™¯ç”Ÿæˆï¼Œè¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå•è§†å›¾å›¾åƒï¼Œç„¶ååœ¨3Dç©ºé—´ä¸­æ‹¼æ¥ï¼Œå¯¼è‡´åœºæ™¯ç©ºé—´ä¸ä¸€è‡´å’Œä¸å¯ä¿¡ã€‚
 
   - (2)ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨2Dç”Ÿæˆæ¨¡å‹ç”Ÿæˆå•è§†å›¾å›¾åƒï¼Œç„¶åæ‹¼æ¥æˆ3Dåœºæ™¯ã€‚è¿™ç§æ–¹æ³•çš„é—®é¢˜åœ¨äºç”Ÿæˆçš„åœºæ™¯ç©ºé—´ä¸ä¸€è‡´å’Œä¸å¯ä¿¡ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ¡ˆæ˜¯åŸºäºå…¨æ™¯é«˜æ–¯æ•£ç‚¹çš„3Dä¸€è‡´æ€§åœºæ™¯ç”Ÿæˆï¼ŒåŠ¨æœºåˆç†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚
 
   - (3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯SceneDreamer360ï¼Œå®ƒåˆ©ç”¨æ–‡æœ¬é©±åŠ¨çš„å…¨æ™¯å›¾åƒç”Ÿæˆæ¨¡å‹ä½œä¸º3Dåœºæ™¯ç”Ÿæˆçš„å…ˆéªŒï¼Œå¹¶é‡‡ç”¨3Dé«˜æ–¯æ•£ç‚¹ï¼ˆ3DGSï¼‰ç¡®ä¿å¤šè§†å›¾å…¨æ™¯å›¾åƒçš„ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µçš„å…¨æ™¯å¢å¼ºï¼Œç”Ÿæˆé«˜åˆ†è¾¨ç‡ã€ç»†èŠ‚ä¸°å¯Œçš„å…¨æ™¯å›¾åƒï¼Œå¹¶ä½¿ç”¨ç‚¹äº‘èåˆåˆå§‹åŒ–æ–¹æ³•ç”Ÿæˆé«˜è´¨é‡ã€ç©ºé—´ä¸€è‡´çš„ç‚¹äº‘ã€‚
 
   - (4)ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡ã€ç©ºé—´ä¸€è‡´ä¸”è§†è§‰ä¸Šå¸å¼•äººçš„3Dåœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSceneDreamer360èƒ½å¤Ÿä»ä»»ä½•æ–‡æœ¬æç¤ºä¸­ç”Ÿæˆæ›´å¥½çš„3Dåœºæ™¯ï¼Œæ”¯æŒå…¶ç ”ç©¶ç›®æ ‡ã€‚
7. Methods:

    - (1): SceneDreamer360æ–¹æ³•é¦–å…ˆé‡‡ç”¨æ–‡æœ¬é©±åŠ¨çš„å…¨æ™¯å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºå…¨æ™¯å›¾åƒï¼›
 
    - (2)ï¼šæ¥ç€ï¼Œé€šè¿‡å…¨æ™¯å¢å¼ºæŠ€æœ¯å¯¹ç”Ÿæˆçš„å…¨æ™¯å›¾åƒè¿›è¡Œå¤„ç†ï¼Œæå‡å›¾åƒçš„é«˜åˆ†è¾¨ç‡å’Œç»†èŠ‚ä¸°å¯Œåº¦ï¼›
 
    - (3)ï¼šåˆ©ç”¨3Dé«˜æ–¯æ•£ç‚¹ï¼ˆ3DGSï¼‰æŠ€æœ¯ç¡®ä¿å¤šè§†å›¾å…¨æ™¯å›¾åƒåœ¨3Dç©ºé—´ä¸­çš„ä¸€è‡´æ€§ï¼›
 
    - (4)ï¼šé‡‡ç”¨ç‚¹äº‘èåˆåˆå§‹åŒ–æ–¹æ³•ï¼ŒåŸºäºå…¨æ™¯å›¾åƒç”Ÿæˆé«˜è´¨é‡ã€ç©ºé—´ä¸€è‡´çš„ç‚¹äº‘ï¼›
 
    - (5)ï¼šæœ€åï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹å°†ç‚¹äº‘æ•°æ®è½¬æ¢ä¸º3Dåœºæ™¯ï¼Œå®ç°æ–‡æœ¬é©±åŠ¨çš„3Dåœºæ™¯ç”Ÿæˆã€‚


8. Conclusion:

                    - (1):è¿™ç¯‡å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼ŒSceneDreamer360é€šè¿‡å¼•å…¥å…¨æ™¯é«˜æ–¯æ•£ç‚¹æŠ€æœ¯ï¼Œæœ‰æ•ˆè§£å†³äº†æ–‡æœ¬é©±åŠ¨3Dåœºæ™¯ç”Ÿæˆä¸­åœºæ™¯ç©ºé—´ä¸ä¸€è‡´å’Œä¸å¯ä¿¡çš„é—®é¢˜ï¼Œä¸ºè¯¥é¢†åŸŸæä¾›äº†æ–°çš„ç ”ç©¶æ€è·¯å’Œæ–¹æ³•ã€‚
                     
                    - (2):åˆ›æ–°ç‚¹ï¼šSceneDreamer360åœ¨å…¨æ™¯å›¾åƒç”Ÿæˆå’Œ3Dç©ºé—´ä¸€è‡´æ€§å¤„ç†æ–¹é¢å®ç°äº†åˆ›æ–°ï¼›æ€§èƒ½ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œç”Ÿæˆçš„é«˜è´¨é‡3Dåœºæ™¯åœ¨è§†è§‰æ•ˆæœå’Œç©ºé—´ä¸€è‡´æ€§ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼›å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•æ¶‰åŠå¤æ‚çš„å…¨æ™¯å›¾åƒç”Ÿæˆå’Œ3Dé«˜æ–¯æ•£ç‚¹å¤„ç†ï¼Œå¯¹è®¡ç®—èµ„æºè¦æ±‚è¾ƒé«˜ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-80966e3956ae85ce87c59d67dc24cf6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-529d79c53ace736e1ce72bef8e2d394f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aa12ad2edac21cd818f1d08f4e91520c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0ec8ebb925d242775d400ab2da1a35e.jpg" align="middle">
</details>




## BiGS: Bidirectional Gaussian Primitives for Relightable 3D Gaussian   Splatting

**Authors:Zhenyuan Liu, Yu Guo, Xinyuan Li, Bernd Bickel, Ran Zhang**

We present Bidirectional Gaussian Primitives, an image-based novel view synthesis technique designed to represent and render 3D objects with surface and volumetric materials under dynamic illumination. Our approach integrates light intrinsic decomposition into the Gaussian splatting framework, enabling real-time relighting of 3D objects. To unify surface and volumetric material within a cohesive appearance model, we adopt a light- and view-dependent scattering representation via bidirectional spherical harmonics. Our model does not use a specific surface normal-related reflectance function, making it more compatible with volumetric representations like Gaussian splatting, where the normals are undefined. We demonstrate our method by reconstructing and rendering objects with complex materials. Using One-Light-At-a-Time (OLAT) data as input, we can reproduce photorealistic appearances under novel lighting conditions in real time. 

[PDF](http://arxiv.org/abs/2408.13370v1) 

**Summary**
æå‡ºäº†ä¸€ç§åŸºäºå›¾åƒçš„æ–°å‹è§†å›¾åˆæˆæŠ€æœ¯ï¼Œé€šè¿‡åŒå‘é«˜æ–¯åŸºå…ƒè¡¨ç¤ºå’Œæ¸²æŸ“åŠ¨æ€å…‰ç…§ä¸‹çš„ä¸‰ç»´ç‰©ä½“ã€‚

**Key Takeaways**
1. ä½¿ç”¨åŒå‘é«˜æ–¯åŸºå…ƒè¿›è¡Œå›¾åƒè§†å›¾åˆæˆã€‚
2. é›†æˆå…‰å†…åˆ†è§£è‡³é«˜æ–¯æ•£ç‚¹æ¡†æ¶ï¼Œå®ç°å®æ—¶é‡å…‰ç…§ã€‚
3. é€šè¿‡åŒå‘çƒè°å‡½æ•°å®ç°è¡¨é¢å’Œä½“ç§¯ææ–™çš„ä¸€è‡´å¤–è§‚æ¨¡å‹ã€‚
4. æ— éœ€ç‰¹å®šè¡¨é¢æ³•çº¿ç›¸å…³åå°„å‡½æ•°ï¼Œå…¼å®¹æ€§æ›´å¼ºã€‚
5. é€šè¿‡é‡å»ºå’Œæ¸²æŸ“å¤æ‚ææ–™ç‰©ä½“å±•ç¤ºæ–¹æ³•ã€‚
6. ä½¿ç”¨å•å…‰æºæ•°æ®è¾“å…¥ï¼Œå®ç°æ–°å‹å…‰ç…§æ¡ä»¶ä¸‹çš„å®æ—¶é€¼çœŸå¤–è§‚å†ç°ã€‚
7. é‡‡ç”¨å®æ—¶æ¸²æŸ“æŠ€æœ¯ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: åŒå‘é«˜æ–¯åŸè¯­ï¼šåŠ¨æ€ç…§æ˜ä¸‹çš„å›¾åƒåŸºç¡€ä¸‰ç»´é‡å»ºä¸æ¸²æŸ“æŠ€æœ¯

2. Authors: [Authors' Names]

3. Affiliation: [First Author's Affiliation in Chinese Translation]

4. Keywords: Image-based novel view synthesis; 3D object representation; Dynamic illumination; Gaussian splatting; Relighting

5. Urls: [Paper Link] or [Github: None]

6. Summary:

   - (1):è¯¥æ–‡ç« çš„ç ”ç©¶èƒŒæ™¯æ˜¯ä¸‰ç»´ç‰©ä½“çš„åŠ¨æ€ç…§æ˜ä¸‹çš„å›¾åƒåŸºç¡€ä¸‰ç»´é‡å»ºä¸æ¸²æŸ“ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸éš¾ä»¥åŒæ—¶å¤„ç†è¡¨é¢å’Œä½“ç§¯ææ–™çš„åŠ¨æ€ç…§æ˜ï¼Œä¸”éš¾ä»¥å®ç°å®æ—¶é‡å…‰ç…§ã€‚

   - (2)ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨è¡¨é¢æ¨¡å‹å’Œä½“ç§¯æ¨¡å‹ï¼Œä½†å®ƒä»¬é€šå¸¸æ— æ³•å¾ˆå¥½åœ°ç»“åˆï¼Œä¸”éš¾ä»¥å¤„ç†åŠ¨æ€ç…§æ˜ã€‚æ–‡ç« æå‡ºçš„æ–¹æ¡ˆå¾ˆå¥½åœ°è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥åŒå‘é«˜æ–¯åŸè¯­å’Œå…‰å†…åˆ†è§£æ¨¡å‹ï¼Œå®ç°äº†å¯¹è¡¨é¢å’Œä½“ç§¯ææ–™çš„åŠ¨æ€ç…§æ˜å…¼å®¹ã€‚

   - (3)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•å°†å…‰å†…åˆ†è§£é›†æˆåˆ°é«˜æ–¯æ•£æ–‘æ¡†æ¶ä¸­ï¼Œé‡‡ç”¨åŒå‘çƒè°å‡½æ•°è¿›è¡Œå…‰ç…§å’Œè§†å›¾ç›¸å…³çš„æ•£å°„è¡¨ç¤ºã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–äºç‰¹å®šçš„è¡¨é¢æ³•çº¿ç›¸å…³çš„åå°„å‡½æ•°ï¼Œä»è€Œæ›´å…¼å®¹äºé«˜æ–¯æ•£æ–‘ç­‰ä½“ç§¯è¡¨ç¤ºã€‚

   - (4)ï¼šè¯¥æ–¹æ³•åœ¨é‡å»ºå’Œæ¸²æŸ“å…·æœ‰å¤æ‚ææ–™çš„ç‰©ä½“æ—¶è¡¨ç°å‡ºè‰²ã€‚ä½¿ç”¨å•å…‰æºæ•°æ®ä½œä¸ºè¾“å…¥ï¼Œå¯ä»¥å®æ—¶åœ°å†ç°æ–°ç…§æ˜æ¡ä»¶ä¸‹çš„é€¼çœŸå¤–è§‚ï¼Œæ”¯æŒäº†å…¶ç›®æ ‡ã€‚


8. Conclusion:

                    - (1):è¯¥ç ”ç©¶å·¥ä½œçš„æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†åŠ¨æ€ç…§æ˜ä¸‹å›¾åƒåŸºç¡€ä¸‰ç»´é‡å»ºä¸æ¸²æŸ“çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æŠ€æœ¯éš¾ä»¥åŒæ—¶å¤„ç†è¡¨é¢å’Œä½“ç§¯ææ–™åŠ¨æ€ç…§æ˜çš„éš¾é¢˜ï¼Œå®ç°äº†å®æ—¶é‡å…‰ç…§å’Œæ–°å‹è§†å›¾åˆæˆã€‚

                    - (2):Innovation point: åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥åŒå‘é«˜æ–¯åŸè¯­å’Œå…‰å†…åˆ†è§£æ¨¡å‹ï¼Œå®ç°äº†å¯¹è¡¨é¢å’Œä½“ç§¯ææ–™çš„åŠ¨æ€ç…§æ˜å…¼å®¹ï¼›Performance: æ€§èƒ½ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆä¸é«˜æ–¯æ•£æ–‘æ¸²æŸ“ç®¡çº¿å…¼å®¹çš„çƒè°ç³»æ•°ï¼Œæ”¯æŒå®æ—¶é‡å…‰ç…§å’Œæ–°å‹è§†å›¾åˆæˆï¼›Workload: å·¥ä½œé‡ä¸Šï¼Œè¯¥æ–¹æ³•éœ€è¦å¤„ç†å¤æ‚çš„è®¡ç®—å’Œè®­ç»ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬çƒè°å‡½æ•°çš„å…‰ç…§å’Œè§†å›¾ç›¸å…³æ•£å°„è¡¨ç¤ºï¼Œä»¥åŠå…‰å†…åˆ†è§£å’Œé‡å»ºæ­¥éª¤ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-5989abf274b5d0d34af2d7e813192b1c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-209ecf536f59d25c3932e4470b84516c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-715a60b3dd4c2db3056d3be90842dc69.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a3e95d648c927d62db31b42f4de42e15.jpg" align="middle">
</details>




## GSFusion: Online RGB-D Mapping Where Gaussian Splatting Meets TSDF   Fusion

**Authors:Jiaxin Wei, Stefan Leutenegger**

Traditional volumetric fusion algorithms preserve the spatial structure of 3D scenes, which is beneficial for many tasks in computer vision and robotics. However, they often lack realism in terms of visualization. Emerging 3D Gaussian splatting bridges this gap, but existing Gaussian-based reconstruction methods often suffer from artifacts and inconsistencies with the underlying 3D structure, and struggle with real-time optimization, unable to provide users with immediate feedback in high quality. One of the bottlenecks arises from the massive amount of Gaussian parameters that need to be updated during optimization. Instead of using 3D Gaussian as a standalone map representation, we incorporate it into a volumetric mapping system to take advantage of geometric information and propose to use a quadtree data structure on images to drastically reduce the number of splats initialized. In this way, we simultaneously generate a compact 3D Gaussian map with fewer artifacts and a volumetric map on the fly. Our method, GSFusion, significantly enhances computational efficiency without sacrificing rendering quality, as demonstrated on both synthetic and real datasets. Code will be available at https://github.com/goldoak/GSFusion. 

[PDF](http://arxiv.org/abs/2408.12677v2) 

**Summary**
ä¼ ç»Ÿç®—æ³•ä¿çœŸ3Dåœºæ™¯ç»“æ„ï¼Œä½†ç¼ºä¹è§†è§‰çœŸå®æ„Ÿï¼›æˆ‘ä»¬æå‡ºGSFusionï¼Œç»“åˆå‡ ä½•ä¿¡æ¯ï¼Œä¼˜åŒ–Gaussianå‚æ•°ï¼Œæé«˜æ¸²æŸ“æ•ˆç‡ã€‚

**Key Takeaways**
1. ä¼ ç»Ÿç®—æ³•åœ¨3Dåœºæ™¯ç»“æ„ä¸Šä¿çœŸä½†è§†è§‰æ•ˆæœå·®ã€‚
2. Gaussian splattingæå‡è§†è§‰æ•ˆæœï¼Œä½†å­˜åœ¨ä¼˜åŒ–éš¾é¢˜ã€‚
3. ç°æœ‰æ–¹æ³•å› Gaussianå‚æ•°æ›´æ–°é‡å¤§è€Œæ•ˆç‡ä½ã€‚
4. æå‡ºå°†Gaussiané›†æˆåˆ°ä½“æ˜ å°„ç³»ç»Ÿä¸­ï¼Œåˆ©ç”¨å‡ ä½•ä¿¡æ¯ã€‚
5. ä½¿ç”¨quadtreeæ•°æ®ç»“æ„å‡å°‘åˆå§‹åŒ–çš„splatsæ•°é‡ã€‚
6. GSFusionç”Ÿæˆç´§å‡‘çš„3D Gaussianåœ°å›¾ï¼Œå‡å°‘ä¼ªå½±ã€‚
7. æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šæé«˜è®¡ç®—æ•ˆç‡ï¼Œä¸ç‰ºç‰²æ¸²æŸ“è´¨é‡ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: GSFusionï¼šåŸºäºé«˜æ–¯æ•£å¸ƒçš„åœ¨çº¿RGB-Dæ˜ å°„ (GSFusion: Online RGB-D Mapping Where Gaussian Splatting Meets TSDF Fusion)

2. Authors: Jiaxin Wei, Stefan Leutenegger

3. Affiliation: æ…•å°¼é»‘å·¥ä¸šå¤§å­¦æ™ºèƒ½æœºå™¨äººå®éªŒå®¤ (Smart Robotics Lab, Technical University of Munich)

4. Keywords: Mapping, RGB-D Perception

5. Urls: https://arxiv.org/abs/2408.12677v2 or None, https://github.com/goldoak/GSFusion

6. Summary:

   - (1): æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯ä¼ ç»Ÿçš„ä½“ç§¯èåˆç®—æ³•åœ¨ä¿æŒ3Dåœºæ™¯ç©ºé—´ç»“æ„æ–¹é¢æœ‰ä¼˜åŠ¿ï¼Œä½†åœ¨å¯è§†åŒ–æ–¹é¢ç¼ºä¹çœŸå®æ„Ÿã€‚æ–°å…´çš„3Dé«˜æ–¯æ•£å¸ƒæŠ€æœ¯èƒ½å¤Ÿæé«˜å¯è§†åŒ–çœŸå®æ„Ÿï¼Œä½†ç°æœ‰çš„åŸºäºé«˜æ–¯çš„é‡æ„æ–¹æ³•é€šå¸¸å­˜åœ¨ä¼ªå½±å’Œä¸åº•å±‚3Dç»“æ„çš„å¤±é…é—®é¢˜ï¼Œä¸”åœ¨å®æ—¶ä¼˜åŒ–æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚

   - (2): è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ä¼ ç»Ÿçš„ä½“ç§¯èåˆç®—æ³•å’ŒåŸºäºç¥ç»è¾å°„åœºçš„é‡å»ºæ–¹æ³•ã€‚ä¼ ç»Ÿçš„ä½“ç§¯èåˆç®—æ³•åœ¨å¯è§†åŒ–æ–¹é¢ç¼ºä¹çœŸå®æ„Ÿï¼Œè€ŒNeRFæ–¹æ³•è™½ç„¶è§†è§‰æ•ˆæœå¥½ï¼Œä½†è®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥å®ç°å®æ—¶æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•å¾ˆå¥½åœ°è§£å†³äº†è¿™äº›é—®é¢˜ã€‚

   - (3)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•å°†3Dé«˜æ–¯æ•£å¸ƒæŠ€æœ¯èå…¥ä½“ç§¯æ˜ å°„ç³»ç»Ÿä¸­ï¼Œåˆ©ç”¨å‡ ä½•ä¿¡æ¯ï¼Œå¹¶æå‡ºåœ¨å›¾åƒä¸Šä½¿ç”¨å››å‰æ ‘æ•°æ®ç»“æ„æ¥æ˜¾è‘—å‡å°‘åˆå§‹åŒ–çš„æ•£å¸ƒæ•°é‡ï¼Œä»è€ŒåŒæ—¶ç”Ÿæˆä¸€ä¸ªç´§å‡‘çš„3Dé«˜æ–¯å›¾å’Œä¸€ä¸ªåŠ¨æ€çš„ä½“ç§¯å›¾ã€‚

   - (4)ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶æ²¡æœ‰ç‰ºç‰²æ¸²æŸ“è´¨é‡ã€‚åœ¨çœŸå®åœºæ™¯çš„æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†6.66 fpsçš„æ˜ å°„é€Ÿåº¦å’Œ27.6MBçš„æ¨¡å‹å¤§å°ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚
7. Methods:

    - (1): è¯¥æ–¹æ³•å°†3Dé«˜æ–¯æ•£å¸ƒï¼ˆGaussian Splattingï¼‰æŠ€æœ¯æ•´åˆåˆ°ä½“ç§¯æ˜ å°„ç³»ç»Ÿä¸­ï¼Œä»¥å¢å¼º3Dåœºæ™¯çš„è§†è§‰çœŸå®æ„Ÿï¼›
 
    - (2): åˆ©ç”¨å‡ ä½•ä¿¡æ¯ä¼˜åŒ–3Dé«˜æ–¯å›¾ç”Ÿæˆï¼Œé€šè¿‡å››å‰æ ‘æ•°æ®ç»“æ„å‡å°‘åˆå§‹åŒ–æ•£å¸ƒæ•°é‡ï¼Œæé«˜è®¡ç®—æ•ˆç‡ï¼›
 
    - (3): ç»“åˆæ—¶æ€è¡¨é¢è·ç¦»åœºï¼ˆTSDFï¼‰èåˆæŠ€æœ¯ï¼Œå®ç°åŠ¨æ€ä½“ç§¯å›¾çš„ç”Ÿæˆï¼ŒåŒæ—¶ä¿æŒ3Dåœºæ™¯çš„ç©ºé—´ç»“æ„ï¼›
 
    - (4): åœ¨å›¾åƒå¤„ç†é˜¶æ®µï¼Œé‡‡ç”¨é«˜æ•ˆçš„ä¼˜åŒ–ç­–ç•¥ï¼Œç¡®ä¿å®æ—¶æ€§èƒ½çš„å®ç°ï¼›
 
    - (5): é€šè¿‡åˆæˆæ•°æ®é›†å’ŒçœŸå®åœºæ™¯æ•°æ®é›†çš„éªŒè¯ï¼Œè¯„ä¼°æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚


8. Conclusion:

                    - (1): è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼Œå®ƒæå‡ºäº†ä¸€ç§ç»“åˆ3Dé«˜æ–¯æ•£å¸ƒå’Œæ—¶æ€è¡¨é¢è·ç¦»åœºèåˆçš„åœ¨çº¿RGB-Dæ˜ å°„æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†3Dåœºæ™¯é‡å»ºçš„è§†è§‰çœŸå®æ„Ÿå’Œè®¡ç®—æ•ˆç‡ï¼Œå¯¹äºå®æ—¶ä¸‰ç»´é‡å»ºå’Œæœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚

                    - (2): Innovation point: è¯¥æ–¹æ³•åœ¨åˆ›æ–°ç‚¹ä¸Šï¼Œå°†3Dé«˜æ–¯æ•£å¸ƒæŠ€æœ¯èå…¥ä½“ç§¯æ˜ å°„ç³»ç»Ÿï¼Œé€šè¿‡å››å‰æ ‘æ•°æ®ç»“æ„ä¼˜åŒ–äº†3Dé«˜æ–¯å›¾çš„ç”Ÿæˆï¼Œå®ç°äº†é«˜æ•ˆç‡çš„3Dåœºæ™¯é‡å»ºï¼›Performance: æ€§èƒ½ä¸Šï¼ŒGSFusionåœ¨çœŸå®åœºæ™¯æµ‹è¯•ä¸­è¾¾åˆ°äº†6.66 fpsçš„æ˜ å°„é€Ÿåº¦å’Œ27.6MBçš„æ¨¡å‹å¤§å°ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„å®æ—¶æ€§å’Œå¯è§†åŒ–æ•ˆæœï¼›Workload: åœ¨å·¥ä½œè´Ÿè½½æ–¹é¢ï¼Œé€šè¿‡ä¼˜åŒ–å…³é”®å¸§ç»´æŠ¤ç­–ç•¥å’Œé«˜æ•ˆçš„ä¼˜åŒ–ç­–ç•¥ï¼ŒGSFusionå®ç°äº†å®æ—¶ä¼˜åŒ–ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8e3eaef4d7240f04f9009c110f80078a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7470ff2f5ea19f538342f7f666d33173.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ceafedafebb50265f3fe42eb0bdaedd7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-85519509bade5c97d826487590c9ed31.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cbd64a2d6ec141ff0621d70102f38a70.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e003b33244846939012a4881ed0ba53a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9eaf33816c16a7e3199fd980b8b46a35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-086089c13eb4f97b146c9c2e3fdc545b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3056e255b355bd8482ea2e20980dff14.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a65b51b84467c8bd9e1070046b7c8d31.jpg" align="middle">
</details>




## InstantStyleGaussian: Efficient Art Style Transfer with 3D Gaussian   Splatting

**Authors:Xin-Yi Yu, Jun-Xin Yu, Li-Bo Zhou, Yan Wei, Lin-Lin Ou**

We present InstantStyleGaussian, an innovative 3D style transfer method based on the 3D Gaussian Splatting (3DGS) scene representation. By inputting a target-style image, it quickly generates new 3D GS scenes. Our method operates on pre-reconstructed GS scenes, combining diffusion models with an improved iterative dataset update strategy. It utilizes diffusion models to generate target style images, adds these new images to the training dataset, and uses this dataset to iteratively update and optimize the GS scenes, significantly accelerating the style editing process while ensuring the quality of the generated scenes. Extensive experimental results demonstrate that our method ensures high-quality stylized scenes while offering significant advantages in style transfer speed and consistency. 

[PDF](http://arxiv.org/abs/2408.04249v2) 

**Summary**
åŸºäº3Dé«˜æ–¯åˆ†å±‚åœºæ™¯è¡¨ç¤ºï¼ŒInstantStyleGaussianå®ç°å¿«é€Ÿ3Dé£æ ¼è½¬æ¢ï¼Œæé«˜ç¼–è¾‘æ•ˆç‡ã€‚

**Key Takeaways**
1. é‡‡ç”¨3Dé«˜æ–¯åˆ†å±‚ï¼ˆ3DGSï¼‰åœºæ™¯è¡¨ç¤ºçš„InstantStyleGaussianã€‚
2. è¾“å…¥ç›®æ ‡é£æ ¼å›¾åƒï¼Œå¿«é€Ÿç”Ÿæˆæ–°3Dåœºæ™¯ã€‚
3. ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç»“åˆæ”¹è¿›çš„æ•°æ®é›†æ›´æ–°ç­–ç•¥ã€‚
4. åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç›®æ ‡é£æ ¼å›¾åƒå¹¶æ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ã€‚
5. è¿­ä»£æ›´æ–°ä¼˜åŒ–3Dåœºæ™¯ï¼ŒåŠ é€Ÿé£æ ¼ç¼–è¾‘ã€‚
6. å®éªŒè¯æ˜ç”Ÿæˆåœºæ™¯è´¨é‡é«˜ã€‚
7. é€Ÿåº¦å¿«ï¼Œé£æ ¼ä¸€è‡´æ€§é«˜ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: InstantStyleGaussian: Efficient Art Style Transfer (å³æ—¶é£æ ¼é«˜æ–¯ï¼šé«˜æ•ˆè‰ºæœ¯é£æ ¼è¿ç§»)

2. Authors: Xin-Yi Yu, Jun-Xin Yu, Li-Bo Zhou, Yan Wei, Lin-Lin Ou

3. Affiliation: æœªæä¾›å…·ä½“ä¿¡æ¯

4. Keywords: 3D Gaussian Splatting, 3D Style Transfer, Iterative Dataset Update

5. Urls: Paper: [InstantStyleGaussian: Efficient Art Style Transfer](https://arxiv.org/abs/2408.04249v2), Github: None

6. Summary:

   - (1): ç ”ç©¶èƒŒæ™¯ï¼šéšç€æœºå™¨äººä»¿çœŸã€è™šæ‹Ÿç°å®å’Œè‡ªåŠ¨é©¾é©¶ç­‰åº”ç”¨çš„å‘å±•ï¼Œ3Dåœºæ™¯å’Œæ¨¡å‹çš„ç¼–è¾‘å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚ä¼ ç»Ÿçš„3Dè¡¨ç¤ºæ–¹æ³•å¦‚ç½‘æ ¼å’Œç‚¹äº‘åœ¨ç¼–è¾‘å¤æ‚åœºæ™¯å’Œç»†èŠ‚æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯ä¸ºäº†æé«˜3Dåœºæ™¯ç¼–è¾‘çš„æ•ˆç‡å’Œç›´è§‚æ€§ã€‚

   - (2): è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä¼ ç»Ÿçš„3Dé£æ ¼è¿ç§»æ–¹æ³•é€šå¸¸éœ€è¦ä»é£æ ¼å›¾åƒä¸­æå–ç‰¹å¾ï¼Œå¹¶å°†å…¶åµŒå…¥åˆ°é‡å»ºçš„3Dåœºæ™¯ä¸­ï¼Œç„¶åè§£ç ä»¥æ¸²æŸ“æ–°åœºæ™¯ã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„å†…å­˜å’Œè®¡ç®—æ—¶é—´ï¼Œä¸”è§£ç æ–¹æ³•ä¼šå½±å“æœ€ç»ˆçš„é£æ ¼è¿ç§»æ•ˆæœï¼Œå¯èƒ½é™ä½å¤šè§†å›¾ä¸€è‡´æ€§å’Œåœºæ™¯è´¨é‡ã€‚æœ¬æ–‡çš„æ–¹æ³•åŸºäº3Dé«˜æ–¯åˆ†å‰²ï¼ˆ3DGSï¼‰åœºæ™¯è¡¨ç¤ºï¼Œç»“åˆæ‰©æ•£æ¨¡å‹å’Œæ”¹è¿›çš„è¿­ä»£æ•°æ®é›†æ›´æ–°ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³è¿™äº›é—®é¢˜ã€‚

   - (3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•é€šè¿‡è¾“å…¥ç›®æ ‡é£æ ¼å›¾åƒï¼Œå¿«é€Ÿç”Ÿæˆæ–°çš„3DGSåœºæ™¯ã€‚å®ƒä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç›®æ ‡é£æ ¼å›¾åƒï¼Œå°†è¿™äº›æ–°å›¾åƒæ·»åŠ åˆ°è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†è¿­ä»£æ›´æ–°å’Œä¼˜åŒ–GSåœºæ™¯ã€‚æ–¹æ³•åŸºäºè¿­ä»£æ•°æ®é›†æ›´æ–°ï¼ˆIDUï¼‰æ–¹æ³•ï¼Œå¹¶é€šè¿‡æ•è·3DGSåœºæ™¯çš„æ‘„åƒæœºè§†è§’å›¾åƒæ¥ç¼–è¾‘å¤šä¸ªè§†è§’å›¾åƒã€‚

   - (4): ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨3Dé£æ ¼è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå®ç°äº†é«˜è´¨é‡çš„é£æ ¼åŒ–åœºæ™¯ï¼ŒåŒæ—¶æé«˜äº†é£æ ¼è¿ç§»çš„é€Ÿåº¦å’Œä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€Ÿåº¦å’Œæ€§èƒ½ä¸Šä¼˜äºä¹‹å‰çš„3Dç¼–è¾‘æ–¹æ³•ã€‚
7. Methods:

- (1): æœ¬æ–‡æå‡ºçš„æ–¹æ³•ä½¿ç”¨è¾“å…¥é£æ ¼å›¾åƒå’Œæ–‡æœ¬æç¤ºï¼Œå…±åŒæŒ‡å¯¼åœ¨è®­ç»ƒçš„3DGSåœºæ™¯ä¸­ç”Ÿæˆæ–°çš„åœºæ™¯ã€‚é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼ˆInstantStyle [30]ï¼‰è¿›è¡Œ2Då›¾åƒé£æ ¼è¿ç§»ï¼Œå¹¶æ”¹è¿›äº†InstructNeRF2NeRF [25]ä¸­è¿­ä»£æ•°æ®é›†æ›´æ–°ï¼ˆIDUï¼‰çš„åŸºç¡€ç­–ç•¥ã€‚

- (2): é¦–å…ˆä½¿ç”¨InstantStyleæ‰©æ•£æ¨¡å‹ç”ŸæˆåŸºäºè¾“å…¥é£æ ¼å›¾åƒå’Œæ–‡æœ¬æç¤ºçš„å„ç§è‰ºæœ¯é£æ ¼çš„2Då›¾åƒï¼Œç„¶åå°†è¿™äº›ç»“æœåå‘ä¼ æ’­åˆ°3DGSåœºæ™¯ï¼Œä½¿ç”¨ç‰¹å®šæŸå¤±å‡½æ•°è¿›è¡Œå¤„ç†ã€‚

- (3): åœ¨ç¼–è¾‘è¿‡ç¨‹ä¸­ï¼Œè¾“å…¥è¾¹ç¼˜æ£€æµ‹å›¾ä»¥ä¿æŒåœºæ™¯çš„åŸºæœ¬ç»“æ„ï¼Œæœ€ç»ˆå®ç°æ•´ä¸ªåœºæ™¯çš„é£æ ¼ç¼–è¾‘ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹å†…å®¹ã€‚

- (4): é‡‡ç”¨NNFMæŸå¤±ï¼ˆNearest Neighbor Feature Matching [15]ï¼‰æ¥åŒ¹é…å±€éƒ¨ç‰¹å¾ï¼Œæ›´å¥½åœ°ä¿ç•™çº¹ç†ç»†èŠ‚ã€‚

- (5): ä½¿ç”¨L1å’ŒLPIPS [31]æŸå¤±å‡½æ•°è®­ç»ƒGaussian Splattingï¼Œå¯¹äºä¸åŒè§†è§’çš„å±€éƒ¨ä¸ä¸€è‡´çº¹ç†ï¼Œä½¿ç”¨NNFMæŸå¤±åŒ¹é…å±€éƒ¨ç‰¹å¾ã€‚

- (6): å°†éšæœºé€‰æ‹©çš„30ä¸ªæˆ–æ›´å°‘çš„ç›¸æœºè§†è§’è¿›è¡Œå•æ¬¡ç¼–è¾‘ï¼Œè¿™äº›ç¼–è¾‘åçš„å›¾åƒä½œä¸ºå‚è€ƒï¼Œå¢åŠ è®­ç»ƒæ•°æ®é›†ï¼Œè€Œä¸æ›¿æ¢ç›¸åº”è§†è§’çš„åŸå§‹å›¾åƒã€‚

- (7): é€šè¿‡è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¢å¼ºGSåœºæ™¯ï¼Œç¡®ä¿æ”¹è¿›å’Œç»†åŒ–ã€‚

- (8): ä½¿ç”¨gsplatåº“ï¼ˆæ¥è‡ªGaussianEditor [27]ï¼‰ä½œä¸ºåº•å±‚æ¨¡å‹å’Œå¯è§†åŒ–å·¥å…·ï¼Œä»¥åŠInstantStyleä½œä¸ºæ‰©æ•£æ¨¡å‹ã€‚

- (9): é€šè¿‡æ§åˆ¶Netæ¡ä»¶ç¼©æ”¾å’Œæ–‡æœ¬ã€å›¾åƒè°ƒæ•´çš„å¼•å¯¼æƒé‡ç­‰å‚æ•°ï¼Œç¡®å®šæ‰©æ•£æ¨¡å‹æ›´æ–°çš„å¼ºåº¦ï¼Œå¹¶æ ¹æ®éœ€è¦æ‰‹åŠ¨è°ƒæ•´ç›¸å…³å¼•å¯¼æƒé‡ä»¥å®ç°æ‰€éœ€çš„ç¼–è¾‘æ•ˆæœã€‚

- (10): è®­ç»ƒæ–¹æ³•æ¶‰åŠæœ€å¤š1kæ¬¡è¿­ä»£ï¼Œåœ¨A100 GPUï¼ˆ40GBå†…å­˜ï¼‰ä¸Šä»…éœ€20åˆ†é’Ÿå³å¯å®Œæˆåœºæ™¯çš„é£æ ¼è¿ç§»ç¼–è¾‘ã€‚


8. Conclusion:

                    - (1): è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼Œå®ƒä¸º3Dåœºæ™¯ç¼–è¾‘é¢†åŸŸæä¾›äº†ä¸€ç§é«˜æ•ˆçš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡3Dåœºæ™¯ç¼–è¾‘çš„æ•ˆç‡å’Œç›´è§‚æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æœºå™¨äººä»¿çœŸã€è™šæ‹Ÿç°å®å’Œè‡ªåŠ¨é©¾é©¶ç­‰åº”ç”¨ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

                    - (2): Innovation point: InstantStyleGaussianæ–¹æ³•é€šè¿‡ç»“åˆæ‰©æ•£æ¨¡å‹å’Œæ”¹è¿›çš„è¿­ä»£æ•°æ®é›†æ›´æ–°ç­–ç•¥ï¼Œå®ç°äº†å¿«é€Ÿä¸”é«˜è´¨é‡çš„3Dé£æ ¼è¿ç§»ï¼Œè¿™æ˜¯å…¶åˆ›æ–°ç‚¹æ‰€åœ¨ï¼›Performance: åœ¨3Dé£æ ¼è¿ç§»ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„é£æ ¼åŒ–åœºæ™¯ï¼ŒåŒæ—¶ä¿æŒäº†é€Ÿåº¦å’Œä¸€è‡´æ€§ï¼›Workload: è¯¥æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†å¤§é‡è¿­ä»£ï¼Œä½†å¾—ç›Šäºé«˜æ•ˆçš„è®¡ç®—ç­–ç•¥ï¼Œæ•´ä½“å·¥ä½œè´Ÿè½½ç›¸å¯¹è¾ƒä½ï¼Œé€‚åˆåœ¨A100 GPUç­‰é«˜æ€§èƒ½è®¾å¤‡ä¸Šè¿è¡Œã€‚




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f9fedaa9225260030de0fe83c424b149.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4159b0eba641f3a329ed43b6ec03d3f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c52e009fe3594898bd9bf1048600d7bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-42d5d2c3b7457fabaeda63213d4e2444.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-651ddd779afa150611aa6acb63053ae1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9fad5c512abc12a5b925eb993be8052.jpg" align="middle">
</details>




## SpikeGS: Reconstruct 3D scene via fast-moving bio-inspired sensors

**Authors:Yijia Guo, Liwen Hu, Lei Ma, Tiejun Huang**

3D Gaussian Splatting (3DGS) demonstrates unparalleled superior performance in 3D scene reconstruction. However, 3DGS heavily relies on the sharp images. Fulfilling this requirement can be challenging in real-world scenarios especially when the camera moves fast, which severely limits the application of 3DGS. To address these challenges, we proposed Spike Gausian Splatting (SpikeGS), the first framework that integrates the spike streams into 3DGS pipeline to reconstruct 3D scenes via a fast-moving bio-inspired camera. With accumulation rasterization, interval supervision, and a specially designed pipeline, SpikeGS extracts detailed geometry and texture from high temporal resolution but texture lacking spike stream, reconstructs 3D scenes captured in 1 second. Extensive experiments on multiple synthetic and real-world datasets demonstrate the superiority of SpikeGS compared with existing spike-based and deblur 3D scene reconstruction methods. Codes and data will be released soon. 

[PDF](http://arxiv.org/abs/2407.03771v2) 

**Summary**
3DGSåœ¨åœºæ™¯é‡å»ºä¸­è¡¨ç°å“è¶Šï¼Œä½†ä¾èµ–æ¸…æ™°å›¾åƒï¼ŒSpikeGSé€šè¿‡é›†æˆ spike æµæ”¹è¿›ï¼Œæå‡å¿«é€Ÿç§»åŠ¨ç›¸æœºä¸‹çš„é‡å»ºæ•ˆæœã€‚

**Key Takeaways**
- 3DGSåœ¨3Dåœºæ™¯é‡å»ºä¸­è¡¨ç°ä¼˜å¼‚ã€‚
- 3DGSå¯¹æ¸…æ™°å›¾åƒä¾èµ–åº¦é«˜ï¼Œé™åˆ¶å…¶åº”ç”¨ã€‚
- æå‡ºSpikeGSï¼Œé›†æˆ spike æµä¼˜åŒ–3DGSã€‚
- é‡‡ç”¨ç§¯ç´¯å…‰æ …åŒ–ã€é—´éš”ç›‘ç£å’Œå®šåˆ¶ç®¡é“ã€‚
- ä»ç¼ºä¹çº¹ç†çš„ spike æµä¸­æå–ç»†èŠ‚ã€‚
- 1ç§’å†…é‡å»º3Dåœºæ™¯ã€‚
- å®éªŒè¯æ˜SpikeGSä¼˜äºç°æœ‰æ–¹æ³•ã€‚
- å°†å‘å¸ƒä»£ç å’Œæ•°æ®ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**



1. Title: è„‰å†²é«˜æ–¯åˆ†å±‚ï¼šåˆ©ç”¨å¿«é€Ÿç§»åŠ¨ç”Ÿç‰©çµæ„Ÿç›¸æœºé‡å»º3Dåœºæ™¯ (SpikeGS: Reconstruct 3D scene captured by a fast-moving bio-inspired camera)

2. Authors: Yijia Guo, Liwen Hu, Lei Ma

3. Affiliation: åŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å›½å®¶é‡ç‚¹å®éªŒå®¤ã€åŒ—äº¬å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢

4. Keywords: 3Dåœºæ™¯é‡å»ºï¼Œé«˜æ–¯åˆ†å±‚ï¼Œè„‰å†²ç›¸æœºï¼Œå®æ—¶é‡å»º

5. Urls: https://arxiv.org/abs/2407.03771v2 or None, None

6. Summary:

   - (1):è¯¥æ–‡ç« çš„ç ”ç©¶èƒŒæ™¯æ˜¯3Dé‡å»ºé¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨åˆ©ç”¨å¿«é€Ÿç§»åŠ¨ç›¸æœºæ—¶ï¼Œå¦‚ä½•æé«˜é‡å»ºé€Ÿåº¦å’Œè´¨é‡æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚
 
   - (2):è¿‡å»çš„3Dé‡å»ºæ–¹æ³•ï¼Œå¦‚3Dé«˜æ–¯åˆ†å±‚ï¼ˆ3DGSï¼‰ï¼Œè™½ç„¶é‡å»ºé€Ÿåº¦å¿«ï¼Œä½†éœ€è¦æ¸…æ™°çš„å›¾åƒè¾“å…¥ï¼Œè¿™åœ¨å®é™…åœºæ™¯ä¸­å°¤å…¶å›°éš¾ï¼Œå› ä¸ºå¿«é€Ÿç§»åŠ¨çš„ç›¸æœºå®¹æ˜“äº§ç”Ÿè¿åŠ¨æ¨¡ç³Šã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¹¶å…·æœ‰å¾ˆå¥½çš„åŠ¨æœºã€‚
 
   - (3)ï¼šè¯¥æ–‡ç« æå‡ºäº†è„‰å†²é«˜æ–¯åˆ†å±‚ï¼ˆSpikeGSï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†æ‹œè€³é˜µåˆ—è„‰å†²æµæ•´åˆåˆ°3DGSæµç¨‹ä¸­ï¼Œä»¥é‡å»ºç”±å¿«é€Ÿç§»åŠ¨çš„é«˜æ—¶é—´åˆ†è¾¨ç‡å½©è‰²è„‰å†²ç›¸æœºåœ¨1ç§’å†…æ•è·çš„3Dåœºæ™¯ã€‚SpikeGSé€šè¿‡ç´¯ç§¯å…‰æ …åŒ–ã€åŒºé—´ç›‘ç£å’Œä¸“é—¨è®¾è®¡çš„æµç¨‹æ¥å®ç°è¿ç»­çš„ç©ºé—´æ—¶é—´æ„ŸçŸ¥ï¼ŒåŒæ—¶ä»æ‹œè€³é˜µåˆ—è„‰å†²æµä¸­æå–è¯¦ç»†çš„ç»“æ„å’Œçº¹ç†ã€‚
 
   - (4)ï¼šåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSpikeGSåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„åŸºäºè„‰å†²å’Œå»æ¨¡ç³Šçš„3Dåœºæ™¯é‡å»ºæ–¹æ³•ï¼Œå…¶PSNRå€¼è¾¾åˆ°äº†32.70ï¼Œæ”¯æŒäº†å®æ—¶é‡å»ºçš„ç›®æ ‡ã€‚
7. Methods:

    - (1): é’ˆå¯¹å¿«é€Ÿç§»åŠ¨ç›¸æœºäº§ç”Ÿçš„è¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§è„‰å†²é«˜æ–¯åˆ†å±‚ï¼ˆSpikeGSï¼‰æ–¹æ³•ã€‚SpikeGSæ–¹æ³•å°†æ‹œè€³é˜µåˆ—è„‰å†²æµæ•´åˆåˆ°3Dé«˜æ–¯åˆ†å±‚ï¼ˆ3DGSï¼‰æµç¨‹ä¸­ï¼Œåˆ©ç”¨é«˜æ—¶é—´åˆ†è¾¨ç‡çš„å½©è‰²è„‰å†²ç›¸æœºåœ¨çŸ­æ—¶é—´å†…æ•è·çš„3Dåœºæ™¯ã€‚

    - (2): ä¸ºäº†ä»æ‹œè€³é˜µåˆ—è„‰å†²æµä¸­æå–è¯¦ç»†çš„ç»“æ„å’Œçº¹ç†ï¼ŒSpikeGSé‡‡ç”¨ç´¯ç§¯å…‰æ …åŒ–ã€åŒºé—´ç›‘ç£å’Œä¸“é—¨è®¾è®¡çš„æµç¨‹æ¥å®ç°è¿ç»­çš„ç©ºé—´æ—¶é—´æ„ŸçŸ¥ã€‚

    - (3): æ–‡ç« é‡‡ç”¨æ—¶é—´ç´¯ç§¯å…‰æ …åŒ–æŠ€æœ¯ï¼Œæ¨¡æ‹Ÿå…‰å­åœ¨ç‰©ç†ä¸Šçš„ç´¯ç§¯è¿‡ç¨‹ï¼Œä»¥æ¢å¤çº¹ç†ç»†èŠ‚å’Œå‡ ä½•ä¿¡æ¯ã€‚

    - (4): ä¸ºäº†è§£å†³è®­ç»ƒåˆæœŸGaussian splatæ”¶æ•›é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼Œæ–‡ç« ä½¿ç”¨è„‰å†²é—´éš”åˆå§‹åŒ–ç‚¹äº‘ï¼Œå¹¶åˆ©ç”¨å…¶è¿›è¡Œåˆå§‹è®­ç»ƒã€‚

    - (5): ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡å’Œé‡å»ºè´¨é‡ï¼Œæ–‡ç« å¼•å…¥äº†ç´¯ç§¯æŸå¤±å‡½æ•°ï¼Œç»“åˆå…‰åº¦è¯¯å·®å’Œç»“æ„ç›¸ä¼¼æ€§ï¼ˆSSIMï¼‰æ¥ä¼˜åŒ–æ¨¡å‹ã€‚

    - (6): åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ–‡ç« é€šè¿‡ç›¸äº’çº¦æŸçš„è®­ç»ƒå’ŒæŸå¤±å‡½æ•°ï¼Œç¡®ä¿äº†ç‚¹äº‘åˆå§‹åŒ–å’ŒGaussian splatå‡ ä½•ç²¾åº¦ï¼Œä»è€Œæé«˜äº†æœ€ç»ˆé‡å»ºè´¨é‡ã€‚

    - (7): æ–‡ç« åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œç»“æœè¡¨æ˜ï¼ŒSpikeGSåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„åŸºäºè„‰å†²å’Œå»æ¨¡ç³Šçš„3Dåœºæ™¯é‡å»ºæ–¹æ³•ã€‚







<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-07276e6ebddbadda6f34dc3325c077ec.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b72c589cdf9131b150d1c25d4921e305.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc32fdcb91ee5d730f20e5129b2279e6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4c8c62704c1535358ce1dc4427a95fc7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-baedf4cfd5e0c6992b40354e6d8fc0d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27a376e74133a2ba000bf50d154ae890.jpg" align="middle">
</details>




