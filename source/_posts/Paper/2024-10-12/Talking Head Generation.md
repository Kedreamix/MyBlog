
---
title: Talking Head Generation
date: 2024-10-12 06:04:04
author: Kedreamix
cover: https://pic1.zhimg.com/v2-bf351a38d373ad29c81b373fe10d2463.jpg
categories: Paper
tags:
    - Talking Head Generation
description: Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-10-12  MMHead Towards Fine-grained Multi-modal 3D Facial Animation  
keywords: Talking Head Generation
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-10-12 æ›´æ–°


## MMHead: Towards Fine-grained Multi-modal 3D Facial Animation

**Authors:Sijing Wu, Yunhao Li, Yichao Yan, Huiyu Duan, Ziwei Liu, Guangtao Zhai**

3D facial animation has attracted considerable attention due to its extensive applications in the multimedia field. Audio-driven 3D facial animation has been widely explored with promising results. However, multi-modal 3D facial animation, especially text-guided 3D facial animation is rarely explored due to the lack of multi-modal 3D facial animation dataset. To fill this gap, we first construct a large-scale multi-modal 3D facial animation dataset, MMHead, which consists of 49 hours of 3D facial motion sequences, speech audios, and rich hierarchical text annotations. Each text annotation contains abstract action and emotion descriptions, fine-grained facial and head movements (i.e., expression and head pose) descriptions, and three possible scenarios that may cause such emotion. Concretely, we integrate five public 2D portrait video datasets, and propose an automatic pipeline to 1) reconstruct 3D facial motion sequences from monocular videos; and 2) obtain hierarchical text annotations with the help of AU detection and ChatGPT. Based on the MMHead dataset, we establish benchmarks for two new tasks: text-induced 3D talking head animation and text-to-3D facial motion generation. Moreover, a simple but efficient VQ-VAE-based method named MM2Face is proposed to unify the multi-modal information and generate diverse and plausible 3D facial motions, which achieves competitive results on both benchmarks. Extensive experiments and comprehensive analysis demonstrate the significant potential of our dataset and benchmarks in promoting the development of multi-modal 3D facial animation. 

[PDF](http://arxiv.org/abs/2410.07757v1) Accepted by ACMMM 2024. Project page:   https://wsj-sjtu.github.io/MMHead/

**Summary**
æ„å»ºå¤§è§„æ¨¡å¤šæ¨¡æ€3Dé¢éƒ¨åŠ¨ç”»æ•°æ®é›†MMHeadï¼Œæ¨åŠ¨æ–‡æœ¬å¼•å¯¼3Dé¢éƒ¨åŠ¨ç”»å‘å±•ã€‚

**Key Takeaways**
1. 3Dé¢éƒ¨åŠ¨ç”»åœ¨å¤šåª’ä½“é¢†åŸŸåº”ç”¨å¹¿æ³›ï¼Œä½†å¤šæ¨¡æ€åŠ¨ç”»ç ”ç©¶è¾ƒå°‘ã€‚
2. MMHeadæ•°æ®é›†åŒ…å«3Dé¢éƒ¨è¿åŠ¨ã€è¯­éŸ³éŸ³é¢‘å’Œæ–‡æœ¬æ³¨é‡Šï¼Œæ¶µç›–åŠ¨ä½œã€æƒ…ç»ªå’Œåœºæ™¯æè¿°ã€‚
3. é›†æˆ5ä¸ªå…¬å…±2Dè‚–åƒè§†é¢‘æ•°æ®é›†ï¼Œè‡ªåŠ¨é‡å»º3Dé¢éƒ¨è¿åŠ¨åºåˆ—ã€‚
4. åˆ©ç”¨AUæ£€æµ‹å’ŒChatGPTè·å–æ–‡æœ¬æ³¨é‡Šï¼Œå®ç°è¯­ä¹‰åˆ°åŠ¨ä½œçš„æ˜ å°„ã€‚
5. å»ºç«‹æ–‡æœ¬è¯±å¯¼3D talking headåŠ¨ç”»å’Œæ–‡æœ¬åˆ°3Dé¢éƒ¨è¿åŠ¨ç”Ÿæˆä¸¤ä¸ªæ–°ä»»åŠ¡åŸºå‡†ã€‚
6. æå‡ºMM2Faceæ–¹æ³•ï¼Œèåˆå¤šæ¨¡æ€ä¿¡æ¯ç”Ÿæˆ3Dé¢éƒ¨è¿åŠ¨ã€‚
7. MMHeadæ•°æ®é›†å’ŒåŸºå‡†åœ¨å¤šæ¨¡æ€3Dé¢éƒ¨åŠ¨ç”»å‘å±•ä¸­å…·æœ‰é‡å¤§æ½œåŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. Title: MMHeadï¼šé¢å‘ç²¾ç»†å¤šæ¨¡æ€çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ç ”ç©¶

2. Authors: Sijing Wuï¼ˆå´æ€é™ï¼‰, Yunhao Liï¼ˆæäº‘è±ªï¼‰, Yichao Yanï¼ˆé¢œä¸€è¶…ï¼‰, Huiyu Duanï¼ˆæ®µæ…§å®‡ï¼‰, Ziwei Liuï¼ˆåˆ˜å­ç®ï¼‰, Guangtao Zhaiï¼ˆç¿Ÿå…‰æ¶›ï¼‰

3. Affiliation: ä¸Šæµ·äº¤é€šå¤§å­¦

4. Keywords: å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ï¼›MMHeadæ•°æ®é›†ï¼›æ–‡æœ¬å¼•å¯¼çš„é¢éƒ¨åŠ¨ç”»ï¼›è‡ªåŠ¨ç®¡é“é‡å»ºï¼›å±‚æ¬¡æ–‡æœ¬æ³¨é‡Šï¼›VQ-VAEæ–¹æ³•ï¼›3Dé¢éƒ¨è¿åŠ¨ç”Ÿæˆ

5. Urls: è®ºæ–‡é“¾æ¥å¾…ç¡®è®¤ï¼ŒGitHubä»£ç é“¾æ¥ï¼ˆå¦‚æœ‰ï¼‰: None

6. Summary:

    - (1) ç ”ç©¶èƒŒæ™¯ï¼šæœ¬æ–‡å…³æ³¨å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»é¢†åŸŸçš„ç ”ç©¶èƒŒæ™¯ï¼Œé‰´äºä¸‰ç»´é¢éƒ¨åŠ¨ç”»åœ¨å¤šåª’ä½“é¢†åŸŸä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç›¸å…³ç ”ç©¶å¼•èµ·äº†å¹¿æ³›çš„å…³æ³¨ã€‚ç‰¹åˆ«æ˜¯éŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»å·²å¾—åˆ°äº†å¹¿æ³›çš„æ¢ç´¢ä¸æ˜¾è‘—çš„ç»“æœï¼Œä½†æ–‡æœ¬å¼•å¯¼çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ç”±äºç¼ºå°‘å¤šæ¨¡æ€æ•°æ®é›†è€Œç ”ç©¶è¾ƒå°‘ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ã€‚
    - (2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå½“å‰ç ”ç©¶è™½ç„¶å·²ç»å–å¾—äº†è¿›å±•ï¼Œä½†ç”±äºç¼ºä¹å¤§è§„æ¨¡çš„å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ•°æ®é›†ï¼Œç°æœ‰çš„æ–¹æ³•åœ¨å®è·µä¸­éš¾ä»¥è¾¾åˆ°é¢„æœŸæ•ˆæœã€‚ç”±äºç¼ºä¹ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿æ€å’Œå¯èƒ½çš„åœºæ™¯ä¿¡æ¯ï¼Œç°æœ‰æ•°æ®é›†é™åˆ¶äº†è¯¥é¢†åŸŸçš„å‘å±•ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºå»ºç«‹ä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ•°æ®é›†MMHeadã€‚
    - (3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡é¦–å…ˆæ•´åˆäº†äº”ä¸ªå…¬å…±äºŒç»´è‚–åƒè§†é¢‘æ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨ç®¡é“æ¥å¤„ç†è¿™äº›æ•°æ®é›†ï¼ŒåŒ…æ‹¬ä»å•ç›®è§†é¢‘ä¸­é‡å»ºä¸‰ç»´é¢éƒ¨è¿åŠ¨åºåˆ—å’Œå€ŸåŠ©AUæ£€æµ‹å’ŒChatGPTè·å–å±‚æ¬¡åŒ–æ–‡æœ¬æ³¨é‡Šã€‚åŸºäºMMHeadæ•°æ®é›†ï¼Œæœ¬æ–‡å»ºç«‹äº†ä¸¤ä¸ªæ–°ä»»åŠ¡çš„æ ‡å‡†ï¼šæ–‡æœ¬å¼•å¯¼çš„ä¸‰ç»´è¯´è¯äººåŠ¨ç”»å’Œæ–‡æœ¬åˆ°ä¸‰ç»´é¢éƒ¨è¿åŠ¨çš„ç”Ÿæˆã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§ç®€å•çš„ä½†æœ‰æ•ˆçš„VQ-VAEæ–¹æ³•â€”â€”MM2Faceï¼Œèƒ½å¤Ÿç»Ÿä¸€å¤šæ¨¡æ€ä¿¡æ¯å¹¶ç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ã€‚
    - (4) ä»»åŠ¡ä¸æ€§èƒ½ï¼šæœ¬æ–‡åœ¨å»ºç«‹çš„æ–°æ•°æ®é›†MMHeadä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº†MMHeadæ•°æ®é›†çš„æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚åŒæ—¶ï¼ŒåŸºäºè¯¥æ•°æ®é›†å»ºç«‹çš„åŸºå‡†æµ‹è¯•è¯æ˜äº†MM2Faceæ–¹æ³•çš„ç«äº‰åŠ›ã€‚æœ¬æ–‡çš„ç ”ç©¶æˆæœå¯¹äºæ¨åŠ¨å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»é¢†åŸŸçš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚æ•°æ®é›†å°†åœ¨æŒ‡å®šçš„ç½‘ç«™ä¸Šå…¬å¼€å‘å¸ƒã€‚

è¯·æ³¨æ„ï¼Œç”±äºè®ºæ–‡å°šæœªå…¬å¼€å‘è¡¨ï¼ŒæŸäº›é“¾æ¥å’Œè¯¦ç»†ä¿¡æ¯å¯èƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚ä»¥ä¸Šå†…å®¹æ˜¯åŸºäºæä¾›çš„è®ºæ–‡æ‘˜è¦å’Œç›¸å…³ä¿¡æ¯è¿›è¡Œçš„æ•´ç†ã€‚
7. æ–¹æ³•ï¼š

* (1) ç ”ç©¶èƒŒæ™¯åˆ†æï¼šç ”ç©¶å›¢é˜Ÿå‘ç°å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»åœ¨å¤šåª’ä½“é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä½†ç›®å‰ç›¸å…³ç ”ç©¶å› ç¼ºä¹å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†è€Œå—åˆ°é™åˆ¶ã€‚ç‰¹åˆ«æ˜¯æ–‡æœ¬å¼•å¯¼çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»é¢†åŸŸç¼ºä¹ç›¸å…³çš„æ•°æ®é›†ï¼Œè¿™å½±å“äº†ç›¸å…³ç ”ç©¶çš„å‘å±•ã€‚å› æ­¤ï¼Œç ”ç©¶å›¢é˜Ÿå†³å®šè§£å†³è¿™ä¸€é—®é¢˜ã€‚
* (2) æ•°æ®é›†å»ºç«‹ï¼šä¸ºäº†å…‹æœç°æœ‰ç ”ç©¶çš„å±€é™æ€§ï¼Œç ”ç©¶å›¢é˜Ÿæ•´åˆäº†äº”ä¸ªå…¬å…±äºŒç»´è‚–åƒè§†é¢‘æ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªè‡ªåŠ¨ç®¡é“æ¥å¤„ç†è¿™äº›æ•°æ®é›†ã€‚è¯¥ç®¡é“åŒ…æ‹¬ä»å•ç›®è§†é¢‘ä¸­é‡å»ºä¸‰ç»´é¢éƒ¨è¿åŠ¨åºåˆ—å’Œå€ŸåŠ©AUæ£€æµ‹å’ŒChatGPTè·å–å±‚æ¬¡åŒ–æ–‡æœ¬æ³¨é‡Šã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿå»ºç«‹äº†æ–°çš„å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ•°æ®é›†MMHeadã€‚
* (3) æ–°ä»»åŠ¡å®šä¹‰ï¼šåŸºäºMMHeadæ•°æ®é›†ï¼Œç ”ç©¶å›¢é˜Ÿå»ºç«‹äº†ä¸¤ä¸ªæ–°ä»»åŠ¡çš„æ ‡å‡†ï¼Œå³æ–‡æœ¬å¼•å¯¼çš„ä¸‰ç»´è¯´è¯äººåŠ¨ç”»å’Œæ–‡æœ¬åˆ°ä¸‰ç»´é¢éƒ¨è¿åŠ¨çš„ç”Ÿæˆã€‚è¿™ä¸¤ä¸ªä»»åŠ¡çš„å»ºç«‹ä¸ºåç»­çš„ç ”ç©¶æä¾›äº†åŸºå‡†æµ‹è¯•ã€‚
* (4) æ–¹æ³•æå‡ºï¼šç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§ç®€å•çš„ä½†æœ‰æ•ˆçš„VQ-VAEæ–¹æ³•â€”â€”MM2Faceã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿç»Ÿä¸€å¤šæ¨¡æ€ä¿¡æ¯å¹¶ç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ã€‚è¯¥æ–¹æ³•åŸºäºMMHeadæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå®éªŒç»“æœè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œç«äº‰åŠ›ã€‚æ•°æ®é›†å°†åœ¨æŒ‡å®šçš„ç½‘ç«™ä¸Šå…¬å¼€å‘å¸ƒã€‚è¯¥æ–¹æ³•çš„åˆ›æ–°æ€§åœ¨äºç»“åˆäº†å¤šæ¨¡æ€ä¿¡æ¯ï¼Œä½¿å¾—ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ›´åŠ ç”ŸåŠ¨è‡ªç„¶ã€‚å…·ä½“çš„æ“ä½œæµç¨‹å’ŒæŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¯¦ç»†é˜è¿°ã€‚

ä»¥ä¸Šæ˜¯å¯¹è¯¥è®ºæ–‡æ–¹æ³•éƒ¨åˆ†çš„è¯¦ç»†æ¦‚æ‹¬å’Œæ€»ç»“ï¼Œå¸Œæœ›èƒ½å¤Ÿå¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚
8. Conclusion:

(1) è¿™ç¯‡æ–‡ç« çš„å·¥ä½œæ„ä¹‰åœ¨äºæ¨åŠ¨äº†å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»é¢†åŸŸçš„å‘å±•ã€‚æ–‡ç« å»ºç«‹äº†ä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ•°æ®é›†MMHeadï¼Œå¹¶åŸºäºè¯¥æ•°æ®é›†å»ºç«‹äº†ä¸¤ä¸ªæ–°ä»»åŠ¡çš„æ ‡å‡†ï¼Œå³æ–‡æœ¬å¼•å¯¼çš„ä¸‰ç»´è¯´è¯äººåŠ¨ç”»å’Œæ–‡æœ¬åˆ°ä¸‰ç»´é¢éƒ¨è¿åŠ¨çš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„VQ-VAEæ–¹æ³•â€”â€”MM2Faceï¼Œèƒ½å¤Ÿç»Ÿä¸€å¤šæ¨¡æ€ä¿¡æ¯å¹¶ç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ã€‚è¿™äº›æ•°æ®é›†å’Œä»»åŠ¡æ ‡å‡†çš„å»ºç«‹ä»¥åŠæ–¹æ³•çš„æå‡ºå°†æœ‰åŠ©äºæ¨åŠ¨å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨ã€‚

(2) åˆ›æ–°ç‚¹ï¼šæ–‡ç« å»ºç«‹äº†æ–°çš„å¤šæ¨¡æ€ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æ•°æ®é›†MMHeadï¼Œå¹¶åŸºäºè¯¥æ•°æ®é›†æå‡ºäº†ä¸¤ä¸ªæ–°ä»»åŠ¡çš„æ ‡å‡†ï¼Œä½“ç°äº†è¾ƒå¼ºçš„åˆ›æ–°æ€§ã€‚åŒæ—¶ï¼Œæ–‡ç« æå‡ºçš„MM2Faceæ–¹æ³•èƒ½å¤Ÿç»Ÿä¸€å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆåˆç†ä¸”å¤šæ ·çš„ä¸‰ç»´é¢éƒ¨è¿åŠ¨ï¼Œå…·æœ‰è¾ƒé«˜çš„æ€§èƒ½ã€‚ä½†æ–‡ç« åœ¨æ€§èƒ½æ–¹é¢ä¹Ÿå­˜åœ¨ä¸€å®šå±€é™æ€§ï¼Œå¦‚å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†çš„å¤„ç†å’Œå¤æ‚åœºæ™¯çš„åº”ç”¨ä»éœ€è¿›ä¸€æ­¥ç ”ç©¶å’Œä¼˜åŒ–ã€‚åœ¨å·¥ä½œé‡æ–¹é¢ï¼Œæ–‡ç« æ•´åˆäº†å¤šä¸ªå…¬å…±äºŒç»´è‚–åƒè§†é¢‘æ•°æ®é›†å¹¶å¼€å‘äº†è‡ªåŠ¨ç®¡é“å¤„ç†è¿™äº›æ•°æ®é›†ï¼Œå·¥ä½œé‡è¾ƒå¤§ï¼›ä½†åœ¨å…·ä½“æ–¹æ³•çš„æå‡ºå’Œå®éªŒéªŒè¯æ–¹é¢ï¼Œæ–‡ç« å†…å®¹ç›¸å¯¹ç®€æ´ï¼Œæœªæ¶‰åŠå¤§é‡å¤æ‚çš„è®¡ç®—å’Œæ¨å¯¼ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-42f46b66e7d42d2ba71796a57ce9de1a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a5913c90431177376e725a374854ba1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ff25a2e0173b8c4c67bb51d49a7322e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50463d983b849736c22e81e3e312927d.jpg" align="middle">
</details>




## Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image   Animation

**Authors:Jiahao Cui, Hui Li, Yao Yao, Hao Zhu, Hanlin Shang, Kaihui Cheng, Hang Zhou, Siyu Zhu, Jingdong Wang**

Recent advances in latent diffusion-based generative models for portrait image animation, such as Hallo, have achieved impressive results in short-duration video synthesis. In this paper, we present updates to Hallo, introducing several design enhancements to extend its capabilities. First, we extend the method to produce long-duration videos. To address substantial challenges such as appearance drift and temporal artifacts, we investigate augmentation strategies within the image space of conditional motion frames. Specifically, we introduce a patch-drop technique augmented with Gaussian noise to enhance visual consistency and temporal coherence over long duration. Second, we achieve 4K resolution portrait video generation. To accomplish this, we implement vector quantization of latent codes and apply temporal alignment techniques to maintain coherence across the temporal dimension. By integrating a high-quality decoder, we realize visual synthesis at 4K resolution. Third, we incorporate adjustable semantic textual labels for portrait expressions as conditional inputs. This extends beyond traditional audio cues to improve controllability and increase the diversity of the generated content. To the best of our knowledge, Hallo2, proposed in this paper, is the first method to achieve 4K resolution and generate hour-long, audio-driven portrait image animations enhanced with textual prompts. We have conducted extensive experiments to evaluate our method on publicly available datasets, including HDTF, CelebV, and our introduced "Wild" dataset. The experimental results demonstrate that our approach achieves state-of-the-art performance in long-duration portrait video animation, successfully generating rich and controllable content at 4K resolution for duration extending up to tens of minutes. Project page https://fudan-generative-vision.github.io/hallo2 

[PDF](http://arxiv.org/abs/2410.07718v1) 

**Summary**
ç ”ç©¶æå‡ºæ”¹è¿›åçš„Halloæ¨¡å‹ï¼Œå¯ç”Ÿæˆé•¿æ—¶ã€4Kåˆ†è¾¨ç‡ã€æ–‡æœ¬é©±åŠ¨çš„è‚–åƒåŠ¨ç”»è§†é¢‘ã€‚

**Key Takeaways**
1. Halloæ¨¡å‹å‡çº§æ”¯æŒé•¿æ—¶è§†é¢‘åˆæˆã€‚
2. å¼•å…¥å›¾åƒç©ºé—´ä¸­çš„å¢å¼ºç­–ç•¥ï¼Œè§£å†³å¤–è§‚æ¼‚ç§»å’Œæ—¶åºä¼ªå½±ã€‚
3. å®ç°äº†4Kåˆ†è¾¨ç‡è‚–åƒè§†é¢‘ç”Ÿæˆã€‚
4. é‡‡ç”¨çŸ¢é‡é‡åŒ–æ½œä»£ç å’Œæ—¶åºå¯¹é½æŠ€æœ¯ã€‚
5. å¼•å…¥å¯è°ƒèŠ‚çš„è¯­ä¹‰æ–‡æœ¬æ ‡ç­¾ï¼Œæé«˜å¯æ§æ€§å’Œå†…å®¹å¤šæ ·æ€§ã€‚
6. Hallo2ä¸ºé¦–ä¸ªå®ç°4Kåˆ†è¾¨ç‡ã€æ—¶é•¿å¯è¾¾æ•°å°æ—¶çš„æ–‡æœ¬é©±åŠ¨è‚–åƒåŠ¨ç”»æ–¹æ³•ã€‚
7. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é•¿æ—¶è‚–åƒè§†é¢‘åŠ¨ç”»æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**


7. æ–¹æ³•ï¼š

*(1) SEINE Chenç­‰äººï¼ˆ2023bï¼‰å¼•å…¥ç”Ÿæˆè¿‡æ¸¡çš„æ¦‚å¿µï¼š*

* è¯¥æ–¹æ³•å…³æ³¨äºå¹³æ»‘åœºæ™¯å˜åŒ–ï¼Œé€šè¿‡ç”Ÿæˆè¿‡æ¸¡æ¥å¢å¼ºè§†è§‰è¿è´¯æ€§ã€‚
* ä½¿ç”¨è¯­ä¹‰è¿åŠ¨é¢„æµ‹å™¨æ¥é¢„æµ‹åœºæ™¯ä¸­çš„åŠ¨ä½œå’Œäº‹ä»¶ï¼Œä»¥å®ç°è‡ªç„¶æµç•…çš„è¿‡æ¸¡æ•ˆæœã€‚

*(2) StoryDiffusion Zhouç­‰äººï¼ˆ2024ï¼‰çš„æ–¹æ³•ï¼š*

* è¯¥æ–¹æ³•ä¸“æ³¨äºè§†è§‰æ•…äº‹å™è¿°ï¼Œé€šè¿‡å¼•å…¥ç”Ÿæˆæ¨¡å‹æ¥åˆ›å»ºè¿è´¯çš„æ•…äº‹æƒ…èŠ‚ã€‚
* åˆ©ç”¨è¯­ä¹‰è¿åŠ¨é¢„æµ‹å™¨æ¥åˆ†æåœºæ™¯ä¸­çš„å¯¹è±¡åŠ¨ä½œå’Œå®ƒä»¬ä¹‹é—´çš„æ½œåœ¨å…³ç³»ã€‚
* é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰é€»è¾‘è¿è´¯æ€§çš„åœºæ™¯ï¼Œå®ç°æµç•…çš„æ•…äº‹å™è¿°ã€‚

ä»¥ä¸Šå†…å®¹ä»…ä¸ºæ ¹æ®æ‚¨æä¾›çš„æè¿°è¿›è¡Œçš„æ¦‚æ‹¬ï¼Œå…·ä½“çš„ç»†èŠ‚å¯èƒ½éœ€è¦æŸ¥é˜…åŸæ–‡ä»¥è·å–æ›´å‡†ç¡®çš„ä¿¡æ¯ã€‚
8. ç»“è®ºï¼š

(1) è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼š
è¯¥æ–‡ç« å±•ç¤ºäº†é€šè¿‡å¢å¼ºHalloæ¡†æ¶çš„åŠŸèƒ½åœ¨è‚–åƒå›¾åƒåŠ¨ç”»æ–¹é¢çš„è¿›å±•ã€‚é€šè¿‡æ‰©å±•åŠ¨ç”»æŒç»­æ—¶é—´è‡³æ•°ååˆ†é’Ÿå¹¶ä¿æŒé«˜åˆ†è¾¨ç‡çš„4Kè¾“å‡ºï¼Œè¯¥ç ”ç©¶è§£å†³äº†ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—å±€é™æ€§ã€‚è¯¥å·¥ä½œå¯¹é•¿æ—¶é—´ã€é«˜åˆ†è¾¨ç‡è‚–åƒå›¾åƒåŠ¨ç”»é¢†åŸŸåšå‡ºäº†é‡è¦è´¡çŒ®ã€‚

(2) åˆ›æ–°æ€§ã€æ€§èƒ½å’Œå·¥ä½œé‡æ–¹é¢çš„æ€»ç»“ï¼š

* åˆ›æ–°æ€§ï¼šæ–‡ç« æå‡ºäº†åˆ›æ–°çš„è‚–åƒå›¾åƒåŠ¨ç”»æ–¹æ³•ï¼Œé€šè¿‡æ‰©å±•åŠ¨ç”»æŒç»­æ—¶é—´ã€å®æ–½æ•°æ®å¢å¼ºæŠ€æœ¯ã€å®æ–½å‘é‡é‡åŒ–æ½œåœ¨ä»£ç ä»¥åŠé‡‡ç”¨æ—¶é—´å¯¹é½æŠ€æœ¯ç­‰æ–¹æ³•ï¼Œä¸ºè‚–åƒå›¾åƒåŠ¨ç”»å¸¦æ¥äº†æ–°çš„çªç ´ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜ç»“åˆäº†éŸ³é¢‘é©±åŠ¨ä¿¡å·å’Œå¯è°ƒæ•´çš„è¯­ä¹‰æ–‡æœ¬æç¤ºï¼Œå®ç°äº†å¯¹é¢éƒ¨è¡¨æƒ…å’Œè¿åŠ¨åŠ¨æ€çš„ç²¾ç¡®æ§åˆ¶ã€‚
* æ€§èƒ½ï¼šæ–‡ç« çš„æ–¹æ³•åœ¨å…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒéªŒè¯ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚æ‰€ç”Ÿæˆçš„åŠ¨ç”»å…·æœ‰é€¼çœŸçš„æ•ˆæœï¼Œä¸”é•¿æ—¶é—´ä¿æŒé«˜è´¨é‡è¾“å‡ºã€‚ç„¶è€Œï¼Œå…³äºæ€§èƒ½çš„å…·ä½“æ•°æ®ï¼ˆå¦‚å¤„ç†é€Ÿåº¦ã€å†…å­˜å ç”¨ç­‰ï¼‰æœªåœ¨æ‘˜è¦ä¸­æåŠã€‚
* å·¥ä½œé‡ï¼šæ–‡ç« æ¶‰åŠå¤§é‡çš„å®éªŒéªŒè¯å’Œç®—æ³•å¼€å‘ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚æ­¤å¤–ï¼Œæ–‡ç« çš„æ–¹æ³•éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºå’Œå­˜å‚¨èµ„æºæ¥å®ç°é«˜åˆ†è¾¨ç‡çš„é•¿æ—¶é—´åŠ¨ç”»ã€‚ä½†ç”±äºæ‘˜è¦ä¸­æ²¡æœ‰å…·ä½“æåŠå·¥ä½œé‡çš„å¤§å°å’Œè®¡ç®—èµ„æºçš„å…·ä½“éœ€æ±‚ï¼Œæ— æ³•å‡†ç¡®è¯„ä¼°è¯¥æ–¹é¢ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bf351a38d373ad29c81b373fe10d2463.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77d1fa55cf81360393f5957b78ed13bf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f81bbe1cc73d4a426701300e3abb6f04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27d927b8dac8bd9f3b3b9b030bc7fc2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63f166e791c3b6969cb0c682cb2ee1ed.jpg" align="middle">
</details>




## FaceVid-1K: A Large-Scale High-Quality Multiracial Human Face Video   Dataset

**Authors:Donglin Di, He Feng, Wenzhang Sun, Yongjia Ma, Hao Li, Wei Chen, Xiaofei Gou, Tonghua Su, Xun Yang**

Generating talking face videos from various conditions has recently become a highly popular research area within generative tasks. However, building a high-quality face video generation model requires a well-performing pre-trained backbone, a key obstacle that universal models fail to adequately address. Most existing works rely on universal video or image generation models and optimize control mechanisms, but they neglect the evident upper bound in video quality due to the limited capabilities of the backbones, which is a result of the lack of high-quality human face video datasets. In this work, we investigate the unsatisfactory results from related studies, gather and trim existing public talking face video datasets, and additionally collect and annotate a large-scale dataset, resulting in a comprehensive, high-quality multiracial face collection named \textbf{FaceVid-1K}. Using this dataset, we craft several effective pre-trained backbone models for face video generation. Specifically, we conduct experiments with several well-established video generation models, including text-to-video, image-to-video, and unconditional video generation, under various settings. We obtain the corresponding performance benchmarks and compared them with those trained on public datasets to demonstrate the superiority of our dataset. These experiments also allow us to investigate empirical strategies for crafting domain-specific video generation tasks with cost-effective settings. We will make our curated dataset, along with the pre-trained talking face video generation models, publicly available as a resource contribution to hopefully advance the research field. 

[PDF](http://arxiv.org/abs/2410.07151v1) 

**Summary**
æˆ‘ä»¬æ„å»ºäº†FaceVid-1Kæ•°æ®é›†ï¼Œå¹¶è®¾è®¡é¢„è®­ç»ƒæ¨¡å‹æå‡äººè„¸è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚

**Key Takeaways**
1. äººè„¸è§†é¢‘ç”Ÿæˆç ”ç©¶çƒ­é—¨ï¼Œä½†é«˜è´¨æ¨¡å‹éœ€é«˜æ€§èƒ½é¢„è®­ç»ƒéª¨å¹²ã€‚
2. ç°æœ‰æ¨¡å‹å¿½è§†éª¨å¹²é™åˆ¶ï¼Œå¯¼è‡´è§†é¢‘è´¨é‡ä¸Šé™ã€‚
3. æˆ‘ä»¬æ”¶é›†å’Œæ•´ç†äº†FaceVid-1Ké«˜è´¨é‡äººè„¸è§†é¢‘æ•°æ®é›†ã€‚
4. è®¾è®¡é¢„è®­ç»ƒéª¨å¹²æ¨¡å‹ï¼Œä¼˜åŒ–äººè„¸è§†é¢‘ç”Ÿæˆã€‚
5. åœ¨å¤šç§ç”Ÿæˆæ¨¡å‹ä¸‹è¿›è¡Œå®éªŒï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è§†é¢‘ã€å›¾åƒåˆ°è§†é¢‘å’Œæ— æ¡ä»¶è§†é¢‘ç”Ÿæˆã€‚
6. å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†åœ¨æ€§èƒ½ä¸Šä¼˜äºå…¬å…±æ•°æ®é›†ã€‚
7. æ•°æ®é›†å’Œæ¨¡å‹å°†å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›ç ”ç©¶è¿›å±•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**


8. Conclusion:

* (1) è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºå¼•å…¥äº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å¤šç§æ—çš„äººè„¸è§†é¢‘æ•°æ®é›†FaceVid-1Kï¼Œå¹¶å¼ºè°ƒè¯¥èµ„æºèƒ½å¤Ÿæ»¡è¶³äººè„¸è§†é¢‘ç”Ÿæˆç›¸å…³ç ”ç©¶ä»»åŠ¡çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨è¯¥æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒï¼Œè·å¾—äº†ä¸€äº›æœ‰ä»·å€¼çš„å®è¯è§è§£ã€‚
* (2) åˆ›æ–°ç‚¹ï¼šå¼•å…¥äº†æ–°çš„å¤§è§„æ¨¡ã€å¤šç§æ—çš„äººè„¸è§†é¢‘æ•°æ®é›†FaceVid-1Kï¼Œå¹¶è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒéªŒè¯ã€‚æ€§èƒ½ï¼šæ–‡ç« æœªå…·ä½“æåŠè¯¥æ•°æ®é›†æˆ–å®éªŒçš„å…·ä½“æ€§èƒ½æŒ‡æ ‡ã€‚å·¥ä½œé‡ï¼šæ•°æ®é›†æ”¶é›†ä¸å®éªŒçš„å·¥ä½œé‡è¾ƒå¤§ï¼Œä½†æ–‡ç« æœªå…·ä½“é˜è¿°å…¶å·¥ä½œé‡çš„å¤§å°æˆ–æŠ•å…¥çš„èµ„æºã€‚

è¯·æ³¨æ„ï¼Œç”±äºæ— æ³•è·å–æ•´ç¯‡æ–‡ç« çš„å®Œæ•´å†…å®¹ï¼Œæˆ‘çš„å›ç­”å¯èƒ½æœ‰æ‰€åå·®ã€‚å¦‚æœæœ‰éœ€è¦ï¼Œè¯·æä¾›æ›´å¤šæ–‡ç« ä¿¡æ¯ä»¥ä¾¿æ›´å‡†ç¡®åœ°å›ç­”ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-515afa1627a07ec6cd0b302c38c1577e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8dd77590dd8da3e9af10f3ce40ba386d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0462eb9f319928ced3326832fa043790.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e5b52bc6d6018d95babb95c73e966833.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cebc81cdf124fcc840075376cb634fbd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b9b6908fdc18eab28a4f84f59456fef.jpg" align="middle">
</details>




## MimicTalk: Mimicking a personalized and expressive 3D talking face in   minutes

**Authors:Zhenhui Ye, Tianyun Zhong, Yi Ren, Ziyue Jiang, Jiawei Huang, Rongjie Huang, Jinglin Liu, Jinzheng He, Chen Zhang, Zehan Wang, Xize Chen, Xiang Yin, Zhou Zhao**

Talking face generation (TFG) aims to animate a target identity's face to create realistic talking videos. Personalized TFG is a variant that emphasizes the perceptual identity similarity of the synthesized result (from the perspective of appearance and talking style). While previous works typically solve this problem by learning an individual neural radiance field (NeRF) for each identity to implicitly store its static and dynamic information, we find it inefficient and non-generalized due to the per-identity-per-training framework and the limited training data. To this end, we propose MimicTalk, the first attempt that exploits the rich knowledge from a NeRF-based person-agnostic generic model for improving the efficiency and robustness of personalized TFG. To be specific, (1) we first come up with a person-agnostic 3D TFG model as the base model and propose to adapt it into a specific identity; (2) we propose a static-dynamic-hybrid adaptation pipeline to help the model learn the personalized static appearance and facial dynamic features; (3) To generate the facial motion of the personalized talking style, we propose an in-context stylized audio-to-motion model that mimics the implicit talking style provided in the reference video without information loss by an explicit style representation. The adaptation process to an unseen identity can be performed in 15 minutes, which is 47 times faster than previous person-dependent methods. Experiments show that our MimicTalk surpasses previous baselines regarding video quality, efficiency, and expressiveness. Source code and video samples are available at https://mimictalk.github.io . 

[PDF](http://arxiv.org/abs/2410.06734v1) Accepted by NeurIPS 2024

**Summary**
æå‡ºMimicTalkæ¨¡å‹ï¼Œåˆ©ç”¨NeRFæ„å»ºçš„é€šç”¨æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆã€ä¸ªæ€§åŒ–çš„è¯´è¯äººè„¸ç”Ÿæˆã€‚

**Key Takeaways**
- æå‡ºMimicTalkï¼Œä¼˜åŒ–ä¸ªæ€§åŒ–è¯´è¯äººè„¸ç”Ÿæˆã€‚
- åˆ©ç”¨NeRFæ„å»ºé€šç”¨æ¨¡å‹ï¼Œæé«˜æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚
- è®¾è®¡é™æ€-åŠ¨æ€æ··åˆé€‚é…æµç¨‹ï¼Œå­¦ä¹ ä¸ªæ€§åŒ–ç‰¹å¾ã€‚
- é¦–æ¬¡å®ç°é£æ ¼åŒ–çš„éŸ³é¢‘åˆ°åŠ¨ä½œæ¨¡å‹ï¼Œæ¨¡ä»¿è¯´è¯é£æ ¼ã€‚
- é€‚é…è¿‡ç¨‹å¿«é€Ÿï¼Œ15åˆ†é’Ÿå®Œæˆï¼Œè¿œè¶…ä¼ ç»Ÿæ–¹æ³•ã€‚
- å®éªŒè¯æ˜ï¼ŒMimicTalkåœ¨è§†é¢‘è´¨é‡ã€æ•ˆç‡å’Œè¡¨ç°åŠ›æ–¹é¢ä¼˜äºå‰äººã€‚
- å¼€æ”¾æºä»£ç å’Œè§†é¢‘ç¤ºä¾‹ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. **æ ‡é¢˜**ï¼šMimicTalk: æ¨¡ä»¿ä¸ªæ€§åŒ–ä¸è¡¨è¾¾åŠ›çš„ä¸‰ç»´äººè„¸å¿«é€Ÿç”ŸæˆæŠ€æœ¯ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰ã€‚
2. **ä½œè€…**ï¼šZhenhui Ye, Tianyun Zhong, Yi Ren, ç­‰ï¼ˆä½œè€…åå•åŠæ‰€å±å•ä½ï¼‰ã€‚
3. **ä½œè€…æ‰€å±å•ä½ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰**ï¼šæµ™æ±Ÿå¤§å­¦ï¼ˆZhejiang Universityï¼‰ä¸å­—èŠ‚è·³åŠ¨ï¼ˆByteDanceï¼‰ã€‚
4. **å…³é”®è¯**ï¼šTalking Face Generation (TFG), Personalized TFG, Neural Radiance Fields (NeRF), Efficient Adaptation, Style Mimickingã€‚
5. **é“¾æ¥**ï¼šè®ºæ–‡é“¾æ¥ï¼ˆå¾…è¡¥å……ï¼‰ï¼ŒGitHubä»£ç é“¾æ¥ï¼š[GitHubé“¾æ¥å°šæœªæä¾›]ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚
6. **æ‘˜è¦**ï¼š

     - (1) ç ”ç©¶èƒŒæ™¯ï¼šæœ¬æ–‡ç ”ç©¶éŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´äººè„¸ç”ŸæˆæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä¸ªæ€§åŒ–ä¸è¡¨è¾¾åŠ›çš„å¿«é€Ÿç”Ÿæˆæ–¹æ³•ã€‚éšç€å¤šåª’ä½“æŠ€æœ¯çš„å‘å±•ï¼ŒéŸ³é¢‘ä¸è§†è§‰ç»“åˆçš„åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ï¼Œæ­¤æŠ€æœ¯å¹¿æ³›åº”ç”¨äºè§†é¢‘ä¼šè®®ã€éŸ³é¢‘å¯è§†åŒ–èŠå¤©æœºå™¨äººç­‰é¢†åŸŸã€‚
     - (2) ç°æœ‰æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„ä¸ªæ€§åŒ–ä¸‰ç»´äººè„¸ç”Ÿæˆæ–¹æ³•é€šå¸¸é‡‡ç”¨å­¦ä¹ ä¸ªä½“ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ–¹å¼ä¸ºæ¯ä¸ªèº«ä»½éšå¼å­˜å‚¨é™æ€å’ŒåŠ¨æ€ä¿¡æ¯ã€‚ä½†è¿™ç§æ–¹å¼æ•ˆç‡ä½ä¸”ç¼ºä¹é€šç”¨æ€§ï¼Œå› ä¸ºéœ€è¦ä¸ºæ¯ä¸ªèº«ä»½è¿›è¡Œå•ç‹¬çš„è®­ç»ƒä¸”å—é™äºè®­ç»ƒæ•°æ®ã€‚
     - (3) ç ”ç©¶æ–¹æ³•ï¼šæå‡ºMimicTalkæ–¹æ³•ï¼Œé¦–æ¬¡åˆ©ç”¨é€šç”¨çš„éä¸ªæ€§åŒ–NeRFæ¨¡å‹æé«˜ä¸ªæ€§åŒ–TFGçš„æ•ˆç‡ä¸ç¨³å¥æ€§ã€‚åŒ…æ‹¬æ„å»ºä¸€ä¸ªéä¸ªæ€§åŒ–çš„ä¸‰ç»´TFGæ¨¡å‹ä½œä¸ºåŸºå‡†æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œä¸ªæ€§åŒ–é€‚åº”ï¼›é‡‡ç”¨é™æ€ä¸åŠ¨æ€ç»“åˆçš„é€‚åº”æµç¨‹æ¥å­¦ä¹ ä¸ªæ€§åŒ–çš„é™æ€å¤–è§‚å’Œé¢éƒ¨åŠ¨æ€ç‰¹å¾ï¼›æå‡ºä¸Šä¸‹æ–‡é£æ ¼åŒ–çš„éŸ³é¢‘åˆ°åŠ¨ä½œæ¨¡å‹ï¼Œæ¨¡ä»¿å‚è€ƒè§†é¢‘ä¸­çš„éšæ€§è¯´è¯é£æ ¼ã€‚
     - (4) ä»»åŠ¡ä¸æ€§èƒ½ï¼šåœ¨ä¸ªæ€§åŒ–è¯´è¯é£æ ¼çš„ä¸‰ç»´äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—æˆæœï¼Œä¸ä¹‹å‰çš„åŸºçº¿ç›¸æ¯”ï¼Œåœ¨è§†é¢‘è´¨é‡ã€æ•ˆç‡å’Œè¡¨ç°åŠ›æ–¹é¢éƒ½æœ‰æå‡ã€‚å®éªŒè¯æ˜MimicTalkæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚

### æ€»ç»“ï¼š

- **(1)** ç ”ç©¶èƒŒæ™¯ï¼šæœ¬æ–‡ç ”ç©¶äº†éŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´äººè„¸ç”ŸæˆæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•å¿«é€Ÿç”Ÿæˆå…·æœ‰ä¸ªæ€§åŒ–ä¸è¡¨è¾¾åŠ›çš„ä¸‰ç»´äººè„¸ï¼Œåœ¨å¤šåª’ä½“é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚
- **(2)** è¿‡å»çš„æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šè¿‡ä¸ºæ¯ä¸ªèº«ä»½å­¦ä¹ ä¸ªä½“ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¥éšå¼å­˜å‚¨ä¿¡æ¯ï¼Œä½†æ•ˆç‡è¾ƒä½ä¸”ç¼ºä¹é€šç”¨æ€§ã€‚
- **(3)** ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†MimicTalkæ–¹æ³•ï¼Œåˆ©ç”¨é€šç”¨çš„éä¸ªæ€§åŒ–NeRFæ¨¡å‹æ¥æé«˜ä¸ªæ€§åŒ–TFGçš„æ•ˆç‡ä¸ç¨³å¥æ€§ï¼ŒåŒ…æ‹¬æ„å»ºåŸºå‡†æ¨¡å‹ã€ä¸ªæ€§åŒ–é€‚åº”ã€é™æ€ä¸åŠ¨æ€ç‰¹å¾å­¦ä¹ ä»¥åŠéŸ³é¢‘åˆ°åŠ¨ä½œçš„é£æ ¼æ¨¡ä»¿æ¨¡å‹ã€‚
- **(4)** ä»»åŠ¡ä¸æ€§èƒ½ï¼šåœ¨ä¸ªæ€§åŒ–è¯´è¯é£æ ¼çš„ä¸‰ç»´äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—æˆæœï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨è§†é¢‘è´¨é‡ã€æ•ˆç‡å’Œè¡¨ç°åŠ›æ–¹é¢å‡è¶…è¶Šå…ˆå‰æ–¹æ³•ã€‚æ€§èƒ½ç»“æœæ”¯æŒäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
7. æ–¹æ³•ï¼š

(1) ç ”ç©¶èƒŒæ™¯ä¸é—®é¢˜å®šä¹‰ï¼šæ–‡ç« èšç„¦äºéŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´äººè„¸ç”ŸæˆæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•å®ç°å¿«é€Ÿç”Ÿæˆå…·æœ‰ä¸ªæ€§åŒ–ä¸è¡¨è¾¾åŠ›çš„ä¸‰ç»´äººè„¸ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•æ•ˆç‡ä½å’Œç¼ºä¹é€šç”¨æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†æ”¹è¿›çš„éœ€æ±‚ã€‚

(2) æ–¹æ³•æ¦‚è¿°ï¼šæå‡ºMimicTalkæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é€šç”¨çš„éä¸ªæ€§åŒ–NeRFæ¨¡å‹æ¥æé«˜ä¸ªæ€§åŒ–TFGçš„æ•ˆç‡ä¸ç¨³å¥æ€§ã€‚é¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªéä¸ªæ€§åŒ–çš„ä¸‰ç»´TFGæ¨¡å‹ä½œä¸ºåŸºå‡†æ¨¡å‹ã€‚ç„¶åï¼Œå¯¹æ­¤åŸºå‡†æ¨¡å‹è¿›è¡Œä¸ªæ€§åŒ–é€‚åº”ï¼Œä»¥é€‚åº”ä¸åŒä¸ªä½“çš„ç‰¹å¾ã€‚

(3) é™æ€ä¸åŠ¨æ€ç‰¹å¾å­¦ä¹ ï¼šé‡‡ç”¨é™æ€ä¸åŠ¨æ€ç»“åˆçš„é€‚åº”æµç¨‹ï¼Œé€šè¿‡å­¦ä¹ ä¸ªæ€§åŒ–çš„é™æ€å¤–è§‚å’Œé¢éƒ¨åŠ¨æ€ç‰¹å¾ï¼Œå®ç°æ›´ä¸ºçœŸå®å’Œè‡ªç„¶çš„äººè„¸ç”Ÿæˆã€‚

(4) éŸ³é¢‘åˆ°åŠ¨ä½œçš„é£æ ¼æ¨¡ä»¿ï¼šæå‡ºä¸Šä¸‹æ–‡é£æ ¼åŒ–çš„éŸ³é¢‘åˆ°åŠ¨ä½œæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ¨¡ä»¿å‚è€ƒè§†é¢‘ä¸­çš„éšæ€§è¯´è¯é£æ ¼ï¼Œä½¿å¾—ç”Ÿæˆçš„ä¸‰ç»´äººè„¸èƒ½å¤Ÿä½“ç°åŸè¯´è¯äººçš„è¡¨è¾¾ç‰¹ç‚¹ã€‚

(5) å®éªŒéªŒè¯ï¼šé€šè¿‡å¤§é‡çš„å®éªŒéªŒè¯ï¼Œåœ¨ä¸ªæ€§åŒ–è¯´è¯é£æ ¼çš„ä¸‰ç»´äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒMimicTalkæ–¹æ³•å–å¾—äº†æ˜¾è‘—æˆæœï¼Œå¹¶åœ¨è§†é¢‘è´¨é‡ã€æ•ˆç‡å’Œè¡¨ç°åŠ›æ–¹é¢å‡æœ‰æå‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¡¨ç°å‡ºäº†ä¼˜è¶Šæ€§ã€‚
8. Conclusion:

(1)å·¥ä½œæ„ä¹‰ï¼šè¿™ç¯‡æ–‡ç« ç ”ç©¶äº†éŸ³é¢‘é©±åŠ¨çš„ä¸‰ç»´äººè„¸å¿«é€Ÿç”ŸæˆæŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯æ¨¡ä»¿ä¸ªæ€§åŒ–ä¸è¡¨è¾¾åŠ›çš„æŠ€æœ¯ã€‚éšç€å¤šåª’ä½“æŠ€æœ¯çš„å‘å±•ï¼Œè¿™ç§æŠ€æœ¯åœ¨è§†é¢‘ä¼šè®®ã€éŸ³é¢‘å¯è§†åŒ–èŠå¤©æœºå™¨äººç­‰é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚è¯¥ç ”ç©¶å¯¹äºæ¨åŠ¨äººè„¸ç”ŸæˆæŠ€æœ¯çš„ä¸ªæ€§åŒ–å’Œè¡¨è¾¾åŠ›æå‡å…·æœ‰é‡è¦æ„ä¹‰ã€‚

(2)åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ä¸‰ç»´è¯„ä»·ï¼š

åˆ›æ–°ç‚¹ï¼šæ–‡ç« æå‡ºäº†MimicTalkæ–¹æ³•ï¼Œåˆ©ç”¨é€šç”¨çš„éä¸ªæ€§åŒ–NeRFæ¨¡å‹æ¥æé«˜ä¸ªæ€§åŒ–TFGçš„æ•ˆç‡ä¸ç¨³å¥æ€§ï¼Œè¿™æ˜¯è¯¥é¢†åŸŸçš„ä¸€ä¸ªæ–°çš„å°è¯•å’Œæ¢ç´¢ã€‚

æ€§èƒ½ï¼šåœ¨ä¸ªæ€§åŒ–è¯´è¯é£æ ¼çš„ä¸‰ç»´äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒMimicTalkæ–¹æ³•å–å¾—äº†æ˜¾è‘—æˆæœï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨è§†é¢‘è´¨é‡ã€æ•ˆç‡å’Œè¡¨ç°åŠ›æ–¹é¢å‡è¶…è¶Šå…ˆå‰æ–¹æ³•ã€‚

å·¥ä½œé‡ï¼šæ–‡ç« è¿›è¡Œäº†å¤§é‡çš„å®éªŒå’ŒéªŒè¯ï¼Œè¯æ˜äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜è¿›è¡Œäº†æ·±å…¥çš„ç†è®ºåˆ†æå’Œè®¨è®ºï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚ä½†æ˜¯ï¼Œæ–‡ç« æ²¡æœ‰æä¾›å……åˆ†çš„å®ç°ç»†èŠ‚å’Œä»£ç å®ç°ï¼Œè¿™å¯èƒ½ä¼šé™åˆ¶å…¶ä»–ç ”ç©¶è€…å¯¹è¯¥æ–¹æ³•çš„æ·±å…¥ç†è§£å’Œåº”ç”¨ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1d9c9ab3a27964701eea89009297aa5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a38af84c9b86216fd7d6091bfab25aa8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fde6139c2cf1945a51e91fbc6e38eda5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-10b8e84a4e8953fda082597a1647d0a8.jpg" align="middle">
</details>




## Towards a GENEA Leaderboard -- an Extended, Living Benchmark for   Evaluating and Advancing Conversational Motion Synthesis

**Authors:Rajmund Nagy, Hendric Voss, Youngwoo Yoon, Taras Kucherenko, Teodor Nikolov, Thanh Hoang-Minh, Rachel McDonnell, Stefan Kopp, Michael Neff, Gustav Eje Henter**

Current evaluation practices in speech-driven gesture generation lack standardisation and focus on aspects that are easy to measure over aspects that actually matter. This leads to a situation where it is impossible to know what is the state of the art, or to know which method works better for which purpose when comparing two publications. In this position paper, we review and give details on issues with existing gesture-generation evaluation, and present a novel proposal for remedying them. Specifically, we announce an upcoming living leaderboard to benchmark progress in conversational motion synthesis. Unlike earlier gesture-generation challenges, the leaderboard will be updated with large-scale user studies of new gesture-generation systems multiple times per year, and systems on the leaderboard can be submitted to any publication venue that their authors prefer. By evolving the leaderboard evaluation data and tasks over time, the effort can keep driving progress towards the most important end goals identified by the community. We actively seek community involvement across the entire evaluation pipeline: from data and tasks for the evaluation, via tooling, to the systems evaluated. In other words, our proposal will not only make it easier for researchers to perform good evaluations, but their collective input and contributions will also help drive the future of gesture-generation research. 

[PDF](http://arxiv.org/abs/2410.06327v1) 15 pages, 2 figures, project page:   https://genea-workshop.github.io/leaderboard/

**Summary**
è¯­éŸ³é©±åŠ¨æ‰‹åŠ¿ç”Ÿæˆè¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–ï¼Œæœ¬æ–‡æå‡ºæ–°æ–¹æ³•æ„å»ºåŠ¨æ€æ’è¡Œæ¦œï¼Œæ¨åŠ¨ç ”ç©¶è¿›å±•ã€‚

**Key Takeaways**
1. ç°æœ‰è¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–ï¼Œå½±å“æˆæœæ¯”è¾ƒã€‚
2. æå‡ºå»ºç«‹åŠ¨æ€æ’è¡Œæ¦œï¼Œå®šæœŸæ›´æ–°ã€‚
3. æ’è¡Œæ¦œç»“åˆå¤§è§„æ¨¡ç”¨æˆ·ç ”ç©¶ï¼Œæå‡è¯„ä»·è´¨é‡ã€‚
4. æ’è¡Œæ¦œå¼€æ”¾ï¼Œæ”¯æŒä»»æ„å‡ºç‰ˆç‰©æäº¤ã€‚
5. é€æ­¥æ¼”è¿›è¯„ä»·æ•°æ®ä¸ä»»åŠ¡ï¼Œè¿½æ±‚é‡è¦ç›®æ ‡ã€‚
6. é¼“åŠ±ç¤¾åŒºå‚ä¸æ•´ä¸ªè¯„ä¼°æµç¨‹ã€‚
7. æ—¨åœ¨æå‡è¯„ä¼°è´¨é‡ï¼Œæ¨åŠ¨æ‰‹åŠ¿ç”Ÿæˆç ”ç©¶å‘å±•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. Title: è¿ˆå‘GENEAæ’è¡Œæ¦œâ€”â€”æ‰©å±•å‹åŠ¨æ€åŸºå‡†æµ‹è¯•ç”¨äºè¯„ä¼°ä¸æ¨åŠ¨å¯¹è¯åŠ¨ä½œåˆæˆçš„å‘å±•

2. Authors: Rajmund Nagy, Hendric Voss, Youngwoo Yoon, Taras Kucharenko, Teodor Nikolov, Thanh Hoang-Minh, Rachel McDonnell, Stefan Kopp, Michael Neff, Gustav Eje Henterç­‰äºº

3. Affiliation: 
   - Rajmund Nagy, Gustav Eje Henterï¼šKTHçš‡å®¶ç†å·¥å­¦é™¢
   - Hendric Voss, Stefan Koppï¼šæ¯”å‹’è´¹å°”å¾·å¤§å­¦
   - Youngwoo Yoonï¼šETRIï¼ˆç”µå­å’Œç”µä¿¡ç ”ç©¶åä¼šï¼‰
   - Taras Kucharenkoï¼šSEED - ç”µå­è‰ºæœ¯
   - Motorica ABå…¬å¸çš„å…¶ä»–ä½œè€…ç­‰ã€‚

4. Keywords: å§¿æ€ç”Ÿæˆè¯„ä¼°ã€åŸºå‡†æµ‹è¯•ã€å¯¹è¯åŠ¨ä½œåˆæˆã€ç¤¾åŒºé©±åŠ¨è§£å†³æ–¹æ¡ˆç­‰ã€‚

5. Urls: [è®ºæ–‡é“¾æ¥](é“¾æ¥åœ°å€)ï¼ŒGithubä»£ç é“¾æ¥ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå¡«å†™ç›¸åº”é“¾æ¥ï¼›å¦‚æœæ²¡æœ‰ï¼Œå¡«å†™"None"ï¼‰

6. Summary: 
   - (1)ç ”ç©¶èƒŒæ™¯ï¼šå½“å‰å§¿æ€ç”Ÿæˆè¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–ï¼Œç°æœ‰çš„è¯„ä¼°æ–¹æ³•è¿‡äºå…³æ³¨æ˜“äºåº¦é‡çš„æ–¹é¢è€Œå¿½ç•¥äº†å®é™…é‡è¦çš„æ–¹é¢ã€‚è¿™ä½¿å¾—æ¯”è¾ƒä¸åŒè®ºæ–‡çš„æ–¹æ³•å˜å¾—å›°éš¾ï¼Œæ— æ³•ç¡®å®šå“ªäº›æ–¹æ³•å¯¹å“ªäº›ç‰¹å®šä»»åŠ¡æ•ˆæœæœ€å¥½ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ³•ã€‚
   - (2)è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰çš„å§¿æ€ç”Ÿæˆè¯„ä¼°å­˜åœ¨è¯¸å¤šä¸è¶³ï¼Œå¦‚ç¼ºä¹ç»Ÿä¸€çš„åŸºå‡†æµ‹è¯•é›†ã€è¯„ä¼°ä»»åŠ¡ä¸è¿è´¯ã€ç”¨æˆ·ç ”ç©¶æ ‡å‡†åŒ–ç¨‹åº¦ä½ç­‰ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†é¢†åŸŸçš„å‘å±•ï¼Œé˜»ç¢äº†æ–°æŠ€æœ¯çš„æ¨å¹¿å’Œåº”ç”¨ã€‚æœ¬æ–‡æå‡ºçš„åŠ¨æœºæ˜¯è§£å†³è¿™äº›é—®é¢˜ï¼Œæä¾›ä¸€ä¸ªæ›´å®Œå–„ã€æ›´æ ‡å‡†çš„è¯„ä¼°æ–¹æ³•ã€‚
   - (3)ç ”ç©¶æ–¹æ³•ï¼šæ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„ç¤¾åŒºé©±åŠ¨çš„æ•´ä½“è§£å†³æ–¹æ¡ˆæ¥åº”å¯¹å§¿æ€ç”Ÿæˆæ¨¡å‹è¯„ä¼°ä¸­çš„ä¸»è¦æŒ‘æˆ˜ã€‚è¯¥æ–¹æ¡ˆåŒ…æ‹¬å»ºç«‹ä¸€ä¸ªåŠ¨æ€çš„ã€ä¸æ–­æ›´æ–°çš„GENEAæ’è¡Œæ¦œï¼Œä»¥æ ‡å‡†çš„æ–¹å¼è¿›è¡Œå§¿æ€ç”Ÿæˆçš„è¯„ä¼°ã€‚æ­¤å¤–ï¼Œè¿˜å¼ºè°ƒäº†ç¤¾åŒºå‚ä¸çš„é‡è¦æ€§ï¼Œä»æ•°æ®ã€ä»»åŠ¡ã€å·¥å…·åˆ°è¯„ä¼°ç³»ç»Ÿçš„å‚ä¸éƒ½è¢«é¼“åŠ±ã€‚æ–‡ç« è¿˜ä»‹ç»äº†æ–°çš„å¯è§†åŒ–å·¥å…·çš„ä½¿ç”¨ï¼Œä»¥ä¾¿æ›´å¥½åœ°å±•ç¤ºå’Œåˆ†æå§¿æ€ç”Ÿæˆæ¨¡å‹çš„ç»“æœã€‚æœ€åé€šè¿‡ä¸æ–­è°ƒæ•´å’Œæ›´æ–°è¯„ä»·æ•°æ®å’Œä»»åŠ¡ä»¥é€‚åº”ç¤¾åŒºè¯†åˆ«çš„æœ€é‡è¦ç›®æ ‡æ¥æ¨åŠ¨é¢†åŸŸå‘å±•ã€‚
   - (4)ä»»åŠ¡ä¸æ€§èƒ½ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ¡ˆæ—¨åœ¨é€šè¿‡å»ºç«‹ä¸€ä¸ªåŠ¨æ€çš„ã€ä¸æ–­æ›´æ–°çš„åŸºå‡†æµ‹è¯•æ’è¡Œæ¦œæ¥æ¨åŠ¨å¯¹è¯åŠ¨ä½œåˆæˆé¢†åŸŸçš„å‘å±•ã€‚è¯¥æ–¹æ¡ˆå°†é‡‡ç”¨å¤§è§„æ¨¡ç”¨æˆ·ç ”ç©¶æ¥è¯„ä¼°æ–°çš„å§¿æ€ç”Ÿæˆç³»ç»Ÿï¼Œå¹¶å°†ç³»ç»Ÿæäº¤åˆ°ä»»ä½•ä½œè€…å–œæ¬¢çš„å‡ºç‰ˆæ¸ é“ã€‚é€šè¿‡ä¸æ–­è¿›åŒ–çš„è¯„ä»·æ•°æ®å’Œä»»åŠ¡ï¼Œè¯¥æ–¹æ¡ˆå°†èƒ½å¤Ÿæ¨åŠ¨ç¤¾åŒºè¯†åˆ«çš„é‡è¦ç›®æ ‡çš„å®ç°ã€‚æœ¬æ–‡çš„æ€§èƒ½è¯„ä»·å°†é€šè¿‡æœªæ¥å‘å¸ƒåœ¨GENEAæ’è¡Œæ¦œä¸Šçš„ç³»ç»Ÿå’Œç›¸å…³ç ”ç©¶æ¥éªŒè¯å’Œæ”¯æŒå…¶ç›®æ ‡å®ç°ã€‚
8. Conclusion:

(1) è¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ç§è§£å†³å§¿æ€ç”Ÿæˆè¯„ä¼°ä¸­å­˜åœ¨é—®é¢˜çš„æ–¹æ³•ï¼Œé€šè¿‡å»ºç«‹åŠ¨æ€çš„ã€ä¸æ–­æ›´æ–°çš„åŸºå‡†æµ‹è¯•æ’è¡Œæ¦œæ¥æ¨åŠ¨å¯¹è¯åŠ¨ä½œåˆæˆé¢†åŸŸçš„å‘å±•ã€‚è¿™é¡¹å·¥ä½œçš„é‡è¦æ€§åœ¨äºä¸ºå§¿æ€ç”Ÿæˆè¯„ä¼°æä¾›äº†ä¸€ä¸ªæ›´å®Œå–„ã€æ›´æ ‡å‡†çš„è¯„ä¼°æ–¹æ³•ï¼Œæœ‰åŠ©äºæ¯”è¾ƒä¸åŒè®ºæ–‡çš„æ–¹æ³•ï¼Œç¡®å®šå“ªäº›æ–¹æ³•å¯¹å“ªäº›ç‰¹å®šä»»åŠ¡æ•ˆæœæœ€å¥½ï¼Œä¿ƒè¿›äº†æ–°æŠ€æœ¯çš„æ¨å¹¿å’Œåº”ç”¨ã€‚

(2) åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç¤¾åŒºé©±åŠ¨çš„æ•´ä½“è§£å†³æ–¹æ¡ˆæ¥åº”å¯¹å§¿æ€ç”Ÿæˆæ¨¡å‹è¯„ä¼°ä¸­çš„ä¸»è¦æŒ‘æˆ˜ï¼Œå»ºç«‹äº†åŠ¨æ€çš„ã€ä¸æ–­æ›´æ–°çš„GENEAæ’è¡Œæ¦œï¼Œä»¥æ ‡å‡†çš„æ–¹å¼è¿›è¡Œå§¿æ€ç”Ÿæˆçš„è¯„ä¼°ï¼Œå¼ºè°ƒäº†ç¤¾åŒºå‚ä¸çš„é‡è¦æ€§ã€‚
æ€§èƒ½ï¼šæ–‡ç« æ‰€ææ–¹æ¡ˆæ—¨åœ¨é€šè¿‡å¤§è§„æ¨¡ç”¨æˆ·ç ”ç©¶æ¥è¯„ä¼°æ–°çš„å§¿æ€ç”Ÿæˆç³»ç»Ÿï¼Œå¹¶é€šè¿‡ä¸æ–­è¿›åŒ–çš„è¯„ä»·æ•°æ®å’Œä»»åŠ¡æ¥æ¨åŠ¨ç¤¾åŒºè¯†åˆ«çš„é‡è¦ç›®æ ‡çš„å®ç°ã€‚
å·¥ä½œé‡ï¼šæ–‡ç« ä»‹ç»äº†æ–°çš„å¯è§†åŒ–å·¥å…·çš„ä½¿ç”¨ï¼Œä»¥ä¾¿æ›´å¥½åœ°å±•ç¤ºå’Œåˆ†æå§¿æ€ç”Ÿæˆæ¨¡å‹çš„ç»“æœï¼Œæœªæ¥å°†é€šè¿‡å‘å¸ƒåœ¨GENEAæ’è¡Œæ¦œä¸Šçš„ç³»ç»Ÿå’Œç›¸å…³ç ”ç©¶æ¥éªŒè¯å’Œæ”¯æŒå…¶ç›®æ ‡å®ç°ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-242295a68599bb2566e8f606631fd0de.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc4b4785bdfe4b7afeb4b2b909af503a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ad4de547fac69da6c8219d6807b3742.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d3eef1ef1c08767c7cd525acec5faf4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f8156047660ccdd1b9e929e2661294eb.jpg" align="middle">
</details>




## Incorporating Talker Identity Aids With Improving Speech Recognition in   Adversarial Environments

**Authors:Sagarika Alavilli, Annesya Banerjee, Gasser Elbanna, Annika Magaro**

Current state-of-the-art speech recognition models are trained to map acoustic signals into sub-lexical units. While these models demonstrate superior performance, they remain vulnerable to out-of-distribution conditions such as background noise and speech augmentations. In this work, we hypothesize that incorporating speaker representations during speech recognition can enhance model robustness to noise. We developed a transformer-based model that jointly performs speech recognition and speaker identification. Our model utilizes speech embeddings from Whisper and speaker embeddings from ECAPA-TDNN, which are processed jointly to perform both tasks. We show that the joint model performs comparably to Whisper under clean conditions. Notably, the joint model outperforms Whisper in high-noise environments, such as with 8-speaker babble background noise. Furthermore, our joint model excels in handling highly augmented speech, including sine-wave and noise-vocoded speech. Overall, these results suggest that integrating voice representations with speech recognition can lead to more robust models under adversarial conditions. 

[PDF](http://arxiv.org/abs/2410.05423v1) Submitted to ICASSP 2025

**Summary**
æœ¬ç ”ç©¶æå‡ºä¸€ç§ç»“åˆè¯´è¯äººè¡¨ç¤ºçš„è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†åœ¨å™ªå£°å’Œè¯­éŸ³å¢å¼ºæ¡ä»¶ä¸‹çš„é²æ£’æ€§ã€‚

**Key Takeaways**
1. è¯­éŸ³è¯†åˆ«æ¨¡å‹å¯¹åˆ†å¸ƒå¤–æ¡ä»¶ï¼ˆå¦‚èƒŒæ™¯å™ªéŸ³ï¼‰æ•æ„Ÿã€‚
2. æå‡ºç»“åˆè¯´è¯äººè¡¨ç¤ºæ¥å¢å¼ºæ¨¡å‹é²æ£’æ€§çš„å‡è®¾ã€‚
3. å¼€å‘äº†ä¸€ç§åŸºäºtransformerçš„æ¨¡å‹ï¼Œè”åˆè¿›è¡Œè¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«ã€‚
4. ä½¿ç”¨Whisperçš„è¯­éŸ³åµŒå…¥å’ŒECAPA-TDNNçš„è¯´è¯äººåµŒå…¥ã€‚
5. è”åˆæ¨¡å‹åœ¨å¹²å‡€æ¡ä»¶ä¸‹ä¸Whisperè¡¨ç°ç›¸å½“ã€‚
6. è”åˆæ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒä¸­ï¼ˆå¦‚8ä¸ªè¯´è¯äººçš„å˜ˆæ‚èƒŒæ™¯å™ªå£°ï¼‰ä¼˜äºWhisperã€‚
7. è”åˆæ¨¡å‹åœ¨å¤„ç†é«˜åº¦å¢å¼ºçš„è¯­éŸ³ï¼ˆå¦‚æ­£å¼¦æ³¢å’Œå™ªå£°ç¼–ç è¯­éŸ³ï¼‰æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

1. Title: åŸºäºè”åˆè®­ç»ƒçš„è¯´è¯äººèº«ä»½è¯†åˆ«ä¸è¯­éŸ³è¯†åˆ«æ¨¡å‹æ”¹è¿›ç ”ç©¶

2. Authors: Sagarika Alavilli, Annesya Banerjee, Gasser Elbanna, Annika Magaro

3. Affiliation: Harvard University Speech and Hearing Bioscience and Technology

4. Keywords: voice identification, automatic speech recognition, joint training

5. Urls: xxx (è®ºæ–‡é“¾æ¥æœªæä¾›)

6. Summary:

    - (1)ç ”ç©¶èƒŒæ™¯ï¼šæœ¬æ–‡ä¸»è¦ç ”ç©¶åœ¨æ¶åŠ£ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•æé«˜è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§ã€‚å½“å‰æœ€å…ˆè¿›çš„è¯­éŸ³è¯†åˆ«æ¨¡å‹åœ¨èƒŒæ™¯å™ªå£°å’Œè¯­éŸ³å¢å¼ºç­‰æ¡ä»¶ä¸‹æ€§èƒ½ä¸‹é™ã€‚
    
    - (2)è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¼ ç»Ÿçš„è¯­éŸ³è¯†åˆ«æ¨¡å‹ä¸»è¦å…³æ³¨è¯­è¨€å†…å®¹ï¼Œå¿½ç•¥è¯´è¯äººç‰¹å®šçš„å£°å­¦çº¿ç´¢ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶è¡¨æ˜è¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§å½±å“è¯­éŸ³æ„ŸçŸ¥ï¼Œä½†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå¾ˆå°‘åˆ©ç”¨è¿™äº›ç‰¹æ€§ã€‚å› æ­¤ï¼Œç°æœ‰çš„æ¨¡å‹åœ¨é¢å¯¹å™ªå£°æˆ–å…¶ä»–å¹²æ‰°æ—¶ï¼Œæ€§èƒ½å¯èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚
    
    - (3)ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè”åˆè®­ç»ƒçš„è¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç»“åˆäº†Whisperçš„è¯­éŸ³åµŒå…¥å’ŒECAPA-TDNNçš„è¯´è¯äººåµŒå…¥ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼Œå…±åŒå¤„ç†è¯­éŸ³å’Œè¯´è¯äººè¯†åˆ«ä»»åŠ¡ã€‚æ¨¡å‹åˆ©ç”¨å˜å‹å™¨ç»“æ„å¤„ç†åµŒå…¥ä¿¡æ¯ï¼Œç”ŸæˆåŒæ—¶åŒ…å«è¯­éŸ³å’Œè¯´è¯äººç‰¹å¾çš„è¡¨ç¤ºã€‚
    
    - (4)ä»»åŠ¡ä¸æ€§èƒ½ï¼šè¯¥æ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒå’Œè¯­éŸ³å¢å¼ºä»»åŠ¡ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå¦‚8äººåŒæ—¶è¯´è¯çš„å˜ˆæ‚èƒŒæ™¯å™ªå£°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆæ¨¡å‹åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¼˜äºWhisperæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†é«˜åº¦å¢å¼ºçš„è¯­éŸ³ï¼Œå¦‚æ­£å¼¦æ³¢å’Œå™ªå£°ç¼–ç çš„è¯­éŸ³æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚æ€»çš„æ¥è¯´ï¼Œè¿™äº›ç»“æœæ”¯æŒäº†é€šè¿‡æ•´åˆè¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§æ¥æé«˜è¯­éŸ³è¯†åˆ«æ¨¡å‹é²æ£’æ€§çš„è§‚ç‚¹ã€‚

ä»¥ä¸Šå†…å®¹ä»…ä¾›å‚è€ƒï¼Œå…·ä½“ä¿¡æ¯å»ºè®®æŸ¥é˜…è®ºæ–‡åŸæ–‡è·å–ã€‚
7. æ–¹æ³•è®ºï¼š

    - (1) ç ”ç©¶èƒŒæ™¯ï¼šè¯¥ç ”ç©¶é’ˆå¯¹æ¶åŠ£ç¯å¢ƒä¸‹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§é—®é¢˜å±•å¼€ã€‚ç°æœ‰çš„æœ€å…ˆè¿›çš„è¯­éŸ³è¯†åˆ«æ¨¡å‹åœ¨èƒŒæ™¯å™ªå£°å’Œè¯­éŸ³å¢å¼ºç­‰æ¡ä»¶ä¸‹æ€§èƒ½ä¸‹é™ã€‚

    - (2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¼ ç»Ÿçš„è¯­éŸ³è¯†åˆ«æ¨¡å‹ä¸»è¦å…³æ³¨è¯­è¨€å†…å®¹ï¼Œå¿½ç•¥äº†è¯´è¯äººçš„ç‰¹å®šå£°å­¦çº¿ç´¢ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶è¡¨æ˜è¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§å½±å“è¯­éŸ³æ„ŸçŸ¥ï¼Œä½†è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå¾ˆå°‘åˆ©ç”¨è¿™äº›ç‰¹æ€§ï¼Œå¯¼è‡´åœ¨é¢å¯¹å™ªå£°æˆ–å…¶ä»–å¹²æ‰°æ—¶æ€§èƒ½ä¸‹é™ã€‚

    - (3) æ–¹æ³•è®ºåˆ›æ–°ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè”åˆè®­ç»ƒçš„è¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«æ¨¡å‹ã€‚è¯¥æ¨¡å‹ç»“åˆäº†Whisperçš„è¯­éŸ³åµŒå…¥å’ŒECAPA-TDNNçš„è¯´è¯äººåµŒå…¥ï¼Œé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼Œå…±åŒå¤„ç†è¯­éŸ³å’Œè¯´è¯äººè¯†åˆ«ä»»åŠ¡ã€‚æ¨¡å‹åˆ©ç”¨å˜å‹å™¨ç»“æ„å¤„ç†åµŒå…¥ä¿¡æ¯ï¼Œç”ŸæˆåŒæ—¶åŒ…å«è¯­éŸ³å’Œè¯´è¯äººç‰¹å¾çš„è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œç ”ç©¶ä½¿ç”¨äº†Whisperæ¨¡å‹ä½œä¸ºè¯­éŸ³è¯†åˆ«çš„åŸºæœ¬æ¶æ„ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šç»“åˆäº†ECAPA-TDNNæ¨¡å‹çš„ä¼˜ç‚¹ï¼Œç”¨äºæå–è¯´è¯äººçš„ç‰¹å¾ã€‚è”åˆæ¨¡å‹é€šè¿‡å¤šå±‚å˜å‹å™¨ç»“æ„å¯¹ä¸¤ç§åµŒå…¥è¿›è¡Œè”åˆå¤„ç†ï¼Œä»¥æé«˜æ¨¡å‹åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚

    - (4) å®éªŒéªŒè¯ï¼šè¯¥æ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒå’Œè¯­éŸ³å¢å¼ºä»»åŠ¡ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆæ¨¡å‹åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¼˜äºWhisperæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¤„ç†é«˜åº¦å¢å¼ºçš„è¯­éŸ³ï¼Œå¦‚æ­£å¼¦æ³¢å’Œå™ªå£°ç¼–ç çš„è¯­éŸ³æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚è¿™äº›ç»“æœæ”¯æŒäº†é€šè¿‡æ•´åˆè¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§æ¥æé«˜è¯­éŸ³è¯†åˆ«æ¨¡å‹é²æ£’æ€§çš„è§‚ç‚¹ã€‚
8. Conclusion:

* (1)ç ”ç©¶æ„ä¹‰ï¼šè¯¥ç ”ç©¶æé«˜äº†åœ¨æ¶åŠ£ç¯å¢ƒä¸‹è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹çš„é²æ£’æ€§ï¼Œå¯¹äºæé«˜è¯­éŸ³è¯†åˆ«ç³»ç»Ÿçš„å®é™…åº”ç”¨æ•ˆæœå…·æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡æ•´åˆè¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨å™ªå£°å’Œå…¶ä»–å¹²æ‰°æ¡ä»¶ä¸‹æ›´åŠ å‡†ç¡®åœ°è¯†åˆ«è¯­éŸ³å†…å®¹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¼€å‘æ›´å¥å£®çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿæä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

* (2)åˆ›æ–°ç‚¹ã€æ€§èƒ½å’Œå·¥ä½œé‡è¯„ä»·ï¼š
  + åˆ›æ–°ç‚¹ï¼šè¯¥ç ”ç©¶ç»“åˆè¯´è¯äººè¯†åˆ«å’Œè¯­éŸ³è¯†åˆ«æ¨¡å‹è¿›è¡Œè”åˆè®­ç»ƒï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„å°è¯•ã€‚é€šè¿‡ç»“åˆWhisperçš„è¯­éŸ³åµŒå…¥å’ŒECAPA-TDNNçš„è¯´è¯äººåµŒå…¥ï¼Œæ¨¡å‹èƒ½å¤ŸåŒæ—¶å¤„ç†è¯­éŸ³å’Œè¯´è¯äººè¯†åˆ«ä»»åŠ¡ï¼Œç”ŸæˆåŒ…å«è¯­éŸ³å’Œè¯´è¯äººç‰¹å¾çš„è¡¨ç¤ºã€‚è¿™ç§ç»“åˆæ–¹å¼æœ‰åŠ©äºæé«˜æ¨¡å‹åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„é²æ£’æ€§ã€‚
  + æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆæ¨¡å‹åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„æ€§èƒ½ä¼˜äºWhisperæ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†é«˜åº¦å¢å¼ºçš„è¯­éŸ³æ—¶è¡¨ç°ä¼˜å¼‚ã€‚è¿™äº›ç»“æœæ”¯æŒäº†é€šè¿‡æ•´åˆè¯­éŸ³å’Œè¯´è¯äººç‰¹æ€§æ¥æé«˜è¯­éŸ³è¯†åˆ«æ¨¡å‹é²æ£’æ€§çš„è§‚ç‚¹ã€‚
  + å·¥ä½œé‡ï¼šç ”ç©¶å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦è¿›è¡Œæ¨¡å‹è®¾è®¡ã€å®éªŒè®¾è®¡ã€å®éªŒå®æ–½å’Œç»“æœåˆ†æç­‰å¤šä¸ªç¯èŠ‚çš„å·¥ä½œã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦è¿›è¡Œæ–‡çŒ®è°ƒç ”å’Œç†è®ºåˆ†æï¼Œä»¥æ”¯æ’‘ç ”ç©¶å·¥ä½œçš„è¿›è¡Œã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œè¯¥ç ”ç©¶å…·æœ‰ä¸€å®šçš„å®é™…æ„ä¹‰å’Œåˆ›æ–°æ€§ï¼Œä½†ä»éœ€è¦åœ¨å®è·µä¸­è¿›ä¸€æ­¥éªŒè¯å’Œå®Œå–„æ¨¡å‹çš„æ€§èƒ½ã€‚


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fb6606ff4cad4d279a82ddc9895cfc84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1f38e27dcc86a1162335b4f7330fa6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dee646e7476834d2d7d2fab444f54180.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58d53d35023f8a5cf4c8b871f5a36ef0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7437da15257e2e4e956b63c6789636aa.jpg" align="middle">
</details>




