
---
title: 元宇宙/虚拟人
date: 2024-06-20 20:30:03
author: Kedreamix
cover: https://pica.zhimg.com/v2-8ca348c29f475636e9f78ac7ef409fa9.jpg
categories: Paper
tags:
    - 元宇宙/虚拟人
description: 元宇宙/虚拟人 方向最新论文已更新，请持续关注 Update in 2024-06-20  AvaTaR Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval  
keywords: 元宇宙/虚拟人
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>⚠️ 以下所有内容总结都来自于 Google的大语言模型[Gemini-Pro](https://ai.google.dev/)的能力，如有错误，仅供参考，谨慎使用
>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！
>💗 如果您觉得我们的项目对您有帮助 [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ，还请您给我们一些鼓励！⭐️ [HuggingFace免费体验](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-06-20 更新


## AvaTaR: Optimizing LLM Agents for Tool-Assisted Knowledge Retrieval

**Authors:Shirley Wu, Shiyu Zhao, Qian Huang, Kexin Huang, Michihiro Yasunaga, Kaidi Cao, Vassilis N. Ioannidis, Karthik Subbian, Jure Leskovec, James Zou**

Large language model (LLM) agents have demonstrated impressive capability in utilizing external tools and knowledge to boost accuracy and reduce hallucinations. However, developing the prompting techniques that make LLM agents able to effectively use external tools and knowledge is a heuristic and laborious task. Here, we introduce AvaTaR, a novel and automatic framework that optimizes an LLM agent to effectively use the provided tools and improve its performance on a given task/domain. During optimization, we design a comparator module to iteratively provide insightful and holistic prompts to the LLM agent via reasoning between positive and negative examples sampled from training data. We demonstrate AvaTaR on four complex multimodal retrieval datasets featuring textual, visual, and relational information. We find AvaTaR consistently outperforms state-of-the-art approaches across all four challenging tasks and exhibits strong generalization ability when applied to novel cases, achieving an average relative improvement of 14% on the Hit@1 metric. Code and dataset are available at https://github.com/zou-group/avatar. 

[PDF](http://arxiv.org/abs/2406.11200v2) 19 pages, 8 figures, 6 tables

**Summary**
大型语言模型（LLM）代理展示了在利用外部工具和知识提升准确性并减少幻觉方面的卓越能力，然而开发使LLM代理有效使用外部工具和知识的提示技术是一项启发式且繁重的任务。我们介绍了AvaTaR，这是一个新颖且自动化的框架，优化LLM代理以有效使用提供的工具，并在给定任务/领域上提升其性能。

**Key Takeaways**
- 大型语言模型（LLM）代理能有效利用外部工具和知识来提高准确性和减少幻觉。
- 发展LLM代理有效使用外部工具和知识的提示技术是一项启发式和繁重的任务。
- AvaTaR是一个自动化框架，旨在优化LLM代理的性能，使其有效利用提供的工具。
- 在优化过程中，AvaTaR设计了一个比较模块，通过正负样本的推理提供全面而有洞察力的提示。
- AvaTaR在四个复杂的多模式检索数据集上进行了演示，这些数据集涉及文本、视觉和关系信息。
- 在四个挑战性任务上，AvaTaR表现出优于现有方法的一致性，并在Hit@1指标上平均相对提升了14%。
- AvaTaR展示了强大的泛化能力，适用于新颖案例，并提供了代码和数据集的开放资源。

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**





好的，我会按照您的要求来总结这篇论文。

1. **标题**：基于LLM代理的工具辅助知识检索优化研究（AVATAR）
中文翻译：LLM Agent for Tool-Assisted Knowledge Retrieval Optimization via AVATAR

2. **作者**：Shirley Wu、Shiyu Zhao、Qian Huang等。具体作者名单请见论文原文。

3. **作者归属**：部分作者隶属于斯坦福大学计算机科学系，部分作者隶属于亚马逊公司。
中文翻译：部分作者为斯坦福大学计算机科学系成员，部分作者为亚马逊公司员工。

4. **关键词**：大型语言模型（LLM）、工具辅助、知识检索、优化框架、自动提示、多模态检索。

5. **链接**：论文链接请参见原文抽象部分的Url链接。GitHub代码库链接：[Github代码库链接](https://github.com/zou-group/avatar)（如有）。
如无GitHub代码库链接，则填写“Github:None”。

6. **摘要**：

    *(1)研究背景：*大型语言模型（LLM）在利用外部工具和知识提高准确性和减少幻觉方面表现出令人印象深刻的能力。然而，开发能够使LLM代理有效利用外部工具和知识的提示技术是一项启发式且费力的任务。本文介绍了一个名为AVATAR的优化框架，旨在自动优化LLM代理在给定任务/域中使用提供的工具的能力。

    *(2)过去的方法及问题：*尽管存在许多直接部署LLM代理的方法，但这些方法主要依赖于复杂的人工设计提示，需要大量的手动试错。这些方法可能导致实施脆弱且准确性不高。此外，现有研究在增强复杂策略以优化LLM方面存在不足。

    *(3)研究方法：*AVATAR框架通过设计一个比较器模块来优化LLM代理。该模块通过迭代的方式为LLM代理提供洞察力和全面的提示，这些提示是通过在训练数据中采样正负例子并进行推理而生成的。AVATAR在四个包含文本、视觉和关系信息的复杂多模态检索数据集上进行了演示，并表现出优越的性能。

    *(4)任务与性能：*AVATAR在四个具有挑战性的任务上始终优于现有方法，并在应用于新案例时表现出强大的泛化能力。平均而言，它在Hit@1指标上实现了14%的相对改进。性能数据支持AVATAR的目标，即优化LLM代理以更有效地使用工具并改善其性能。

以上内容严格按照您的要求进行格式化和回答，希望对您有所帮助！





8. 结论：

（1）该工作的意义在于介绍了一个名为AVATAR的优化框架，该框架能够自动化优化LLM代理，使其在复杂的多步任务中更有效地利用工具。这项工作为LLM代理在知识检索等方面的应用提供了新的思路和方法，有助于提高LLM代理的性能和效率。

（2）创新点：该文章提出了AVATAR框架，通过比较器模块自动优化LLM代理的工具使用能力，实现了对LLM代理的自动化优化。该框架在多模态检索等复杂任务上表现出优越的性能。

性能：AVATAR框架在四个具有挑战性的任务上始终优于现有方法，并在Hit@1指标上实现了相对改进。实验结果表明，AVATAR框架能够有效地提高LLM代理的性能。

工作量：文章涉及多个复杂任务和实验，包括设计AVATAR框架、实现比较器模块、进行多模态检索实验等。工作量较大，但实验结果证明了该框架的有效性和优越性。







<details>
  <summary>点此查看论文截图</summary>
<img src="https://pica.zhimg.com/v2-8ca348c29f475636e9f78ac7ef409fa9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d91f1c9d7220f0235a90f84883583b2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f462a5168982f840c7819e199c2480b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-33e4b0882dfe943117ce7f400d5aef85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-97e15a105da880710e80afab09cb526b.jpg" align="middle">
</details>




