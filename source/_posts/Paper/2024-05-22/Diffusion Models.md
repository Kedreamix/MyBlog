
---
title: Diffusion Models
date: 2024-05-22 12:21:50
author: Kedreamix
cover: https://picx.zhimg.com/v2-d222555f8f090be73c96a07a45af66c0.jpg
categories: Paper
tags:
    - Diffusion Models
description: Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-22  Diffusion-RSCC Diffusion Probabilistic Model for Change Captioning in   Remote Sensing Images  
keywords: Diffusion Models
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-05-22 æ›´æ–°


## Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in   Remote Sensing Images

**Authors:Xiaofei Yu, Yitong Li, Jie Ma**

Remote sensing image change captioning (RSICC) aims at generating human-like language to describe the semantic changes between bi-temporal remote sensing image pairs. It provides valuable insights into environmental dynamics and land management. Unlike conventional change captioning task, RSICC involves not only retrieving relevant information across different modalities and generating fluent captions, but also mitigating the impact of pixel-level differences on terrain change localization. The pixel problem due to long time span decreases the accuracy of generated caption. Inspired by the remarkable generative power of diffusion model, we propose a probabilistic diffusion model for RSICC to solve the aforementioned problems. In training process, we construct a noise predictor conditioned on cross modal features to learn the distribution from the real caption distribution to the standard Gaussian distribution under the Markov chain. Meanwhile, a cross-mode fusion and a stacking self-attention module are designed for noise predictor in the reverse process. In testing phase, the well-trained noise predictor helps to estimate the mean value of the distribution and generate change captions step by step. Extensive experiments on the LEVIR-CC dataset demonstrate the effectiveness of our Diffusion-RSCC and its individual components. The quantitative results showcase superior performance over existing methods across both traditional and newly augmented metrics. The code and materials will be available online at https://github.com/Fay-Y/Diffusion-RSCC. 

[PDF](http://arxiv.org/abs/2405.12875v1) 

**Summary**
æ‰©æ•£æ¨¡å‹åº”ç”¨äºé¥æ„Ÿå›¾åƒå˜åŒ–æè¿°ï¼Œæœ‰æ•ˆå‡è½»åƒç´ å·®å¼‚å¯¹åœ°å½¢å˜åŒ–å®šä½çš„å½±å“ï¼Œæé«˜æè¿°ç²¾åº¦ã€‚

**Key Takeaways**
- é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°æ—¨åœ¨ç”Ÿæˆäººç±»å¯ç†è§£çš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œä»¥è§£é‡ŠåŒæ—¶ç›¸é¥æ„Ÿå›¾åƒå¯¹ä¹‹é—´çš„è¯­ä¹‰å˜åŒ–ã€‚
- é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°ä¸ä»…æ¶‰åŠè·¨æ¨¡æ€ç›¸å…³ä¿¡æ¯çš„æå–å’Œæµç•…æè¿°çš„ç”Ÿæˆï¼Œè¿˜éœ€å‡è½»åƒç´ çº§å·®å¼‚å¯¹åœ°å½¢å˜åŒ–å®šä½çš„å½±å“ã€‚
- æ—¶é—´è·¨åº¦é•¿çš„åƒç´ é—®é¢˜ä¼šé™ä½ç”Ÿæˆæè¿°çš„å‡†ç¡®åº¦ã€‚
- æ‰©æ•£æ¨¡å‹å…·æœ‰æ°å‡ºçš„ç”Ÿæˆèƒ½åŠ›ï¼Œå¯ç”¨äºé¥æ„Ÿå›¾åƒå˜åŒ–æè¿°ï¼Œè§£å†³ä¸Šè¿°é—®é¢˜ã€‚
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ„å»ºå™ªå£°é¢„æµ‹å™¨ä»¥å­¦ä¹ ä»çœŸå®æè¿°åˆ†å¸ƒåˆ°æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„åˆ†å¸ƒã€‚
- åœ¨æ¨ç†é˜¶æ®µï¼Œè®­ç»ƒå¥½çš„å™ªå£°é¢„æµ‹å™¨æœ‰åŠ©äºä¼°è®¡åˆ†å¸ƒçš„å‡å€¼å¹¶é€æ­¥ç”Ÿæˆå˜åŒ–æè¿°ã€‚
- åœ¨ LEVIR-CC æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜äº†æ‰©æ•£æ¨¡å‹åœ¨é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°ä¸­çš„æœ‰æ•ˆæ€§ã€‚
- è¯¥æ–¹æ³•åœ¨ä¼ ç»Ÿå’Œæ–°å¢åŠ çš„æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>é¢˜ç›®ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°</p>
</li>
<li>
<p>ä½œè€…ï¼šXiaofei Yu, Yitong Li, Jie Ma</p>
</li>
<li>
<p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤–å›½è¯­å¤§å­¦ä¿¡æ¯ç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢</p>
</li>
<li>
<p>å…³é”®è¯ï¼šé¥æ„Ÿï¼Œæ‰©æ•£æ¨¡å‹ï¼Œå˜åŒ–æè¿°ï¼Œæ³¨æ„åŠ›æœºåˆ¶</p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.07736, Githubï¼šNone</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šé¥æ„Ÿå›¾åƒå˜åŒ–æè¿°ï¼ˆRSICCï¼‰æ—¨åœ¨ç”Ÿæˆç±»ä¼¼äººç±»è¯­è¨€çš„å¥å­æ¥æè¿°åŒæ—¶ç›¸é¥æ„Ÿå›¾åƒå¯¹ä¹‹é—´çš„è¯­ä¹‰å˜åŒ–ã€‚ä¸ä¼ ç»Ÿçš„å˜åŒ–æè¿°ä»»åŠ¡ä¸åŒï¼ŒRSICC ä¸ä»…æ¶‰åŠè·¨ä¸åŒæ¨¡æ€æ£€ç´¢ç›¸å…³ä¿¡æ¯å¹¶ç”Ÿæˆæµç•…çš„æè¿°ï¼Œè¿˜è¦å‡è½»åƒç´ çº§å·®å¼‚å¯¹åœ°å½¢å˜åŒ–å®šä½çš„å½±å“ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰çš„ RSICC æ–¹æ³•é€šå¸¸é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œä½†å®ƒä»¬éš¾ä»¥åŒºåˆ†è¯­ä¹‰å˜åŒ–å’Œä¼ªå˜åŒ–ï¼Œä»è€Œå½±å“æè¿°çš„å‡†ç¡®æ€§ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ RSICC æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ„é€ äº†ä¸€ä¸ªæ¡ä»¶ä¸ºäº¤å‰æ¨¡æ€ç‰¹å¾çš„å™ªå£°é¢„æµ‹å™¨ï¼Œå­¦ä¹ ä»çœŸå®æè¿°åˆ†å¸ƒåˆ°é©¬å°”å¯å¤«é“¾ä¸‹çš„æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„åˆ†å¸ƒã€‚åŒæ—¶ï¼Œåœ¨é€†è¿‡ç¨‹ä¸­è®¾è®¡äº†ä¸€ä¸ªè·¨æ¨¡æ€èåˆå’Œä¸€ä¸ªå †å è‡ªæ³¨æ„åŠ›æ¨¡å—ç”¨äºå™ªå£°é¢„æµ‹å™¨ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šå®éªŒç»“æœï¼šåœ¨ LEVIR-CC æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨ä¼ ç»Ÿå’Œæ–°å¢åŠ çš„æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æ–¹æ³•åŒºåˆ†è¯­ä¹‰å˜åŒ–å’Œä¼ªå˜åŒ–çš„èƒ½åŠ›ï¼Œä»è€Œæé«˜äº†æè¿°çš„å‡†ç¡®æ€§ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å·¥ä½œçš„ä¸»è¦æ„ä¹‰åœ¨äºï¼šæå‡ºäº†ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ„å»ºæ¡ä»¶ä¸ºäº¤å‰æ¨¡æ€ç‰¹å¾çš„å™ªå£°é¢„æµ‹å™¨ï¼Œå­¦ä¹ ä»çœŸå®æè¿°åˆ†å¸ƒåˆ°é©¬å°”å¯å¤«é“¾ä¸‹çš„æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„åˆ†å¸ƒï¼Œå¹¶è®¾è®¡äº†è·¨æ¨¡æ€èåˆå’Œå †å è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œæœ‰æ•ˆåŒºåˆ†è¯­ä¹‰å˜åŒ–å’Œä¼ªå˜åŒ–ï¼Œæé«˜äº†æè¿°çš„å‡†ç¡®æ€§ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³æ€»ç»“å¦‚ä¸‹ï¼š</p>
<p>åˆ›æ–°ç‚¹ï¼š
- æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é¥æ„Ÿå›¾åƒå˜åŒ–æè¿°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ„å»ºæ¡ä»¶ä¸ºäº¤å‰æ¨¡æ€ç‰¹å¾çš„å™ªå£°é¢„æµ‹å™¨ï¼Œå­¦ä¹ ä»çœŸå®æè¿°åˆ†å¸ƒåˆ°é©¬å°”å¯å¤«é“¾ä¸‹çš„æ ‡å‡†é«˜æ–¯åˆ†å¸ƒçš„åˆ†å¸ƒï¼Œæœ‰æ•ˆåŒºåˆ†è¯­ä¹‰å˜åŒ–å’Œä¼ªå˜åŒ–ï¼Œæé«˜äº†æè¿°çš„å‡†ç¡®æ€§ã€‚
- è®¾è®¡äº†è·¨æ¨¡æ€èåˆå’Œå †å è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›å’Œå˜åŒ–å®šä½èƒ½åŠ›ã€‚</p>
<p>æ€§èƒ½ï¼š
- åœ¨ LEVIR-CC æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨ä¼ ç»Ÿå’Œæ–°å¢åŠ çš„æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- æœ¬æ–‡æ–¹æ³•éœ€è¦è¾ƒå¤§çš„è®­ç»ƒæ•°æ®é‡å’Œè¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-21dbd52d9fa2dfab9ed21bd713132601.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea4cb0070ada153d3948236792884ccd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f43b384f7a1cf699952513394080a478.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-559ce1394523d55dae45d360bd3b2838.jpg" align="middle">
</details>




## Diffusion for World Modeling: Visual Details Matter in Atari

**Authors:Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, FranÃ§ois Fleuret**

World models constitute a promising approach for training reinforcement learning agents in a safe and sample-efficient manner. Recent world models predominantly operate on sequences of discrete latent variables to model environment dynamics. However, this compression into a compact discrete representation may ignore visual details that are important for reinforcement learning. Concurrently, diffusion models have become a dominant approach for image generation, challenging well-established methods modeling discrete latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. We analyze the key design choices that are required to make diffusion suitable for world modeling, and demonstrate how improved visual details can lead to improved agent performance. DIAMOND achieves a mean human normalized score of 1.46 on the competitive Atari 100k benchmark; a new best for agents trained entirely within a world model. To foster future research on diffusion for world modeling, we release our code, agents and playable world models at https://github.com/eloialonso/diamond. 

[PDF](http://arxiv.org/abs/2405.12399v1) 25 pages, 11 figures, 10 tables

**Summary**
æ‰©æ•£æ¨¡å‹çš„è§†è§‰ç»†èŠ‚æå‡å¯æ”¹å–„ä¸–ç•Œæ¨¡å‹ä¸­å¼ºåŒ–å­¦ä¹ ä»£ç†çš„æ€§èƒ½ã€‚

**Key Takeaways**
- ä¸–ç•Œæ¨¡å‹ä¸ºå¼ºåŒ–å­¦ä¹ ä»£ç†æä¾›äº†ä¸€ç§å®‰å…¨ã€é«˜æ•ˆçš„è®­ç»ƒæ–¹æ³•ã€‚
- æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸã€‚
- DIAMONDï¼ˆDIffusion As a Model Of eNvironment Dreamsï¼‰æ˜¯ç¬¬ä¸€ä¸ªåœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸­è®­ç»ƒçš„å¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚
- DIAMONDåœ¨Atari 100kåŸºå‡†ä¸Šè¾¾åˆ°1.46çš„äººç±»å½’ä¸€åŒ–å¹³å‡å¾—åˆ†ã€‚
- æ‰©æ•£æ¨¡å‹å¯ä»¥æ•è·å¯¹å¼ºåŒ–å­¦ä¹ é‡è¦çš„è§†è§‰ç»†èŠ‚ã€‚
- DIAMONDä»£ç ã€ä»£ç†å’Œå¯ç©ä¸–ç•Œæ¨¡å‹å·²å¼€æºã€‚
- æ‰©æ•£æ¨¡å‹åœ¨ä¸–ç•Œå»ºæ¨¡é¢†åŸŸå…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: ä¸–ç•Œå»ºæ¨¡çš„æ‰©æ•£ï¼šAtari ä¸­çš„è§†è§‰ç»†èŠ‚è‡³å…³é‡è¦</p>
</li>
<li>
<p>Authors: Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, FranÃ§ois Fleuret</p>
</li>
<li>
<p>Affiliation: æ—¥å†…ç“¦å¤§å­¦</p>
</li>
<li>
<p>Keywords: Diffusion, World Modeling, Reinforcement Learning, Atari</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2405.12399, Github: https://github.com/eloialonso/diamond</p>
</li>
<li>
<p>Summary:</p>
<pre><code>            (1): ä¸–ç•Œæ¨¡å‹æ˜¯ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ï¼Œå¯ç”¨äºä»¥å®‰å…¨ä¸”æ ·æœ¬é«˜æ•ˆçš„æ–¹å¼è®­ç»ƒå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚æœ€è¿‘çš„ä¸–ç•Œæ¨¡å‹ä¸»è¦å¯¹ç¦»æ•£æ½œåœ¨å˜é‡åºåˆ—è¿›è¡Œæ“ä½œä»¥å»ºæ¨¡ç¯å¢ƒåŠ¨æ€ã€‚ç„¶è€Œï¼Œè¿™ç§å‹ç¼©æˆç´§å‡‘çš„ç¦»æ•£è¡¨ç¤ºå¯èƒ½ä¼šå¿½ç•¥å¯¹å¼ºåŒ–å­¦ä¹ å¾ˆé‡è¦çš„è§†è§‰ç»†èŠ‚ã€‚ä¸æ­¤åŒæ—¶ï¼Œæ‰©æ•£æ¨¡å‹å·²æˆä¸ºå›¾åƒç”Ÿæˆçš„ä¸»å¯¼æ–¹æ³•ï¼ŒæŒ‘æˆ˜äº†å¯¹ç¦»æ•£æ½œåœ¨å˜é‡å»ºæ¨¡çš„æˆç†Ÿæ–¹æ³•ã€‚å—è¿™ç§èŒƒå¼è½¬å˜çš„å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº† DIAMONDï¼ˆDIffusion As a Model Of eNvironment Dreamsï¼‰ï¼Œä¸€ç§åœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸­è®­ç»ƒçš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ã€‚æˆ‘ä»¬åˆ†æäº†ä½¿æ‰©æ•£é€‚ç”¨äºä¸–ç•Œå»ºæ¨¡æ‰€éœ€çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œå¹¶å±•ç¤ºäº†æ”¹è¿›çš„è§†è§‰ç»†èŠ‚å¦‚ä½•æé«˜æ™ºèƒ½ä½“æ€§èƒ½ã€‚DIAMOND åœ¨å…·æœ‰ç«äº‰åŠ›çš„ Atari 100k åŸºå‡†æµ‹è¯•ä¸­è·å¾—äº† 1.46 çš„å¹³å‡äººç±»å½’ä¸€åŒ–åˆ†æ•°ï¼›è¿™æ˜¯åœ¨ä¸–ç•Œæ¨¡å‹ä¸­å®Œå…¨è®­ç»ƒçš„æ™ºèƒ½ä½“çš„æœ€æ–°æˆç»©ã€‚ä¸ºäº†ä¿ƒè¿›æœªæ¥å¯¹ä¸–ç•Œå»ºæ¨¡æ‰©æ•£çš„ç ”ç©¶ï¼Œæˆ‘ä»¬åœ¨ https://github.com/eloialonso/diamond ä¸Šå‘å¸ƒäº†æˆ‘ä»¬çš„ä»£ç ã€æ™ºèƒ½ä½“å’Œå¯ç©ä¸–ç•Œæ¨¡å‹ã€‚

            (2): æœ€è¿‘çš„ä¸–ç•Œå»ºæ¨¡æ–¹æ³•é€šå¸¸å°†ç¯å¢ƒåŠ¨æ€å»ºæ¨¡ä¸ºç¦»æ•£æ½œåœ¨å˜é‡åºåˆ—ã€‚æ½œåœ¨ç©ºé—´çš„ç¦»æ•£åŒ–æœ‰åŠ©äºé¿å…åœ¨å¤šæ­¥æ—¶é—´èŒƒå›´å†…ç´¯ç§¯è¯¯å·®ã€‚ç„¶è€Œï¼Œè¿™ç§ç¼–ç å¯èƒ½ä¼šä¸¢å¤±ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´æ³›åŒ–æ€§å’Œé‡å»ºè´¨é‡ä¸‹é™ã€‚è¿™å¯¹äºä¿¡æ¯è¦æ±‚ä¸å¤ªæ˜ç¡®çš„æ›´çœŸå®åœºæ™¯å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œä¾‹å¦‚è®­ç»ƒè‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼ˆAutonomous Vehiclesï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè§†è§‰è¾“å…¥ä¸­çš„å°ç»†èŠ‚ï¼Œä¾‹å¦‚è¿œå¤„çš„äº¤é€šç¯æˆ–è¡Œäººï¼Œå¯èƒ½ä¼šæ”¹å˜æ™ºèƒ½ä½“çš„ç­–ç•¥ã€‚å¢åŠ ç¦»æ•£æ½œåœ¨å˜é‡çš„æ•°é‡å¯ä»¥å‡è½»è¿™ç§æœ‰æŸå‹ç¼©ï¼Œä½†ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚

            (3): æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯ï¼šåˆ†æä½¿æ‰©æ•£é€‚åˆä¸–ç•Œå»ºæ¨¡æ‰€éœ€çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œå¹¶å±•ç¤ºäº†æ”¹è¿›çš„è§†è§‰ç»†èŠ‚å¦‚ä½•æé«˜æ™ºèƒ½ä½“æ€§èƒ½ã€‚

            (4): åœ¨ Atari 100k åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šï¼ŒDIAMOND å–å¾—äº† 1.46 çš„å¹³å‡äººç±»å½’ä¸€åŒ–åˆ†æ•°ã€‚è¯¥æ€§èƒ½æ”¯æŒäº†ä»–ä»¬åœ¨ä¸–ç•Œæ¨¡å‹ä¸­å®Œå…¨è®­ç»ƒæ™ºèƒ½ä½“çš„ç›®æ ‡ã€‚
</code></pre>
</li>
<li>
<p>Methods:</p>
<pre><code>            (1):æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º DIAMOND çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“åœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒã€‚

            (2):DIAMOND ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥å¯¹ç¯å¢ƒåŠ¨æ€è¿›è¡Œå»ºæ¨¡ï¼Œè€Œä¸æ˜¯ç¦»æ•£æ½œåœ¨å˜é‡åºåˆ—ã€‚

            (3):ä½œè€…åˆ†æäº†ä½¿æ‰©æ•£é€‚ç”¨äºä¸–ç•Œå»ºæ¨¡æ‰€éœ€çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œå¹¶å±•ç¤ºäº†æ”¹è¿›çš„è§†è§‰ç»†èŠ‚å¦‚ä½•æé«˜æ™ºèƒ½ä½“æ€§èƒ½ã€‚

            (4):DIAMOND åœ¨ Atari 100k åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šå–å¾—äº† 1.46 çš„å¹³å‡äººç±»å½’ä¸€åŒ–åˆ†æ•°ï¼Œè¿™è¡¨æ˜äº†æ‰©æ•£ä¸–ç•Œæ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚
</code></pre>
</li>
<li>
<p>ç»“è®ºï¼š</p>
<pre><code>            (1):æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º DIAMOND çš„å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“åœ¨æ‰©æ•£ä¸–ç•Œæ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒã€‚DIAMOND åœ¨ Atari 100k åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šå–å¾—äº† 1.46 çš„å¹³å‡äººç±»å½’ä¸€åŒ–åˆ†æ•°ï¼Œè¿™è¡¨æ˜äº†æ‰©æ•£ä¸–ç•Œæ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚

            (2):Innovation point: æœ¬æ–‡æå‡ºäº†ä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯¹ç¯å¢ƒåŠ¨æ€è¿›è¡Œå»ºæ¨¡çš„æ–¹æ³•ï¼Œè€Œä¸æ˜¯ç¦»æ•£æ½œåœ¨å˜é‡åºåˆ—ã€‚ Performance: DIAMOND åœ¨ Atari 100k åŸºå‡†æµ‹è¯•ä»»åŠ¡ä¸Šå–å¾—äº† 1.46 çš„å¹³å‡äººç±»å½’ä¸€åŒ–åˆ†æ•°ï¼Œè¿™è¡¨æ˜äº†æ‰©æ•£ä¸–ç•Œæ¨¡å‹åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚ Workload: DIAMOND çš„è®­ç»ƒæˆæœ¬é«˜äºä½¿ç”¨ç¦»æ•£æ½œåœ¨å˜é‡åºåˆ—çš„ä¸–ç•Œæ¨¡å‹çš„è®­ç»ƒæˆæœ¬ã€‚
</code></pre>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-72ac1259074913dc48248601ecb6050f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f4d7aa4fb02351e901a1debcb4d39d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3025a3d3200ab1611ab31f0968676023.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d222555f8f090be73c96a07a45af66c0.jpg" align="middle">
</details>




## Images that Sound: Composing Images and Sounds on a Single Canvas

**Authors:Ziyang Chen, Daniel Geng, Andrew Owens**

Spectrograms are 2D representations of sound that look very different from the images found in our visual world. And natural images, when played as spectrograms, make unnatural sounds. In this paper, we show that it is possible to synthesize spectrograms that simultaneously look like natural images and sound like natural audio. We call these spectrograms images that sound. Our approach is simple and zero-shot, and it leverages pre-trained text-to-image and text-to-spectrogram diffusion models that operate in a shared latent space. During the reverse process, we denoise noisy latents with both the audio and image diffusion models in parallel, resulting in a sample that is likely under both models. Through quantitative evaluations and perceptual studies, we find that our method successfully generates spectrograms that align with a desired audio prompt while also taking the visual appearance of a desired image prompt. Please see our project page for video results: https://ificl.github.io/images-that-sound/ 

[PDF](http://arxiv.org/abs/2405.12221v1) Project site: https://ificl.github.io/images-that-sound/

**Summary**
è‡ªç„¶å›¾åƒçš„å£°è°±å›¾æ—¢èƒ½å±•ç°é€¼çœŸçš„è§†è§‰æ•ˆæœï¼Œåˆèƒ½äº§ç”Ÿè‡ªç„¶çš„å£°éŸ³ã€‚

**Key Takeaways**
- å£°è°±å›¾æ˜¯å£°éŸ³çš„äºŒç»´è¡¨ç¤ºï¼Œå…¶å¤–è§‚ä¸æˆ‘ä»¬è§†è§‰ä¸–ç•Œä¸­çš„å›¾åƒæˆªç„¶ä¸åŒã€‚
- è‡ªç„¶å›¾åƒä½œä¸ºå£°è°±å›¾æ’­æ”¾æ—¶ï¼Œä¼šäº§ç”Ÿä¸è‡ªç„¶çš„å£°éŸ³ã€‚
- æœ¬ç ”ç©¶åˆæˆå‡ºåŒæ—¶å…·æœ‰è‡ªç„¶å›¾åƒå¤–è§‚å’Œè‡ªç„¶éŸ³é¢‘å£°éŸ³çš„å£°è°±å›¾ï¼Œç§°ä¸ºâ€œå¯è§†åŒ–å£°éŸ³â€ã€‚
- è¯¥æ–¹æ³•é‡‡ç”¨é›¶æ ·æœ¬å­¦ä¹ ï¼Œåˆ©ç”¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­çš„é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°å£°è°±å›¾æ‰©æ•£æ¨¡å‹ã€‚
- é€†å‘è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡éŸ³é¢‘å’Œå›¾åƒæ‰©æ•£æ¨¡å‹å¹¶è¡Œå¯¹å™ªå£°æ½œåœ¨å˜é‡è¿›è¡Œå»å™ªï¼Œç”Ÿæˆæ»¡è¶³ä¸¤ä¸ªæ¨¡å‹è¦æ±‚çš„æ ·æœ¬ã€‚
- å®šé‡è¯„ä¼°å’Œæ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸç”Ÿæˆäº†ä¸ç›®æ ‡éŸ³é¢‘æç¤ºä¸€è‡´ã€åŒæ—¶å…·æœ‰ç›®æ ‡å›¾åƒæç¤ºè§†è§‰å¤–è§‚çš„å£°è°±å›¾ã€‚
- æ›´è¯¦ç»†çš„ç ”ç©¶ç»“æœè¯·è§é¡¹ç›®ä¸»é¡µï¼šhttps://ificl.github.io/images-that-sound/

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>æ ‡é¢˜ï¼šå›¾åƒå³å£°éŸ³ï¼šåœ¨å•ä¸€ç”»å¸ƒä¸Šåˆæˆå›¾åƒå’Œå£°éŸ³</p>
</li>
<li>
<p>ä½œè€…ï¼šZiyang Chen, Daniel Geng, Andrew Owens</p>
</li>
<li>
<p>éš¶å±å•ä½ï¼šå¯†æ­‡æ ¹å¤§å­¦</p>
</li>
<li>
<p>å…³é”®è¯ï¼šå›¾åƒåˆ°å£°éŸ³ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œé›¶æ ·æœ¬å­¦ä¹ </p>
</li>
<li>
<p>è®ºæ–‡é“¾æ¥ï¼šhttps://ificl.github.io/images-that-sound/ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</p>
</li>
<li>
<p>æ‘˜è¦ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šå£°è°±å›¾æ˜¯å£°éŸ³çš„äºŒç»´è¡¨ç¤ºï¼Œä¸æˆ‘ä»¬è§†è§‰ä¸–ç•Œä¸­çš„å›¾åƒçœ‹èµ·æ¥éå¸¸ä¸åŒã€‚å½“è‡ªç„¶å›¾åƒä»¥å£°è°±å›¾çš„å½¢å¼æ’­æ”¾æ—¶ï¼Œä¼šäº§ç”Ÿä¸è‡ªç„¶çš„å£°éŸ³ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•æ— æ³•åŒæ—¶ç”Ÿæˆæ—¢åƒè‡ªç„¶å›¾åƒåˆåƒè‡ªç„¶éŸ³é¢‘çš„å£°è°±å›¾ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ä¸”é›¶æ ·æœ¬çš„æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°å£°è°±å›¾æ‰©æ•£æ¨¡å‹ï¼Œåœ¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œã€‚åœ¨åå‘è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨éŸ³é¢‘å’Œå›¾åƒæ‰©æ•£æ¨¡å‹å¹¶è¡Œå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªåŒæ—¶ç¬¦åˆè¿™ä¸¤ä¸ªæ¨¡å‹çš„æ ·æœ¬ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šé€šè¿‡å®šé‡è¯„ä¼°å’Œæ„ŸçŸ¥ç ”ç©¶ï¼Œæœ¬æ–‡çš„æ–¹æ³•æˆåŠŸç”Ÿæˆäº†ä¸æ‰€éœ€éŸ³é¢‘æç¤ºä¸€è‡´ï¼ŒåŒæ—¶å…·æœ‰æ‰€éœ€å›¾åƒæç¤ºè§†è§‰å¤–è§‚çš„å£°è°±å›¾ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°å£°è°±å›¾æ‰©æ•£æ¨¡å‹ï¼Œåœ¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šåœ¨åå‘è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨éŸ³é¢‘å’Œå›¾åƒæ‰©æ•£æ¨¡å‹å¹¶è¡Œå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šå¾—åˆ°ä¸€ä¸ªåŒæ—¶ç¬¦åˆè¿™ä¸¤ä¸ªæ¨¡å‹çš„æ ·æœ¬ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
<pre><code>            ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œè¡¨æ˜ï¼Œè‡ªç„¶å›¾åƒçš„åˆ†å¸ƒä¸è‡ªç„¶å£°è°±å›¾çš„åˆ†å¸ƒä¹‹é—´å­˜åœ¨éå¹³å‡¡çš„é‡å ã€‚æˆ‘ä»¬é€šè¿‡ä»è¿™ä¸¤ä¸ªåˆ†å¸ƒçš„äº¤é›†ä¸­è¿›è¡Œé‡‡æ ·æ¥è¯æ˜è¿™ä¸€ç‚¹ï¼Œä»è€Œå¾—åˆ°çœ‹èµ·æ¥åƒçœŸå®å›¾åƒä½†å¬èµ·æ¥åƒè‡ªç„¶å£°éŸ³çš„å£°è°±å›¾ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œç”±äºå£°ç å™¨æœ¬è´¨ä¸Šæ˜¯æœ‰æŸçš„ï¼Œå› æ­¤é€šå¸¸æ— æ³•å®ç°å®Œç¾çš„å¾ªç¯ä¸€è‡´æ€§ã€‚

            ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ä¸ªç®€å•ä¸”é›¶æ ·æœ¬çš„æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒå’Œæ–‡æœ¬åˆ°å£°è°±å›¾æ‰©æ•£æ¨¡å‹ï¼Œåœ¨å…±äº«æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œåœ¨åå‘è¿‡ç¨‹ä¸­å¹¶è¡Œå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªï¼Œå¾—åˆ°ä¸€ä¸ªåŒæ—¶ç¬¦åˆè¿™ä¸¤ä¸ªæ¨¡å‹çš„æ ·æœ¬ï¼›æ€§èƒ½ï¼šé€šè¿‡å®šé‡è¯„ä¼°å’Œæ„ŸçŸ¥ç ”ç©¶ï¼Œæœ¬æ–‡çš„æ–¹æ³•æˆåŠŸç”Ÿæˆäº†ä¸æ‰€éœ€éŸ³é¢‘æç¤ºä¸€è‡´ï¼ŒåŒæ—¶å…·æœ‰æ‰€éœ€å›¾åƒæç¤ºè§†è§‰å¤–è§‚çš„å£°è°±å›¾ï¼›å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•ç®€å•æ˜“ç”¨ï¼Œä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–æ¨¡å‹ã€‚
</code></pre>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-44e9096dfe8b1eb6e7cbea03451f9e61.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3f85b8a4d2b38d0e0dd599904b6101cd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-030148a4e48570d9fe061e8cc613146d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f3517b1b23ac9838a5e3355e6bbc727.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-01ecd2fc03770b0401757015953e2d0a.jpg" align="middle">
</details>




## Slicedit: Zero-Shot Video Editing With Text-to-Image Diffusion Models   Using Spatio-Temporal Slices

**Authors:Nathaniel Cohen, Vladimir Kulikov, Matan Kleiner, Inbar Huberman-Spiegelglas, Tomer Michaeli**

Text-to-image (T2I) diffusion models achieve state-of-the-art results in image synthesis and editing. However, leveraging such pretrained models for video editing is considered a major challenge. Many existing works attempt to enforce temporal consistency in the edited video through explicit correspondence mechanisms, either in pixel space or between deep features. These methods, however, struggle with strong nonrigid motion. In this paper, we introduce a fundamentally different approach, which is based on the observation that spatiotemporal slices of natural videos exhibit similar characteristics to natural images. Thus, the same T2I diffusion model that is normally used only as a prior on video frames, can also serve as a strong prior for enhancing temporal consistency by applying it on spatiotemporal slices. Based on this observation, we present Slicedit, a method for text-based video editing that utilizes a pretrained T2I diffusion model to process both spatial and spatiotemporal slices. Our method generates videos that retain the structure and motion of the original video while adhering to the target text. Through extensive experiments, we demonstrate Slicedit's ability to edit a wide range of real-world videos, confirming its clear advantages compared to existing competing methods. Webpage: https://matankleiner.github.io/slicedit/ 

[PDF](http://arxiv.org/abs/2405.12211v1) ICML 2024. Code and examples are available at   https://matankleiner.github.io/slicedit/

**Summary**
åŸºäºè‡ªç„¶è§†é¢‘çš„æ—¶ç©ºåˆ‡ç‰‡ä¸çœŸå®å›¾åƒå…·æœ‰ç›¸ä¼¼çš„ç‰¹æ€§ï¼Œå¯åˆ©ç”¨é¢„è®­ç»ƒçš„ T2I æ‰©æ•£æ¨¡å‹å¯¹å…¶è¿›è¡Œå¤„ç†ï¼Œå¢å¼ºè§†é¢‘ç¼–è¾‘ä¸­çš„æ—¶é—´ä¸€è‡´æ€§

**Key Takeaways**

- åˆ©ç”¨é¢„è®­ç»ƒçš„ T2I æ‰©æ•£æ¨¡å‹æ¥å¢å¼ºæ—¶ç©ºä¸€è‡´æ€§
- Slicedit æ–¹æ³•åŒæ—¶å¤„ç†ç©ºé—´å’Œæ—¶ç©ºåˆ‡ç‰‡
- ç”Ÿæˆè§†é¢‘ä¿ç•™åŸå§‹è§†é¢‘çš„ç»“æ„å’Œè¿åŠ¨ï¼ŒåŒæ—¶ç¬¦åˆç›®æ ‡æ–‡æœ¬
- åœ¨å¹¿æ³›å®éªŒä¸­ï¼Œè¯æ˜ Slicedit èƒ½å¤Ÿç¼–è¾‘å„ç§çœŸå®è§†é¢‘
- æ˜æ˜¾ä¼˜äºç°æœ‰çš„ç«äº‰æ–¹æ³•

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: Sliceditï¼šåŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å’Œæ—¶ç©ºåˆ‡ç‰‡çš„é›¶æ ·æœ¬è§†é¢‘ç¼–è¾‘</p>
</li>
<li>
<p>Authors: Nathaniel Cohen, Vladimir Kulikov, Matan Kleiner, Inbar Huberman-Spiegelglas, Tomer Michaeli</p>
</li>
<li>
<p>Affiliation: å·´é»çŸ¿ä¸š-PSLç ”ç©¶å¤§å­¦</p>
</li>
<li>
<p>Keywords: æ–‡æœ¬åˆ°å›¾åƒ, è§†é¢‘ç¼–è¾‘, æ‰©æ•£æ¨¡å‹, æ—¶ç©ºåˆ‡ç‰‡</p>
</li>
<li>
<p>Urls: </p>
</li>
<li>
<p>Summary: </p>
<p>(1): æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆå’Œç¼–è¾‘ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç„¶è€Œï¼Œå°†è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ç”¨äºè§†é¢‘ç¼–è¾‘è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚è®¸å¤šç°æœ‰å·¥ä½œè¯•å›¾é€šè¿‡åƒç´ ç©ºé—´æˆ–æ·±åº¦ç‰¹å¾ä¹‹é—´çš„æ˜¾å¼å¯¹åº”æœºåˆ¶æ¥å¢å¼ºç¼–è¾‘è§†é¢‘ä¸­çš„æ—¶é—´ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éš¾ä»¥å¤„ç†å¼ºçƒˆçš„éåˆšæ€§è¿åŠ¨ã€‚</p>
<p>(2): æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»æ ¹æœ¬ä¸Šä¸åŒçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºä»¥ä¸‹è§‚å¯Ÿï¼šè‡ªç„¶è§†é¢‘çš„æ—¶ç©ºåˆ‡ç‰‡è¡¨ç°å‡ºä¸è‡ªç„¶å›¾åƒç›¸ä¼¼çš„ç‰¹å¾ã€‚å› æ­¤ï¼Œé€šå¸¸ä»…ç”¨ä½œè§†é¢‘å¸§å…ˆéªŒçš„ç›¸åŒ T2I æ‰©æ•£æ¨¡å‹ä¹Ÿå¯ä»¥é€šè¿‡åœ¨æ—¶ç©ºåˆ‡ç‰‡ä¸Šåº”ç”¨å®ƒæ¥ä½œä¸ºå¢å¼ºæ—¶é—´ä¸€è‡´æ€§çš„å¼ºå…ˆéªŒã€‚</p>
<p>(3): åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬æå‡ºäº† Sliceditï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ–‡æœ¬çš„è§†é¢‘ç¼–è¾‘æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„ T2I æ‰©æ•£æ¨¡å‹å¤„ç†ç©ºé—´å’Œæ—¶ç©ºåˆ‡ç‰‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”Ÿæˆçš„è§†é¢‘ä¿ç•™äº†åŸå§‹è§†é¢‘çš„ç»“æ„å’Œè¿åŠ¨ï¼ŒåŒæ—¶éµå¾ªç›®æ ‡æ–‡æœ¬ã€‚</p>
<p>(4): é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº† Slicedit ç¼–è¾‘å„ç§çœŸå®ä¸–ç•Œè§†é¢‘çš„èƒ½åŠ›ï¼Œè¯å®äº†å…¶ä¸ç°æœ‰ç«äº‰æ–¹æ³•ç›¸æ¯”çš„æ˜æ˜¾ä¼˜åŠ¿ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šæå‡º Sliceditï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ–‡æœ¬çš„è§†é¢‘ç¼–è¾‘æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„ Text-to-Imageï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹å¤„ç†ç©ºé—´å’Œæ—¶ç©ºåˆ‡ç‰‡ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•å°†æ—¶ç©ºåˆ‡ç‰‡ä½œä¸ºå¢å¼ºæ—¶é—´ä¸€è‡´æ€§çš„å¼ºå…ˆéªŒï¼Œé€šè¿‡åœ¨æ—¶ç©ºåˆ‡ç‰‡ä¸Šåº”ç”¨ T2I æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆè§†é¢‘ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šSlicedit ç¼–è¾‘è§†é¢‘æ—¶ä¿ç•™äº†åŸå§‹è§†é¢‘çš„ç»“æ„å’Œè¿åŠ¨ï¼ŒåŒæ—¶éµå¾ªç›®æ ‡æ–‡æœ¬ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬çš„é›¶æ ·æœ¬è§†é¢‘ç¼–è¾‘æ–¹æ³• Sliceditï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œäº†ä¿®æ”¹ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†è§†é¢‘ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œå®ƒå°†æœ€åˆè®¾è®¡ç”¨äºå›¾åƒçš„é¢„è®­ç»ƒå»å™ªå™¨ä¹Ÿåº”ç”¨äºè§†é¢‘çš„æ—¶ç©ºåˆ‡ç‰‡ã€‚ä¸ºäº†ç¼–è¾‘è§†é¢‘ï¼Œæˆ‘ä»¬åœ¨ DDPM åæ¼”è¿‡ç¨‹ä¸­ä½¿ç”¨æˆ‘ä»¬è†¨èƒ€çš„å»å™ªå™¨ï¼ŒåŒæ—¶å°†æºè§†é¢‘çš„æ‰©å±•æ³¨æ„åŠ›æ³¨å…¥ç›®æ ‡è§†é¢‘ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œåœ¨ç¼–è¾‘è§†é¢‘æ—¶ä¿ç•™äº†æœªæŒ‡å®šåŒºåŸŸï¼ŒåŒæ—¶ä¸å½±å“æ—¶é—´ä¸€è‡´æ€§ã€‚æˆ‘ä»¬é€šè¿‡æµ‹é‡ç¼–è¾‘ä¿çœŸåº¦ã€ç»“æ„ä¿ç•™å’Œæ—¶é—´ä¸€è‡´æ€§æŒ‡æ ‡å¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶è¾…ä»¥ç”¨æˆ·ç ”ç©¶ã€‚è™½ç„¶æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿ç•™è¾“å…¥è§†é¢‘çš„ç»“æ„æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒåœ¨å…¨å±€ç¼–è¾‘ä»»åŠ¡ä¸­é‡åˆ°äº†æŒ‘æˆ˜ï¼Œä¾‹å¦‚å°†è‡ªç„¶è§†é¢‘çš„å¸§è½¬æ¢ä¸ºç»˜ç”»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…é™äºä¿ç•™ç»“æ„çš„ç¼–è¾‘ã€‚è¿™æ˜¯ç”±äºä½¿ç”¨äº†å¸¦æœ‰æ³¨æ„åŠ›æ³¨å…¥çš„ DDPM åæ¼”ã€‚å›¾ 11 ä¸­æ˜¾ç¤ºäº†ä¸€ä¸ªç¤ºä¾‹å¤±è´¥æ¡ˆä¾‹ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬çš„é›¶æ ·æœ¬è§†é¢‘ç¼–è¾‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶å°†å…¶åº”ç”¨äºè§†é¢‘çš„æ—¶ç©ºåˆ‡ç‰‡ä»¥å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç¼–è¾‘ä¿çœŸåº¦ã€ç»“æ„ä¿ç•™å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
å·¥ä½œé‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•éœ€è¦é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä¸”ç¼–è¾‘è¿‡ç¨‹å¯èƒ½éœ€è¦å¤§é‡è®¡ç®—ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7ad40d7ffd4fdfec179a13d80066e3bf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fc0922570bcd1ad99da98532754eebb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db1b0305aeb4fd36b0e3253f5b88f485.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7730aa9df76f69b4353b0e3ce05aaa74.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e869c60df6712ebe7f060fa84c38f40e.jpg" align="middle">
</details>




## Evolving Storytelling: Benchmarks and Methods for New Character   Customization with Diffusion Models

**Authors:Xiyu Wang, Yufei Wang, Satoshi Tsutsui, Weisi Lin, Bihan Wen, Alex C. Kot**

Diffusion-based models for story visualization have shown promise in generating content-coherent images for storytelling tasks. However, how to effectively integrate new characters into existing narratives while maintaining character consistency remains an open problem, particularly with limited data. Two major limitations hinder the progress: (1) the absence of a suitable benchmark due to potential character leakage and inconsistent text labeling, and (2) the challenge of distinguishing between new and old characters, leading to ambiguous results. To address these challenges, we introduce the NewEpisode benchmark, comprising refined datasets designed to evaluate generative models' adaptability in generating new stories with fresh characters using just a single example story. The refined dataset involves refined text prompts and eliminates character leakage. Additionally, to mitigate the character confusion of generated results, we propose EpicEvo, a method that customizes a diffusion-based visual story generation model with a single story featuring the new characters seamlessly integrating them into established character dynamics. EpicEvo introduces a novel adversarial character alignment module to align the generated images progressively in the diffusive process, with exemplar images of new characters, while applying knowledge distillation to prevent forgetting of characters and background details. Our evaluation quantitatively demonstrates that EpicEvo outperforms existing baselines on the NewEpisode benchmark, and qualitative studies confirm its superior customization of visual story generation in diffusion models. In summary, EpicEvo provides an effective way to incorporate new characters using only one example story, unlocking new possibilities for applications such as serialized cartoons. 

[PDF](http://arxiv.org/abs/2405.11852v1) 

**Summary**
æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥æ–°è§’è‰²æ—¶ï¼Œå®šåˆ¶åŒ–æ–¹æ³•EpicEvoå¯æœ‰æ•ˆè§£å†³è§’è‰²ä¸€è‡´æ€§é—®é¢˜ï¼Œé€šè¿‡å•ä¸ªæ•…äº‹èŒƒä¾‹å®ç°æ— ç¼æ•´åˆã€‚

**Key Takeaways**
- NewEpisodeåŸºå‡†å»ºç«‹ï¼Œç”¨äºè¯„ä¼°æ‰©æ•£ç”Ÿæˆæ¨¡å‹åœ¨ä»…ä½¿ç”¨å•ä¸€ç¤ºä¾‹æ•…äº‹çš„æƒ…å†µä¸‹ï¼Œç”Ÿæˆå…·æœ‰æ–°è§’è‰²çš„å†…å®¹è¿è´¯å›¾åƒã€‚
- ç²¾ç‚¼æ•°æ®é›†ï¼Œæ¶ˆé™¤å­—ç¬¦æ³„éœ²å’Œæ–‡æœ¬æ ‡ç­¾ä¸ä¸€è‡´çš„é—®é¢˜ã€‚
- EpicEvoæ–¹æ³•ï¼Œé€šè¿‡å•ä¸€æ•…äº‹å®šåˆ¶åŸºäºæ‰©æ•£çš„å¯è§†åŒ–æ•…äº‹ç”Ÿæˆæ¨¡å‹ï¼Œæ— ç¼æ•´åˆæ–°è§’è‰²ã€‚
- åŠ å…¥å¯¹æŠ—æ€§å­—ç¬¦å¯¹é½æ¨¡å—ï¼Œåœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å°†ç”Ÿæˆå›¾åƒä¸æ–°è§’è‰²ç¤ºä¾‹å›¾åƒå¯¹é½ã€‚
- è¿ç”¨çŸ¥è¯†è’¸é¦ï¼Œé˜²æ­¢é—å¿˜è§’è‰²å’ŒèƒŒæ™¯ç»†èŠ‚ã€‚
- è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒEpicEvoåœ¨NewEpisodeåŸºå‡†ä¸Šä¼˜äºç°æœ‰åŸºçº¿ã€‚
- EpicEvoå¯æœ‰æ•ˆæ•´åˆæ–°è§’è‰²ï¼Œä»…éœ€å•ä¸ªç¤ºä¾‹æ•…äº‹ï¼Œä¸ºè¿è½½æ¼«ç”»ç­‰åº”ç”¨å¼€è¾Ÿæ–°å¯èƒ½ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: å¯æ¼”åŒ–çš„æ•…äº‹ç”Ÿæˆï¼šç”¨äºæ–°è§’è‰²è‡ªå®šä¹‰çš„åŸºå‡†å’Œæ–¹æ³•</p>
</li>
<li>
<p>Authors: Xiyu Wang, Yufei Wang, Satoshi Tsutsui, Weisi Lin, Bihan Wen, Alex C. Kot</p>
</li>
<li>
<p>Affiliation: å—æ´‹ç†å·¥å¤§å­¦</p>
</li>
<li>
<p>Keywords: Generative Diffusion Model, Story Visualization, Generative Model Customization</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/pdf/2405.11852.pdf , Github:None</p>
</li>
<li>
<p>Summary:</p>
<p>(1): åŸºäºæ‰©æ•£çš„æ¨¡å‹åœ¨æ•…äº‹å¯è§†åŒ–ä¸­å±•ç¤ºäº†ç”Ÿæˆå†…å®¹è¿è´¯å›¾åƒçš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå¦‚ä½•åœ¨ä¿æŒè§’è‰²ä¸€è‡´æ€§çš„åŒæ—¶æœ‰æ•ˆåœ°å°†æ–°è§’è‰²èå…¥ç°æœ‰å™äº‹ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªéš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ã€‚æœ‰ä¸¤ä¸ªä¸»è¦é™åˆ¶é˜»ç¢äº†è¿›å±•ï¼š(1) ç”±äºæ½œåœ¨çš„è§’è‰²æ³„éœ²å’Œä¸ä¸€è‡´çš„æ–‡æœ¬æ ‡è®°ï¼Œç¼ºå°‘åˆé€‚çš„åŸºå‡†ï¼›(2) åŒºåˆ†æ–°è§’è‰²å’Œæ—§è§’è‰²çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´ç»“æœæ¨¡æ£±ä¸¤å¯ã€‚</p>
<p>(2): è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹æ¥ç”Ÿæˆæ•…äº‹å¯è§†åŒ–ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š1ï¼‰ç¼ºä¹åˆé€‚çš„åŸºå‡†æ¥è¯„ä¼°ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå…·æœ‰æ–°è§’è‰²çš„æ–°æ•…äº‹çš„é€‚åº”æ€§ã€‚2ï¼‰éš¾ä»¥åŒºåˆ†æ–°è§’è‰²å’Œæ—§è§’è‰²ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœæ¨¡æ£±ä¸¤å¯ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•åŒ…æ‹¬ï¼š1ï¼‰å¼•å…¥ NewEpisode åŸºå‡†ï¼Œè¯¥åŸºå‡†åŒ…å«ç»è¿‡æ”¹è¿›çš„æ•°æ®é›†ï¼Œæ—¨åœ¨ä½¿ç”¨å•ä¸ªç¤ºä¾‹æ•…äº‹è¯„ä¼°ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå…·æœ‰æ–°è§’è‰²çš„æ–°æ•…äº‹çš„é€‚åº”æ€§ã€‚2ï¼‰æå‡º EpicEvoï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨å…·æœ‰æ–°è§’è‰²çš„å•ä¸ªæ•…äº‹æ¥è‡ªå®šä¹‰åŸºäºæ‰©æ•£çš„è§†è§‰æ•…äº‹ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ï¼Œå°†æ–°è§’è‰²æ— ç¼é›†æˆåˆ°æ—¢å®šçš„è§’è‰²åŠ¨æ€ä¸­ã€‚</p>
<p>(4): æœ¬æ–‡æ–¹æ³•åœ¨ NewEpisode åŸºå‡†ä¸Šå–å¾—äº†ä»¥ä¸‹æ€§èƒ½ï¼š1ï¼‰å®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒEpicEvo åœ¨ NewEpisode åŸºå‡†ä¸Šä¼˜äºç°æœ‰çš„åŸºçº¿ã€‚2ï¼‰å®šæ€§ç ”ç©¶è¯å®äº† EpicEvo åœ¨æ‰©æ•£æ¨¡å‹ä¸­å¯¹è§†è§‰æ•…äº‹ç”Ÿæˆçš„å“è¶Šå®šåˆ¶ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§ä»…ä½¿ç”¨ä¸€ä¸ªç¤ºä¾‹æ•…äº‹å°±èƒ½èåˆæ–°è§’è‰²çš„æœ‰æ•ˆæ–¹æ³•ï¼Œä¸ºè¿è½½æ¼«ç”»ç­‰åº”ç”¨è§£é”äº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>(1): æå‡º NewEpisode åŸºå‡†ï¼Œè¯¥åŸºå‡†åŒ…å«ç»è¿‡æ”¹è¿›çš„æ•°æ®é›†ï¼Œæ—¨åœ¨ä½¿ç”¨å•ä¸ªç¤ºä¾‹æ•…äº‹è¯„ä¼°ç”Ÿæˆæ¨¡å‹ç”Ÿæˆå…·æœ‰æ–°è§’è‰²çš„æ–°æ•…äº‹çš„é€‚åº”æ€§ï¼›</p>
<p>(2): æå‡ºäº† EpicEvoï¼Œè¿™æ˜¯ä¸€ç§ä½¿ç”¨å…·æœ‰æ–°è§’è‰²çš„å•ä¸ªæ•…äº‹æ¥è‡ªå®šä¹‰åŸºäºæ‰©æ•£çš„è§†è§‰æ•…äº‹ç”Ÿæˆæ¨¡å‹çš„æ–¹æ³•ï¼Œå°†æ–°è§’è‰²æ— ç¼é›†æˆåˆ°æ—¢å®šçš„è§’è‰²åŠ¨æ€ä¸­ï¼›</p>
<p>(3): åœ¨ NewEpisode åŸºå‡†ä¸Šå¯¹ EpicEvo è¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ EpicEvo åœ¨ç”Ÿæˆå…·æœ‰æ–°è§’è‰²çš„æ–°æ•…äº‹çš„é€‚åº”æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„åŸºçº¿ï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨æ‰©æ•£æ¨¡å‹ä¸­å¯¹è§†è§‰æ•…äº‹ç”Ÿæˆè¿›è¡Œå“è¶Šçš„å®šåˆ¶ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡è§£å†³äº†æ•…äº‹è§’è‰²å®šåˆ¶çš„éš¾é¢˜ï¼Œæå‡º NewEpisode åŸºå‡†å’Œ EpicEvo æ–¹æ³•ï¼Œä½¿è§†è§‰æ•…äº‹ç”Ÿæˆæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä»æœªè§è¿‡çš„è§’è‰²çš„æ–°æ•…äº‹ï¼Œä¸ºè¿è½½æ¼«ç”»ç­‰åº”ç”¨è§£é”äº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡º NewEpisode åŸºå‡†å’Œ EpicEvo æ–¹æ³•ï¼›æ€§èƒ½ï¼šåœ¨ NewEpisode åŸºå‡†ä¸Šä¼˜äºç°æœ‰çš„åŸºçº¿ï¼Œèƒ½å¤Ÿåœ¨æ‰©æ•£æ¨¡å‹ä¸­å¯¹è§†è§‰æ•…äº‹ç”Ÿæˆè¿›è¡Œå“è¶Šçš„å®šåˆ¶ï¼›å·¥ä½œé‡ï¼šéœ€è¦æ”¶é›†å’Œæ•´ç† NewEpisode åŸºå‡†æ•°æ®ï¼Œè®­ç»ƒ EpicEvo æ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1bcf790e86915883bf4c5491f4af0617.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7e49809f39744c919340eadd0a23302.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7829327de314711f1e323c58084208a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aea383233d966c6afec2db0d88be118b.jpg" align="middle">
</details>




## ViViD: Video Virtual Try-on using Diffusion Models

**Authors:Zixun Fang, Wei Zhai, Aimin Su, Hongliang Song, Kai Zhu, Mao Wang, Yu Chen, Zhiheng Liu, Yang Cao, Zheng-Jun Zha**

Video virtual try-on aims to transfer a clothing item onto the video of a target person. Directly applying the technique of image-based try-on to the video domain in a frame-wise manner will cause temporal-inconsistent outcomes while previous video-based try-on solutions can only generate low visual quality and blurring results. In this work, we present ViViD, a novel framework employing powerful diffusion models to tackle the task of video virtual try-on. Specifically, we design the Garment Encoder to extract fine-grained clothing semantic features, guiding the model to capture garment details and inject them into the target video through the proposed attention feature fusion mechanism. To ensure spatial-temporal consistency, we introduce a lightweight Pose Encoder to encode pose signals, enabling the model to learn the interactions between clothing and human posture and insert hierarchical Temporal Modules into the text-to-image stable diffusion model for more coherent and lifelike video synthesis. Furthermore, we collect a new dataset, which is the largest, with the most diverse types of garments and the highest resolution for the task of video virtual try-on to date. Extensive experiments demonstrate that our approach is able to yield satisfactory video try-on results. The dataset, codes, and weights will be publicly available. Project page: https://becauseimbatman0.github.io/ViViD. 

[PDF](http://arxiv.org/abs/2405.11794v1) 

**Summary**
è§†é¢‘è™šæ‹Ÿè¯•ç©¿é€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°æœè£…åœ¨è§†é¢‘äººä½“ä¸Šçš„è¯•ç©¿ï¼Œè¯¥æ¡†æ¶åŒ…å«æœè£…ç¼–ç å™¨ã€å§¿æ€ç¼–ç å™¨å’Œæ—¶é—´æ¨¡å—ï¼Œå¹¶æ”¶é›†äº†ç”¨äºè§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡çš„æœ€å¤§ã€æœ€å…·å¤šæ ·æ€§æœè£…ç±»å‹å’Œæœ€é«˜åˆ†è¾¨ç‡çš„æ–°æ•°æ®é›†ã€‚

**Key Takeaways**
- è§†é¢‘è™šæ‹Ÿè¯•ç©¿å°†æœè£…è½¬ç§»åˆ°ç›®æ ‡äººç‰©è§†é¢‘ä¸Šï¼Œä½†é€å¸§åº”ç”¨å›¾åƒè¯•ç©¿ä¼šå¯¼è‡´æ—¶é—´ä¸ä¸€è‡´ã€‚
- ViViD æ¡†æ¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥è§£å†³è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ã€‚
- æœè£…ç¼–ç å™¨æå–æœè£…è¯­ä¹‰ç‰¹å¾ï¼Œç”¨äºæ•è·æœè£…ç»†èŠ‚å¹¶é€šè¿‡æ³¨æ„åŠ›ç‰¹å¾èåˆæœºåˆ¶æ³¨å…¥ç›®æ ‡è§†é¢‘ã€‚
- å§¿åŠ¿ç¼–ç å™¨ç¼–ç å§¿åŠ¿ä¿¡å·ï¼Œä½¿æ¨¡å‹å­¦ä¹ æœè£…ä¸äººä½“å§¿åŠ¿ä¹‹é—´çš„äº¤äº’ã€‚
- æ–‡æœ¬åˆ°å›¾åƒç¨³å®šçš„æ‰©æ•£æ¨¡å‹ä¸­åŠ å…¥å±‚æ¬¡åŒ–æ—¶é—´æ¨¡å—ï¼Œå®ç°æ›´è¿è´¯ã€é€¼çœŸçš„è§†é¢‘åˆæˆã€‚
- ViViD æ”¶é›†äº†è¿„ä»Šä¸ºæ­¢ç”¨äºè§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡çš„æœ€å¤§ã€æœ€å…·å¤šæ ·æ€§æœè£…ç±»å‹å’Œæœ€é«˜åˆ†è¾¨ç‡çš„æ–°æ•°æ®é›†ã€‚
- å®éªŒè¡¨æ˜ï¼ŒViViD èƒ½å¤Ÿäº§ç”Ÿä»¤äººæ»¡æ„çš„è§†é¢‘è¯•ç©¿ç»“æœã€‚
- æ•°æ®é›†ã€ä»£ç å’Œæƒé‡å°†å…¬å¼€ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: ViViD: ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„è§†é¢‘è™šæ‹Ÿè¯•ç©¿</p>
</li>
<li>
<p>Authors: Zixun Fang, Wei Zhai, Aimin Su, Hongliang Song, Kai Zhu, Mao Wang, Yu Chen, Zhiheng Liu, Yang Cao, Zheng-Jun Zha</p>
</li>
<li>
<p>Affiliation: ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</p>
</li>
<li>
<p>Keywords: Video virtual try-on, Diffusion models, Pose encoding, Temporal consistency</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2405.11794, Github: None</p>
</li>
<li>
<p>Summary: </p>
</li>
</ol>
<p>(1): è§†é¢‘è™šæ‹Ÿè¯•ç©¿æ—¨åœ¨å°†ä¸€ä»¶è¡£æœè½¬ç§»åˆ°ç›®æ ‡äººç‰©çš„è§†é¢‘ä¸Šã€‚å°†åŸºäºå›¾åƒçš„è¯•ç©¿æŠ€æœ¯é€å¸§åº”ç”¨äºè§†é¢‘é¢†åŸŸä¼šå¯¼è‡´æ—¶é—´ä¸ä¸€è‡´çš„ç»“æœï¼Œè€Œä¹‹å‰çš„åŸºäºè§†é¢‘çš„è¯•ç©¿è§£å†³æ–¹æ¡ˆåªèƒ½ç”Ÿæˆä½è§†è§‰è´¨é‡å’Œæ¨¡ç³Šçš„ç»“æœã€‚</p>
<p>(2): è¿‡å»çš„åŸºäºå›¾åƒçš„è™šæ‹Ÿè¯•ç©¿æ–¹æ³•æ— æ³•ç›´æ¥åº”ç”¨äºè§†é¢‘ï¼Œå› ä¸ºè¿™ä¼šå¯¼è‡´ç¾éš¾æ€§çš„ç»“æœã€‚åŸºäºè§†é¢‘çš„è¯•ç©¿è§£å†³æ–¹æ¡ˆè™½ç„¶å¯ä»¥è§£å†³æ—¶é—´ä¸€è‡´æ€§é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šäº§ç”Ÿä½è§†è§‰è´¨é‡å’Œæ¨¡ç³Šçš„ç»“æœã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº† ViViDï¼Œä¸€ä¸ªä½¿ç”¨å¼ºå¤§çš„æ‰©æ•£æ¨¡å‹æ¥è§£å†³è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡çš„æ–°æ¡†æ¶ã€‚ViViD åŒ…å«ä¸€ä¸ªæœè£…ç¼–ç å™¨ï¼Œç”¨äºæå–ç»†ç²’åº¦çš„æœè£…è¯­ä¹‰ç‰¹å¾ï¼ŒæŒ‡å¯¼æ¨¡å‹æ•æ‰æœè£…ç»†èŠ‚å¹¶é€šè¿‡æå‡ºçš„æ³¨æ„åŠ›ç‰¹å¾èåˆæœºåˆ¶å°†å…¶æ³¨å…¥ç›®æ ‡è§†é¢‘ä¸­ã€‚ä¸ºäº†ç¡®ä¿æ—¶ç©ºä¸€è‡´æ€§ï¼ŒViViD å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„å§¿åŠ¿ç¼–ç å™¨æ¥ç¼–ç å§¿åŠ¿ä¿¡å·ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æœè£…å’Œäººä½“å§¿åŠ¿ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå¹¶å°†åˆ†å±‚çš„ Temporal æ¨¡å—æ’å…¥åˆ°æ–‡æœ¬åˆ°å›¾åƒçš„ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸­ä»¥å®ç°æ›´è¿è´¯å’Œé€¼çœŸçš„è§†é¢‘åˆæˆã€‚æ­¤å¤–ï¼ŒViViD è¿˜æ”¶é›†äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢ç”¨äºè§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡çš„æœ€å¤§ã€æœè£…ç±»å‹æœ€å¤šã€åˆ†è¾¨ç‡æœ€é«˜çš„æ•°æ®é›†ã€‚</p>
<p>(4): å®éªŒè¡¨æ˜ï¼ŒViViD èƒ½å¤Ÿäº§ç”Ÿä»¤äººæ»¡æ„çš„è§†é¢‘è¯•ç©¿ç»“æœã€‚åœ¨ ViViD æ•°æ®é›†ä¸Šï¼ŒViViD åœ¨ FID å’Œ LPIPS åº¦é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº† ViViD åœ¨è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š</p>
<pre><code>            (1):è¯¥æ–¹æ³•å°†è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡è§†ä¸ºè§†é¢‘ä¿®å¤é—®é¢˜ï¼Œå°†æœè£…ç²˜è´´åˆ°ä¸æœè£…æ— å…³çš„åŒºåŸŸï¼›

            (2):æå‡ºæœè£…ç¼–ç å™¨æå–æœè£…è¯­ä¹‰ç‰¹å¾ï¼Œé€šè¿‡æ³¨æ„åŠ›ç‰¹å¾èåˆæœºåˆ¶æ³¨å…¥ç›®æ ‡è§†é¢‘ä¸­ï¼›

            (3):å¼•å…¥è½»é‡çº§å§¿åŠ¿ç¼–ç å™¨ç¼–ç å§¿åŠ¿ä¿¡å·ï¼Œä½¿æ¨¡å‹å­¦ä¹ æœè£…å’Œäººä½“å§¿åŠ¿ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼›

            (4):åœ¨æ–‡æœ¬åˆ°å›¾åƒçš„ç¨³å®šæ‰©æ•£æ¨¡å‹ä¸­æ’å…¥åˆ†å±‚çš„ Temporal æ¨¡å—ï¼Œå®ç°æ›´è¿è´¯ã€é€¼çœŸçš„è§†é¢‘åˆæˆï¼›

            (5):æ”¶é›†æ–°æ•°æ®é›† ViViDï¼ŒåŒ…å«è¿„ä»Šä¸ºæ­¢ç”¨äºè§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡çš„æœ€å¤§ã€æœè£…ç±»å‹æœ€å¤šã€åˆ†è¾¨ç‡æœ€é«˜çš„è§†é¢‘æ•°æ®ã€‚
</code></pre>
</li>
<li>
<p>ç»“è®ºï¼š</p>
<pre><code>            (1): æœ¬å·¥ä½œé¦–æ¬¡å°†å¼ºå¤§çš„æ‰©æ•£æ¨¡å‹åº”ç”¨äºè§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ï¼Œæå‡ºäº† ViViD æ¡†æ¶ï¼Œåœ¨è§†é¢‘è™šæ‹Ÿè¯•ç©¿é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚

            (2):Innovation point: åˆ›æ–°ç‚¹ï¼šæå‡ºäº†æœè£…ç¼–ç å™¨ã€æ³¨æ„åŠ›ç‰¹å¾èåˆæœºåˆ¶ã€è½»é‡çº§å§¿åŠ¿ç¼–ç å™¨å’Œåˆ†å±‚çš„ Temporal æ¨¡å—ï¼Œæœ‰æ•ˆè§£å†³äº†è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ä¸­çš„æœè£…ç»†èŠ‚æ•æ‰ã€æ—¶é—´ä¸€è‡´æ€§ã€æœè£…ä¸äººä½“å§¿åŠ¿äº¤äº’å»ºæ¨¡ç­‰å…³é”®æŒ‘æˆ˜ã€‚Performance: æ€§èƒ½ï¼šåœ¨ ViViD æ•°æ®é›†ä¸Šï¼ŒViViD åœ¨ FID å’Œ LPIPS åº¦é‡æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨è§†é¢‘è™šæ‹Ÿè¯•ç©¿ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚Workload: å·¥ä½œé‡ï¼šViViD çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚
</code></pre>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0355bce071e350207c70de02bda959ed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23ccaa5c8bb5673e1bef077ad2b7d22a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e7b35dffa1cf9920b89882397361f15f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e3d8bba6d2cbf1178e36f754857920d.jpg" align="middle">
</details>




## HR Human: Modeling Human Avatars with Triangular Mesh and   High-Resolution Textures from Videos

**Authors:Qifeng Chen, Rengan Xie, Kai Huang, Qi Wang, Wenting Zheng, Rong Li, Yuchi Huo**

Recently, implicit neural representation has been widely used to generate animatable human avatars. However, the materials and geometry of those representations are coupled in the neural network and hard to edit, which hinders their application in traditional graphics engines. We present a framework for acquiring human avatars that are attached with high-resolution physically-based material textures and triangular mesh from monocular video. Our method introduces a novel information fusion strategy to combine the information from the monocular video and synthesize virtual multi-view images to tackle the sparsity of the input view. We reconstruct humans as deformable neural implicit surfaces and extract triangle mesh in a well-behaved pose as the initial mesh of the next stage. In addition, we introduce an approach to correct the bias for the boundary and size of the coarse mesh extracted. Finally, we adapt prior knowledge of the latent diffusion model at super-resolution in multi-view to distill the decomposed texture. Experiments show that our approach outperforms previous representations in terms of high fidelity, and this explicit result supports deployment on common renderers. 

[PDF](http://arxiv.org/abs/2405.11270v1) 

**Summary**

ç”¨å•ç›®è§†é¢‘è·å–å¸¦æœ‰ç‰©ç†æè´¨çº¹ç†å’Œä¸‰è§’å½¢ç½‘æ ¼çš„å¯å˜å½¢äººä½“æ¨¡å‹ã€‚

**Key Takeaways**

- ä½¿ç”¨éšå¼ç¥ç»è¡¨ç¤ºç”Ÿæˆå¯åŠ¨ç”»äººä½“æ¨¡å‹ã€‚
- å¼•å…¥ä¿¡æ¯èåˆç­–ç•¥è§£å†³å•ç›®è§†é¢‘è¾“å…¥è§†å›¾ç¨€ç–é—®é¢˜ã€‚
- é‡å»ºäººä½“ä¸ºå¯å˜å½¢ç¥ç»éšå¼æ›²é¢ï¼Œæå–ä¸‰è§’å½¢ç½‘æ ¼ä½œä¸ºåˆå§‹ç½‘æ ¼ã€‚
- æå‡ºæ–¹æ³•çº æ­£ç²—ç³™ç½‘æ ¼è¾¹ç•Œå’Œå¤§å°åå·®ã€‚
- é‡‡ç”¨å¤šè§†å›¾è¶…åˆ†è¾¨ç‡æ½œæ‰©æ•£æ¨¡å‹å…ˆéªŒçŸ¥è¯†æå–åˆ†è§£çº¹ç†ã€‚
- å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨é«˜ä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å¾€è¡¨ç¤ºï¼Œä¸”æ˜¾å¼ç»“æœæ”¯æŒåœ¨é€šç”¨æ¸²æŸ“å™¨ä¸Šéƒ¨ç½²ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: HR Human: ä½¿ç”¨ä¸‰è§’å½¢ç½‘æ ¼å’Œé«˜åˆ†è¾¨ç‡çº¹ç†ä»è§†é¢‘ä¸­å»ºæ¨¡äººä½“åŒ–èº«</p>
</li>
<li>
<p>Authors: Qifeng Chen, Rengan Xie, Kai Huang, Qi Wang, Wenting Zheng, Rong Li, Yuchi Huo</p>
</li>
<li>
<p>Affiliation: ä¸­å›½æ­å·</p>
</li>
<li>
<p>Keywords: Human modeling;Rendering;Texture super resolution</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2405.11270</p>
</li>
</ol>
<p>Github: None</p>
<ol>
<li>
<p>Summary:</p>
<p>(1): è¿‘æœŸï¼Œéšå¼ç¥ç»è¡¨ç¤ºå·²è¢«å¹¿æ³›ç”¨äºç”Ÿæˆå¯åŠ¨ç”»çš„äººä½“åŒ–èº«ã€‚ç„¶è€Œï¼Œè¿™äº›è¡¨ç¤ºä¸­çš„æè´¨å’Œå‡ ä½•å½¢çŠ¶åœ¨ç¥ç»ç½‘ç»œä¸­è€¦åˆï¼Œéš¾ä»¥ç¼–è¾‘ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨ä¼ ç»Ÿå›¾å½¢å¼•æ“ä¸­çš„åº”ç”¨ã€‚</p>
<p>(2): è¿‡å»çš„æ–¹æ³•ä¸»è¦æœ‰ï¼šImplicit animatable human reconstructionã€Relighting4Dã€Relightavatarã€‚è¿™äº›æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼šéšå¼å‡ ä½•å’Œçº¹ç†éš¾ä»¥ç¼–è¾‘ï¼Œäº§ç”Ÿçš„çº¹ç†æ¸…æ™°åº¦ä½ï¼Œæ— æ³•åº”ç”¨äºä¼ ç»Ÿå›¾å½¢å¼•æ“ã€‚</p>
<p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å•ç›®è§†é¢‘ä¸­è·å–å…·æœ‰é«˜åˆ†è¾¨ç‡åŸºäºç‰©ç†çš„æè´¨çº¹ç†å’Œä¸‰è§’å½¢ç½‘æ ¼çš„äººä½“åŒ–èº«çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„ä¿¡æ¯èåˆç­–ç•¥ï¼Œå°†å•ç›®è§†é¢‘ä¸­çš„ä¿¡æ¯ä¸åˆæˆçš„è™šæ‹Ÿå¤šè§†å›¾å›¾åƒç›¸ç»“åˆï¼Œä»¥è§£å†³è¾“å…¥è§†å›¾çš„ç¨€ç–æ€§ã€‚æˆ‘ä»¬å°†äººä½“é‡å»ºä¸ºå¯å˜å½¢çš„ç¥ç»éšå¼æ›²é¢ï¼Œå¹¶åœ¨è¡Œä¸ºè‰¯å¥½çš„å§¿æ€ä¸­æå–ä¸‰è§’å½¢ç½‘æ ¼ä½œä¸ºä¸‹ä¸€é˜¶æ®µçš„åˆå§‹ç½‘æ ¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–¹æ³•æ¥çº æ­£æå–çš„ç²—ç³™ç½‘æ ¼çš„è¾¹ç•Œå’Œå¤§å°åå·®ã€‚æœ€åï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å¤šè§†å›¾è¶…åˆ†è¾¨ç‡ä¸­æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†æ¥æå–åˆ†è§£çš„çº¹ç†ã€‚</p>
<p>(4): åœ¨äººä½“å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨é«˜ä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å¾€çš„è¡¨ç¤ºï¼Œå¹¶ä¸”è¿™ç§æ˜¾å¼ç»“æœæ”¯æŒåœ¨é€šç”¨æ¸²æŸ“å™¨ä¸Šçš„éƒ¨ç½²ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§ä»å•ç›®è§†é¢‘è·å–å…·æœ‰é«˜åˆ†è¾¨ç‡åŸºäºç‰©ç†çš„æè´¨çº¹ç†å’Œä¸‰è§’å½¢ç½‘æ ¼çš„äººä½“åŒ–èº«çš„æ–¹æ³•ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„ä¿¡æ¯èåˆç­–ç•¥ï¼Œå°†å•ç›®è§†é¢‘ä¸­çš„ä¿¡æ¯ä¸åˆæˆçš„è™šæ‹Ÿå¤šè§†å›¾å›¾åƒç›¸ç»“åˆï¼Œä»¥è§£å†³è¾“å…¥è§†å›¾çš„ç¨€ç–æ€§ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šå°†äººä½“é‡å»ºä¸ºå¯å˜å½¢çš„ç¥ç»éšå¼æ›²é¢ï¼Œå¹¶åœ¨è¡Œä¸ºè‰¯å¥½çš„å§¿æ€ä¸­æå–ä¸‰è§’å½¢ç½‘æ ¼ä½œä¸ºä¸‹ä¸€é˜¶æ®µçš„åˆå§‹ç½‘æ ¼ï¼›</p>
<p>ï¼ˆ4ï¼‰ï¼šå¼•å…¥äº†ä¸€ç§æ–¹æ³•æ¥çº æ­£æå–çš„ç²—ç³™ç½‘æ ¼çš„è¾¹ç•Œå’Œå¤§å°åå·®ï¼›</p>
<p>ï¼ˆ5ï¼‰ï¼šé‡‡ç”¨äº†å¤šè§†å›¾è¶…åˆ†è¾¨ç‡ä¸­æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†æ¥æå–åˆ†è§£çš„çº¹ç†ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å•ç›®è§†é¢‘ä¸­è·å–å…·æœ‰é«˜åˆ†è¾¨ç‡åŸºäºç‰©ç†çš„æè´¨çº¹ç†å’Œä¸‰è§’å½¢ç½‘æ ¼çš„äººä½“åŒ–èº«çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨é«˜ä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å¾€çš„è¡¨ç¤ºï¼Œå¹¶ä¸”è¿™ç§æ˜¾å¼ç»“æœæ”¯æŒåœ¨é€šç”¨æ¸²æŸ“å™¨ä¸Šçš„éƒ¨ç½²ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¿¡æ¯èåˆç­–ç•¥ï¼Œå°†å•ç›®è§†é¢‘ä¸­çš„ä¿¡æ¯ä¸åˆæˆçš„è™šæ‹Ÿå¤šè§†å›¾å›¾åƒç›¸ç»“åˆï¼Œä»¥è§£å†³è¾“å…¥è§†å›¾çš„ç¨€ç–æ€§ï¼›å¼•å…¥äº†ä¸€ç§æ–¹æ³•æ¥çº æ­£æå–çš„ç²—ç³™ç½‘æ ¼çš„è¾¹ç•Œå’Œå¤§å°åå·®ï¼›é‡‡ç”¨äº†å¤šè§†å›¾è¶…åˆ†è¾¨ç‡ä¸­æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†æ¥æå–åˆ†è§£çš„çº¹ç†ã€‚
æ€§èƒ½ï¼šåœ¨äººä½“å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨é«˜ä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å¾€çš„è¡¨ç¤ºã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦åˆæˆè™šæ‹Ÿå¤šè§†å›¾å›¾åƒï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-58f6be0321d44679e674675890fa61f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d120932cc8da35e36223e213bf08ff48.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e49edd99763ea96c13881d786d9a42af.jpg" align="middle">
</details>




## Deep Data Consistency: a Fast and Robust Diffusion Model-based Solver   for Inverse Problems

**Authors:Hanyu Chen, Zhixiu Hao, Liying Xiao**

Diffusion models have become a successful approach for solving various image inverse problems by providing a powerful diffusion prior. Many studies tried to combine the measurement into diffusion by score function replacement, matrix decomposition, or optimization algorithms, but it is hard to balance the data consistency and realness. The slow sampling speed is also a main obstacle to its wide application. To address the challenges, we propose Deep Data Consistency (DDC) to update the data consistency step with a deep learning model when solving inverse problems with diffusion models. By analyzing existing methods, the variational bound training objective is used to maximize the conditional posterior and reduce its impact on the diffusion process. In comparison with state-of-the-art methods in linear and non-linear tasks, DDC demonstrates its outstanding performance of both similarity and realness metrics in generating high-quality solutions with only 5 inference steps in 0.77 seconds on average. In addition, the robustness of DDC is well illustrated in the experiments across datasets, with large noise and the capacity to solve multiple tasks in only one pre-trained model. 

[PDF](http://arxiv.org/abs/2405.10748v1) Codes: https://github.com/Hanyu-Chen373/DeepDataConsistency

**Summary:**
æ·±åº¦æ•°æ®ä¸€è‡´æ€§é€šè¿‡æ·±åº¦å­¦ä¹ æ¨¡å‹æ›´æ–°æ•°æ®ä¸€è‡´æ€§æ­¥éª¤ï¼Œè§£å†³äº†æ‰©æ•£æ¨¡å‹æ±‚è§£é€†é—®é¢˜çš„æŒ‘æˆ˜ï¼Œå±•ç°äº†å“è¶Šçš„ç›¸ä¼¼æ€§å’ŒçœŸå®æ€§è¡¨ç°ã€‚

**Key Takeaways:**
- æå‡ºæ·±åº¦æ•°æ®ä¸€è‡´æ€§ (DDC) æ–¹æ³•ï¼Œå°†æ•°æ®ä¸€è‡´æ€§æ­¥éª¤ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ›´æ–°ã€‚
- ä½¿ç”¨å˜åˆ†ç•Œè®­ç»ƒç›®æ ‡ï¼Œæœ€å¤§åŒ–æ¡ä»¶åéªŒï¼Œå‡å°‘å…¶å¯¹æ‰©æ•£è¿‡ç¨‹çš„å½±å“ã€‚
- åœ¨çº¿æ€§å’Œéçº¿æ€§ä»»åŠ¡ä¸­ï¼ŒDDC åœ¨ç›¸ä¼¼æ€§å’ŒçœŸå®æ€§æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚
- DDC ä»…éœ€ 5 æ­¥æ¨ç†ï¼Œå¹³å‡è€—æ—¶ 0.77 ç§’ï¼Œç”Ÿæˆé«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆã€‚
- DDC åœ¨ä¸åŒæ•°æ®é›†ã€å¤§å™ªå£°æ¡ä»¶ä¸‹è¡¨ç°ç¨³å¥ã€‚
- DDC å¯ä»¥ç”¨ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡å‹è§£å†³å¤šä¸ªä»»åŠ¡ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: æ·±åº¦æ•°æ®ä¸€è‡´æ€§ï¼šä¸€ç§å¿«é€Ÿä¸”é²æ£’çš„æ‰©æ•£æ¨¡å‹æ±‚è§£é€†é—®é¢˜çš„æ¨¡å‹</p>
</li>
<li>
<p>Authors: é™ˆç€šå®‡ï¼Œéƒå¿—ä¿®ï¼Œè‚–ä¸½è‹±</p>
</li>
<li>
<p>Affiliation: æ¸…åå¤§å­¦</p>
</li>
<li>
<p>Keywords: æ‰©æ•£æ¨¡å‹ï¼Œé€†é—®é¢˜ï¼Œæ•°æ®ä¸€è‡´æ€§ï¼ŒçœŸå®æ€§</p>
</li>
<li>
<p>Urls: https://arxiv.org/abs/2405.10748v1, Github:None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1):æ‰©æ•£æ¨¡å‹åœ¨è§£å†³å›¾åƒé€†é—®é¢˜æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†å¦‚ä½•å¹³è¡¡æ•°æ®ä¸€è‡´æ€§å’ŒçœŸå®æ€§æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚</p>
<p>(2):ç°æœ‰æ–¹æ³•åŒ…æ‹¬æ›¿æ¢å¾—åˆ†å‡½æ•°ã€åˆ†è§£çŸ©é˜µæˆ–ä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼Œä½†å®ƒä»¬åœ¨æ•°æ®ä¸€è‡´æ€§å’ŒçœŸå®æ€§ä¹‹é—´éš¾ä»¥å¹³è¡¡ï¼Œä¸”æ¨ç†é€Ÿåº¦æ…¢ã€‚</p>
<p>(3):æœ¬æ–‡æå‡ºæ·±åº¦æ•°æ®ä¸€è‡´æ€§ï¼ˆDDCï¼‰ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ›´æ–°æ‰©æ•£æ¨¡å‹ä¸­çš„æ•°æ®ä¸€è‡´æ€§æ­¥éª¤ï¼Œé€šè¿‡å˜åˆ†ç•Œè®­ç»ƒç›®æ ‡æœ€å¤§åŒ–æ¡ä»¶åéªŒæ¦‚ç‡ï¼Œå¹¶å‡å°‘å…¶å¯¹æ‰©æ•£è¿‡ç¨‹çš„å½±å“ã€‚</p>
<p>(4):åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€ä¿®å¤ã€å»æ¨¡ç³Šå’ŒJPEGæ¢å¤ç­‰ä»»åŠ¡ä¸Šï¼ŒDDCåœ¨ä»…éœ€5ä¸ªæ¨ç†æ­¥éª¤ä¸”å¹³å‡è€—æ—¶0.77ç§’çš„æƒ…å†µä¸‹ï¼Œåœ¨ç›¸ä¼¼æ€§å’ŒçœŸå®æ€§æŒ‡æ ‡ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¹³è¡¡æ•°æ®ä¸€è‡´æ€§å’ŒçœŸå®æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒDDCåœ¨ä¸åŒæ•°æ®é›†ã€å¤§å™ªå£°å’Œå•ä¸€é¢„è®­ç»ƒæ¨¡å‹è§£å†³å¤šä»»åŠ¡æ–¹é¢çš„é²æ£’æ€§ä¹Ÿå¾—åˆ°äº†è¯æ˜ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æå‡ºæ·±åº¦æ•°æ®ä¸€è‡´æ€§ï¼ˆDDCï¼‰ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ›´æ–°æ‰©æ•£æ¨¡å‹ä¸­çš„æ•°æ®ä¸€è‡´æ€§æ­¥éª¤ï¼Œé€šè¿‡å˜åˆ†ç•Œè®­ç»ƒç›®æ ‡æœ€å¤§åŒ–æ¡ä»¶åéªŒæ¦‚ç‡ï¼Œå¹¶å‡å°‘å…¶å¯¹æ‰©æ•£è¿‡ç¨‹çš„å½±å“ï¼›</p>
<p>ï¼ˆ2ï¼‰åˆ©ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆæ•°æ®ä¸€è‡´æ€§é¡¹ï¼Œå¹¶å°†å…¶èå…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿ç•™æ•°æ®ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œç”Ÿæˆæ›´çœŸå®çš„å›¾åƒï¼›</p>
<p>ï¼ˆ3ï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡å˜åˆ†ç•Œè®­ç»ƒç›®æ ‡æœ€å¤§åŒ–æ¡ä»¶åéªŒæ¦‚ç‡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºç”Ÿæˆä¸æ¡ä»¶æ•°æ®ä¸€è‡´çš„çœŸå®å›¾åƒï¼›</p>
<p>ï¼ˆ4ï¼‰é€šè¿‡å‡å°‘æ•°æ®ä¸€è‡´æ€§é¡¹å¯¹æ‰©æ•£è¿‡ç¨‹çš„å½±å“ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­å¿«é€Ÿç”Ÿæˆå›¾åƒï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„çœŸå®æ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„æ·±åº¦æ•°æ®ä¸€è‡´æ€§ï¼ˆDDCï¼‰æ–¹æ³•ï¼Œåœ¨å¹³è¡¡æ•°æ®ä¸€è‡´æ€§å’ŒçœŸå®æ€§çš„åŒæ—¶ï¼Œå®ç°äº†å¿«é€Ÿæ¨ç†ï¼Œä¸ºæ‰©æ•£æ¨¡å‹æ±‚è§£é€†é—®é¢˜æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºæ·±åº¦æ•°æ®ä¸€è‡´æ€§ï¼ˆDDCï¼‰æ–¹æ³•ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ›´æ–°æ‰©æ•£æ¨¡å‹ä¸­çš„æ•°æ®ä¸€è‡´æ€§æ­¥éª¤ï¼Œé€šè¿‡å˜åˆ†ç•Œè®­ç»ƒç›®æ ‡æœ€å¤§åŒ–æ¡ä»¶åéªŒæ¦‚ç‡ï¼Œå¹¶å‡å°‘å…¶å¯¹æ‰©æ•£è¿‡ç¨‹çš„å½±å“ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€ä¿®å¤ã€å»æ¨¡ç³Šå’Œ JPEG æ¢å¤ç­‰ä»»åŠ¡ä¸Šï¼ŒDDC åœ¨ä»…éœ€ 5 ä¸ªæ¨ç†æ­¥éª¤ä¸”å¹³å‡è€—æ—¶ 0.77 ç§’çš„æƒ…å†µä¸‹ï¼Œåœ¨ç›¸ä¼¼æ€§å’ŒçœŸå®æ€§æŒ‡æ ‡ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</p>
<p>å·¥ä½œé‡ï¼šDDC çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦ä½¿ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆæ•°æ®ä¸€è‡´æ€§é¡¹ï¼Œå¹¶å°†å…¶èå…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-825b9ef49219bfe90e547c36af6ae92e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d8f3559fc7f4e16bd5efc45f3e874012.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-833585aeca5f9fcecaa196677353c9fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-62c582c82243d4b2484dbc714bdede51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-321a696bd3140a7780176a7ef30ec4fe.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-58f99fcf80754e3e0aae1cad41d5cfeb.jpg" align="middle">
</details>




