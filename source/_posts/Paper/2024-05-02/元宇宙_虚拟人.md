
---
title: å…ƒå®‡å®™/è™šæ‹Ÿäºº
date: 2024-05-02 10:00:16
author: Kedreamix
cover: https://pica.zhimg.com/v2-37516691b13dabbabb3b74ea46b402d8.jpg
categories: Paper
tags:
    - å…ƒå®‡å®™/è™šæ‹Ÿäºº
description: å…ƒå®‡å®™/è™šæ‹Ÿäºº æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-05-02  EMOPortraits Emotion-enhanced Multimodal One-shot Head Avatars  
keywords: å…ƒå®‡å®™/è™šæ‹Ÿäºº
toc:
toc_number: false
toc_style_simple: true
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax: true
katex:
aplayer:
highlight_shrink:
aside:
---

>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹[Gemini-Pro](https://ai.google.dev/)çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨
>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼
>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© [ChatPaperFree](https://github.com/Kedreamix/ChatPaperFree) ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ [HuggingFaceå…è´¹ä½“éªŒ](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)

# 2024-05-02 æ›´æ–°


## EMOPortraits: Emotion-enhanced Multimodal One-shot Head Avatars

**Authors:Nikita Drobyshev, Antoni Bigata Casademunt, Konstantinos Vougioukas, Zoe Landgraf, Stavros Petridis, Maja Pantic**

Head avatars animated by visual signals have gained popularity, particularly in cross-driving synthesis where the driver differs from the animated character, a challenging but highly practical approach. The recently presented MegaPortraits model has demonstrated state-of-the-art results in this domain. We conduct a deep examination and evaluation of this model, with a particular focus on its latent space for facial expression descriptors, and uncover several limitations with its ability to express intense face motions. To address these limitations, we propose substantial changes in both training pipeline and model architecture, to introduce our EMOPortraits model, where we:   Enhance the model's capability to faithfully support intense, asymmetric face expressions, setting a new state-of-the-art result in the emotion transfer task, surpassing previous methods in both metrics and quality.   Incorporate speech-driven mode to our model, achieving top-tier performance in audio-driven facial animation, making it possible to drive source identity through diverse modalities, including visual signal, audio, or a blend of both.   We propose a novel multi-view video dataset featuring a wide range of intense and asymmetric facial expressions, filling the gap with absence of such data in existing datasets. 

[PDF](http://arxiv.org/abs/2404.19110v1) 

**Summary**
è™šæ‹Ÿäººå¤´éƒ¨é€šè¿‡è§†è§‰ä¿¡å·åŠ¨ç”»é©±åŠ¨ï¼Œåœ¨è·¨é©±åŠ¨åˆæˆä¸­å°¤å…¶å—æ¬¢è¿ï¼Œè¿™æ˜¯ä¸€ç§æå…·æŒ‘æˆ˜ä½†éå¸¸å®ç”¨çš„æ–¹æ³•ã€‚

**Key Takeaways**
- MegaPortraits æ¨¡å‹åœ¨è¡¨æƒ…æè¿°ç¬¦çš„æ½œåœ¨ç©ºé—´æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•è¡¨è¾¾å¼ºçƒˆçš„é¢éƒ¨åŠ¨ä½œã€‚
- EMOPortraits æ¨¡å‹å¯¹è®­ç»ƒç®¡é“å’Œæ¨¡å‹æ¶æ„è¿›è¡Œäº†é‡å¤§æ›´æ”¹ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å¼ºçƒˆã€ä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…çš„å¿ å®æ”¯æŒã€‚
- EMOPortraits æ¨¡å‹åœ¨æƒ…æ„Ÿè½¬ç§»ä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨æŒ‡æ ‡å’Œè´¨é‡æ–¹é¢éƒ½è¶…è¶Šäº†ä»¥å‰çš„æ–¹æ³•ã€‚
- EMOPortraits æ¨¡å‹ç»“åˆäº†åŸºäºè¯­éŸ³çš„æ¨¡å¼ï¼Œåœ¨éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ä¸­å®ç°äº†é¡¶çº§æ€§èƒ½ã€‚
- EMOPortraits æ¨¡å‹æ”¯æŒé€šè¿‡è§†è§‰ä¿¡å·ã€éŸ³é¢‘æˆ–ä¸¤è€…ç»“åˆçš„å¤šç§æ–¹å¼é©±åŠ¨æºèº«ä»½ã€‚
- æå‡ºä¸€ä¸ªæ–°çš„å¤šè§†å›¾è§†é¢‘æ•°æ®é›†ï¼ŒåŒ…å«å¹¿æ³›çš„å¼ºçƒˆå’Œä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: EMOPortraits: æƒ…ç»ªå¢å¼ºå¤šæ¨¡æ€ä¸€å‘å¤´åƒ</p>
</li>
<li>
<p>Authors: Nikita Drobyshev, Antoni Bigata Casademunt, Konstantinos Vougioukas, Zoe Landgraf, Stavros Petridis, Maja Pantic</p>
</li>
<li>
<p>Affiliation: å¸å›½ç†å·¥å­¦é™¢</p>
</li>
<li>
<p>Keywords: å¤´éƒ¨åŒ–èº«ã€é¢éƒ¨è¡¨æƒ…ã€æƒ…æ„Ÿä¼ é€’ã€è¯­éŸ³é©±åŠ¨ã€å¤šæ¨¡æ€</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2404.19110v1, Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>(1): ç ”ç©¶èƒŒæ™¯ï¼šå¤´éƒ¨åŒ–èº«åŠ¨ç”»åœ¨è·¨é©±åŠ¨åˆæˆä¸­è¶Šæ¥è¶Šæµè¡Œï¼Œå…¶ä¸­é©±åŠ¨è€…ä¸åŠ¨ç”»è§’è‰²ä¸åŒï¼Œè¿™æ˜¯ä¸€ç§å…·æœ‰æŒ‘æˆ˜æ€§ä½†éå¸¸å®ç”¨çš„æ–¹æ³•ã€‚æœ€è¿‘æå‡ºçš„ MegaPortraits æ¨¡å‹åœ¨è¿™ä¸ªé¢†åŸŸå±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p>
<p>(2): è¿‡å»çš„æ–¹æ³•ï¼šç ”ç©¶äººå‘˜å¯¹ MegaPortraits æ¨¡å‹è¿›è¡Œäº†æ·±å…¥çš„æ£€æŸ¥å’Œè¯„ä¼°ï¼Œç‰¹åˆ«å…³æ³¨å…¶é¢éƒ¨è¡¨æƒ…æè¿°ç¬¦çš„æ½œåœ¨ç©ºé—´ï¼Œå‘ç°å…¶è¡¨è¾¾å¼ºçƒˆé¢éƒ¨åŠ¨ä½œçš„èƒ½åŠ›å­˜åœ¨ä¸€äº›é™åˆ¶ã€‚</p>
<p>(3): ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œç ”ç©¶äººå‘˜åœ¨è®­ç»ƒç®¡é“å’Œæ¨¡å‹æ¶æ„ä¸­æå‡ºäº†å®è´¨æ€§çš„æ”¹å˜ï¼Œå¼•å…¥äº† EMOPortraits æ¨¡å‹ï¼Œå…¶ä¸­ï¼š
   - å¢å¼ºäº†æ¨¡å‹å¿ å®æ”¯æŒå¼ºçƒˆã€ä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…çš„èƒ½åŠ›ï¼Œåœ¨æƒ…æ„Ÿä¼ é€’ä»»åŠ¡ä¸­è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›ç»“æœï¼Œåœ¨æŒ‡æ ‡å’Œè´¨é‡ä¸Šéƒ½è¶…è¿‡äº†ä»¥å‰çš„æ–¹æ³•ã€‚
   - å°†è¯­éŸ³é©±åŠ¨æ¨¡å¼çº³å…¥æ¨¡å‹ï¼Œåœ¨éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ä¸­å®ç°äº†é¡¶çº§æ€§èƒ½ï¼Œä½¿å¾—å¯ä»¥é€šè¿‡è§†è§‰ä¿¡å·ã€éŸ³é¢‘æˆ–ä¸¤è€…æ··åˆç­‰å¤šç§æ–¹å¼é©±åŠ¨æºèº«ä»½ã€‚
   - æå‡ºäº†ä¸€ç»„æ–°çš„å¤šè§†è§’è§†é¢‘æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«å¹¿æ³›çš„å¼ºçƒˆå’Œä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…ï¼Œå¡«è¡¥äº†ç°æœ‰æ•°æ®é›†ä¸­ç¼ºä¹æ­¤ç±»æ•°æ®çš„æƒ…å†µã€‚</p>
<p>(4): æ€§èƒ½å’Œæ•ˆæœï¼šåœ¨æƒ…æ„Ÿä¼ é€’ä»»åŠ¡ä¸Šï¼ŒEMOPortraits æ¨¡å‹åœ¨æŒ‡æ ‡å’Œè´¨é‡ä¸Šéƒ½è¶…è¿‡äº†ä»¥å‰çš„æ–¹æ³•ï¼Œè®¾å®šäº†æ–°çš„æœ€å…ˆè¿›çš„ç»“æœã€‚åœ¨éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ä¸­ï¼Œè¯¥æ¨¡å‹ä¹Ÿå–å¾—äº†é¡¶çº§æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ç ”ç©¶äººå‘˜çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ä¸ªèƒ½å¤Ÿé€šè¿‡å¤šç§æ–¹å¼é©±åŠ¨æºèº«ä»½çš„å¤´éƒ¨åŒ–èº«åŠ¨ç”»æ¨¡å‹ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
    (1): å¯¹ MegaPortraits æ¨¡å‹è¿›è¡Œæ·±å…¥æ£€æŸ¥å’Œè¯„ä¼°ï¼Œå‘ç°å…¶åœ¨è¡¨è¾¾å¼ºçƒˆé¢éƒ¨åŠ¨ä½œæ–¹é¢å­˜åœ¨é™åˆ¶ï¼›
    (2): åœ¨è®­ç»ƒç®¡é“å’Œæ¨¡å‹æ¶æ„ä¸­æå‡ºå®è´¨æ€§æ”¹å˜ï¼Œå¼•å…¥ EMOPortraits æ¨¡å‹ï¼›
    (3): å¢å¼ºæ¨¡å‹å¿ å®æ”¯æŒå¼ºçƒˆã€ä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…çš„èƒ½åŠ›ï¼›
    (4): å°†è¯­éŸ³é©±åŠ¨æ¨¡å¼çº³å…¥æ¨¡å‹ï¼Œå®ç°éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»é¡¶çº§æ€§èƒ½ï¼›
    (5): æå‡ºå¤šè§†è§’è§†é¢‘æ•°æ®é›†ï¼Œå¡«è¡¥ç°æœ‰æ•°æ®é›†ä¸­ç¼ºä¹å¼ºçƒˆå’Œä¸å¯¹ç§°é¢éƒ¨è¡¨æƒ…æ•°æ®çš„æƒ…å†µã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³• EMOPortraitsï¼Œç”¨äºåˆ›å»ºç¥ç»å¤´åƒï¼Œåœ¨å›¾åƒé©±åŠ¨ã€è·¨èº«ä»½æƒ…ç»ªè½¬æ¢æ–¹é¢å…·æœ‰å“è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„è¯­éŸ³é©±åŠ¨æ¨¡å¼ä½¿å¾—å¯ä»¥é€šè¿‡å¤šç§æ¡ä»¶ï¼ˆè§†é¢‘ã€éŸ³é¢‘ã€å¤´éƒ¨è¿åŠ¨ï¼‰æ¥é©±åŠ¨é¢éƒ¨åŠ¨ç”»ã€‚æˆ‘ä»¬æ”¶é›†äº† FEED æ•°æ®é›†ï¼Œæˆ‘ä»¬ç›¸ä¿¡è¿™å°†æˆä¸ºä»äº‹å¤šå…ƒåŒ–ä»¥äººä¸ºä¸­å¿ƒç ”ç©¶çš„ç ”ç©¶äººå‘˜çš„å®è´µèµ„äº§ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚å®ƒä¸ä¼šç”Ÿæˆå¤´åƒçš„èº«ä½“æˆ–è‚©è†€ï¼Œé™åˆ¶äº†ä¸€äº›ç”¨ä¾‹ã€‚æˆ‘ä»¬ç›®å‰å°†æˆ‘ä»¬çš„è¾“å‡ºä¸æºå›¾åƒä¸»ä½“é›†æˆåœ¨ä¸€èµ·ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹æœ‰æ—¶éš¾ä»¥è¿›è¡Œå‡†ç¡®çš„è¡¨æƒ…è½¬æ¢ï¼Œå¹¶ä¸”åœ¨å¤´éƒ¨å¤§å¹…æ—‹è½¬æ—¶æ€§èƒ½ä¸ä½³ã€‚è¿™äº›æŒ‘æˆ˜å¯¹äºæœªæ¥çš„å¢å¼ºè‡³å…³é‡è¦ï¼Œå¹¶ä¸”ä»ç„¶æ˜¯æˆ‘ä»¬æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶å·¥ä½œçš„æ ¸å¿ƒã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ae09218eb625859aeda612581ba59975.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-76da3d8060bb28f6e1488ffdcf42c493.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-07199851d15b47c4d1a719b68cd3f240.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-29a1efddd95063c164480f3a84bf5f72.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc5fc34eb617f15c5ecceee7d25f9f5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e7948dbe17eb67516e7078da09fc10ae.jpg" align="middle">
</details>




## MeGA: Hybrid Mesh-Gaussian Head Avatar for High-Fidelity Rendering and   Head Editing

**Authors:Cong Wang, Di Kang, He-Yi Sun, Shen-Han Qian, Zi-Xuan Wang, Linchao Bao, Song-Hai Zhang**

Creating high-fidelity head avatars from multi-view videos is a core issue for many AR/VR applications. However, existing methods usually struggle to obtain high-quality renderings for all different head components simultaneously since they use one single representation to model components with drastically different characteristics (e.g., skin vs. hair). In this paper, we propose a Hybrid Mesh-Gaussian Head Avatar (MeGA) that models different head components with more suitable representations. Specifically, we select an enhanced FLAME mesh as our facial representation and predict a UV displacement map to provide per-vertex offsets for improved personalized geometric details. To achieve photorealistic renderings, we obtain facial colors using deferred neural rendering and disentangle neural textures into three meaningful parts. For hair modeling, we first build a static canonical hair using 3D Gaussian Splatting. A rigid transformation and an MLP-based deformation field are further applied to handle complex dynamic expressions. Combined with our occlusion-aware blending, MeGA generates higher-fidelity renderings for the whole head and naturally supports more downstream tasks. Experiments on the NeRSemble dataset demonstrate the effectiveness of our designs, outperforming previous state-of-the-art methods and supporting various editing functionalities, including hairstyle alteration and texture editing. 

[PDF](http://arxiv.org/abs/2404.19026v1) Project page: https://conallwang.github.io/MeGA_Pages/

**Summary**
å¤šæ¨¡æ€è¡¨æƒ…è™šæ‹Ÿäººå¤´éƒ¨å»ºæ¨¡æ–¹æ³• MeGA: ä½¿ç”¨ç½‘æ ¼èåˆé«˜æ–¯æ¨¡å‹ï¼Œä¸ºä¸åŒå¤´éƒ¨ç»„ä»¶æä¾›æ›´åˆé€‚çš„è¡¨å¾æ–¹æ³•ã€‚

**Key Takeaways**
- æå‡ºä¸€ç§æ··åˆç½‘æ ¼-é«˜æ–¯è™šæ‹Ÿäººå¤´éƒ¨å»ºæ¨¡æ–¹æ¡ˆ MeGAã€‚
- é€‰æ‹©å¢å¼ºå‹ FLAME ç½‘æ ¼ä½œä¸ºé¢éƒ¨è¡¨å¾ï¼Œå¹¶é¢„æµ‹ UV ä½ç§»å›¾ä»¥æä¾›é€é¡¶ç‚¹åç§»ï¼Œå®ç°ä¸ªæ€§åŒ–å‡ ä½•ç»†èŠ‚ã€‚
- é‡‡ç”¨å»¶è¿Ÿç¥ç»æ¸²æŸ“æŠ€æœ¯è·å–é¢éƒ¨é¢œè‰²ï¼Œå¹¶å°†ç¥ç»çº¹ç†åˆ†è§£ä¸ºä¸‰ä¸ªæœ‰æ„ä¹‰çš„éƒ¨åˆ†ï¼Œå®ç°é€¼çœŸçš„æ¸²æŸ“ã€‚
- ä½¿ç”¨ 3D é«˜æ–¯æº…å°„æ„å»ºé™æ€è§„èŒƒå¤´å‘ï¼Œåˆ©ç”¨åˆšä½“å˜æ¢å’ŒåŸºäº MLP çš„å˜å½¢åœºå¤„ç†å¤æ‚çš„åŠ¨æ€è¡¨æƒ…ã€‚
- ç»“åˆé®æŒ¡æ„ŸçŸ¥èåˆï¼ŒMeGA ä¸ºæ•´ä¸ªå¤´éƒ¨ç”Ÿæˆæ›´é«˜ä¿çœŸåº¦çš„æ¸²æŸ“ï¼Œå¹¶æ”¯æŒæ›´å¤šä¸‹æ¸¸ä»»åŠ¡ã€‚
- åœ¨ NeRSemble æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒMeGA ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶æ”¯æŒå‘å‹æ”¹å˜å’Œçº¹ç†ç¼–è¾‘ç­‰å¤šç§ç¼–è¾‘åŠŸèƒ½ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>
<p>Title: MeGAï¼šæ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼ˆä¸­æ–‡ç¿»è¯‘ï¼šMeGAï¼šç”¨äºé«˜ä¿çœŸæ¸²æŸ“å’Œå¤´éƒ¨ç¼–è¾‘çš„æ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼‰</p>
</li>
<li>
<p>Authors: Cong Wang, Di Kang, He-Yi Sun, Shen-Han Qian, Zi-Xuan Wang, Linchao Bao, Song-Hai Zhang</p>
</li>
<li>
<p>Affiliation: æ¸…åå¤§å­¦ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼šæ¸…åå¤§å­¦ï¼‰</p>
</li>
<li>
<p>Keywords: Head Avatar, High-Fidelity Rendering, Head Editing, Mesh, Gaussian</p>
</li>
<li>
<p>Urls: Paper: https://arxiv.org/abs/2404.19026 , Github: None</p>
</li>
<li>
<p>Summary:</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šé«˜ä¿çœŸå¤´éƒ¨å¤´åƒçš„åˆ›å»ºæ˜¯ AR/VR åº”ç”¨ä¸­çš„æ ¸å¿ƒé—®é¢˜ï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥åŒæ—¶ä¸ºæ‰€æœ‰ä¸åŒçš„å¤´éƒ¨ç»„ä»¶è·å¾—é«˜è´¨é‡çš„æ¸²æŸ“ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨å•ä¸€è¡¨ç¤ºæ¥å»ºæ¨¡å…·æœ‰æˆªç„¶ä¸åŒç‰¹å¾çš„ç»„ä»¶ï¼ˆä¾‹å¦‚ï¼Œçš®è‚¤ä¸å¤´å‘ï¼‰ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•æ¢ç´¢äº†åŸºäºç½‘æ ¼ã€åŸºäº NeRF å’ŒåŸºäº 3D é«˜æ–¯çš„è¡¨ç¤ºï¼Œå–å¾—äº†æ˜¾ç€è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºäººç±»å¤´éƒ¨æ˜¯ä¸€ä¸ªåŒ…å«å…·æœ‰æˆªç„¶ä¸åŒç‰¹å¾çš„ç»„ä»¶ï¼ˆä¾‹å¦‚ï¼Œçš®è‚¤ä¸å¤´å‘ï¼‰çš„å¤æ‚â€œç‰©ä½“â€ï¼Œå› æ­¤å¯èƒ½ä¸å­˜åœ¨å¯ä»¥åŒæ—¶å¾ˆå¥½åœ°å»ºæ¨¡æ‰€æœ‰è¿™äº›ç»„ä»¶çš„å•ä¸€è¡¨ç¤ºã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼ˆMeGAï¼‰ï¼Œå®ƒä½¿ç”¨æ›´åˆé€‚çš„è¡¨ç¤ºæ¥å»ºæ¨¡ä¸åŒçš„å¤´éƒ¨ç»„ä»¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªå¢å¼ºçš„ FLAME ç½‘æ ¼ä½œä¸ºæˆ‘ä»¬çš„é¢éƒ¨è¡¨ç¤ºï¼Œå¹¶é¢„æµ‹ä¸€ä¸ª UV ç½®æ¢è´´å›¾æ¥æä¾›æ¯ä¸ªé¡¶ç‚¹çš„åç§»é‡ï¼Œä»¥æ”¹è¿›ä¸ªæ€§åŒ–çš„å‡ ä½•ç»†èŠ‚ã€‚ä¸ºäº†å®ç°é€¼çœŸçš„æ¸²æŸ“ï¼Œæˆ‘ä»¬ä½¿ç”¨å»¶è¿Ÿç¥ç»æ¸²æŸ“è·å–é¢éƒ¨é¢œè‰²ï¼Œå¹¶å°†ç¥ç»çº¹ç†åˆ†è§£ä¸ºä¸‰ä¸ªæœ‰æ„ä¹‰çš„éƒ¨åˆ†ã€‚å¯¹äºå¤´å‘å»ºæ¨¡ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ 3D é«˜æ–¯ç‚¹äº‘æ„å»ºé™æ€è§„èŒƒå¤´å‘ã€‚ç„¶ååº”ç”¨åˆšæ€§å˜æ¢å’ŒåŸºäº MLP çš„å˜å½¢åœºæ¥å¤„ç†å¤æ‚çš„åŠ¨æ€è¡¨æƒ…ã€‚ç»“åˆæˆ‘ä»¬çš„é®æŒ¡æ„ŸçŸ¥æ··åˆï¼ŒMeGA ä¸ºæ•´ä¸ªå¤´éƒ¨ç”Ÿæˆæ›´é«˜ä¿çœŸçš„æ¸²æŸ“ï¼Œå¹¶è‡ªç„¶åœ°æ”¯æŒæ›´å¤šä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šä»»åŠ¡ä¸æ€§èƒ½ï¼šåœ¨ NeRSemble æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜äº†æˆ‘ä»¬è®¾è®¡çš„æœ‰æ•ˆæ€§ï¼Œä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹¶æ”¯æŒå„ç§ç¼–è¾‘åŠŸèƒ½ï¼ŒåŒ…æ‹¬å‘å‹æ”¹å˜å’Œçº¹ç†ç¼–è¾‘ã€‚</p>
<ol>
<li>
<p>Methods: </p>
<pre><code>            (1):æå‡ºæ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼ˆMeGAï¼‰ï¼Œä½¿ç”¨æ›´åˆé€‚çš„è¡¨ç¤ºæ¥å»ºæ¨¡ä¸åŒçš„å¤´éƒ¨ç»„ä»¶ï¼›

            (2):é€‰æ‹©å¢å¼ºçš„ FLAME ç½‘æ ¼ä½œä¸ºé¢éƒ¨è¡¨ç¤ºï¼Œé¢„æµ‹ UV ç½®æ¢è´´å›¾æä¾›é¡¶ç‚¹åç§»é‡ï¼Œæ”¹è¿›ä¸ªæ€§åŒ–å‡ ä½•ç»†èŠ‚ï¼›

            (3):ä½¿ç”¨å»¶è¿Ÿç¥ç»æ¸²æŸ“è·å–é¢éƒ¨é¢œè‰²ï¼Œå°†ç¥ç»çº¹ç†åˆ†è§£ä¸ºä¸‰ä¸ªæœ‰æ„ä¹‰çš„éƒ¨åˆ†ï¼Œå®ç°é€¼çœŸæ¸²æŸ“ï¼›

            (4):ä½¿ç”¨ 3D é«˜æ–¯ç‚¹äº‘æ„å»ºé™æ€è§„èŒƒå¤´å‘ï¼Œåº”ç”¨åˆšæ€§å˜æ¢å’ŒåŸºäº MLP çš„å˜å½¢åœºå¤„ç†è¡¨æƒ…ï¼›

            (5):ç»“åˆé®æŒ¡æ„ŸçŸ¥æ··åˆï¼Œç”Ÿæˆæ›´é«˜ä¿çœŸçš„æ¸²æŸ“ï¼Œæ”¯æŒå‘å‹æ”¹å˜å’Œçº¹ç†ç¼–è¾‘ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚
</code></pre>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†æ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼ˆMeGAï¼‰ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘æ ¼è¿›è¡Œé¢éƒ¨å»ºæ¨¡ï¼Œä½¿ç”¨ 3DGS è¿›è¡Œå¤´å‘å»ºæ¨¡ã€‚ä¸ºäº†è·å¾—é«˜è´¨é‡çš„é¢éƒ¨æ¨¡å‹ï¼Œæˆ‘ä»¬å¢å¼ºäº† FLAME ç½‘æ ¼å¹¶è§£ç äº†ä¸€ä¸ª UV ç½®æ¢è´´å›¾ä»¥è·å¾—å‡ ä½•ç»†èŠ‚ã€‚é¢éƒ¨é¢œè‰²æ˜¯ä»ç¥ç»çº¹ç†è´´å›¾ä¸­è§£ç çš„ï¼Œè¯¥è´´å›¾ç”±è§£è€¦æ¼«åå°„çº¹ç† Ë†Tdiã€è§†ç‚¹ç›¸å…³çº¹ç† Ë†Tv å’ŒåŠ¨æ€çº¹ç† Ë†Tdy ç»„æˆã€‚ä¸ºäº†è·å¾—é«˜è´¨é‡çš„å¤´å‘æ¨¡å‹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé™æ€ 3DGS å¤´å‘ï¼Œå¹¶é‡‡ç”¨åˆšæ€§å˜æ¢ç»“åˆåŸºäº MLP çš„å˜å½¢åœºè¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚æœ€ç»ˆçš„æ¸²æŸ“æ˜¯é€šè¿‡å°†å¤´å‘å’Œå¤´éƒ¨éƒ¨åˆ†ä¸æˆ‘ä»¬çš„é®æŒ¡æ„ŸçŸ¥æ··åˆæ¨¡å—æ··åˆè·å¾—çš„ã€‚æ­¤å¤–ï¼ŒMeGA è‡ªç„¶æ”¯æŒå„ç§ç¼–è¾‘åŠŸèƒ½ï¼ŒåŒ…æ‹¬å‘å‹æ›´æ”¹å’Œçº¹ç†ç¼–è¾‘ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºæ··åˆç½‘æ ¼-é«˜æ–¯å¤´éƒ¨å¤´åƒï¼ˆMeGAï¼‰ï¼Œä½¿ç”¨æ›´åˆé€‚çš„è¡¨ç¤ºæ¥å»ºæ¨¡ä¸åŒçš„å¤´éƒ¨ç»„ä»¶ï¼›æ€§èƒ½ï¼šåœ¨ NeRSemble æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜äº†æˆ‘ä»¬è®¾è®¡çš„æœ‰æ•ˆæ€§ï¼Œä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼›å·¥ä½œé‡ï¼š.......</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-37516691b13dabbabb3b74ea46b402d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfaebdbe659151ed19833d736cf99b64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-179dcf87ee24bc1a697ea323e2d146c3.jpg" align="middle">
</details>




